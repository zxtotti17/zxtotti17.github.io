[{"id":"dff573c37ee274635402fd33e69bcfcf","title":"文章名","content":"","slug":"文章名","date":"2021-12-09T11:34:30.000Z","categories_index":"","tags_index":"","author_index":"Fly"},{"id":"6607396c684bdaf6e6783930fc77d6ef","title":"Mysql的一些不常用的规则","content":"mysql的全文索引主要用在用户搜索查询，达人秀中应用是用来匹配作品内容及标题全文搜索\n传统的匹配方式是like “%xxx%”但这样效率是很低的，在mysql 5.7版本之后提供了inodb的全文索引方式，用的是分词的形式\n达人秀中用户主要用的是中文查找内容，但是在标题和内容中存在网页html  css等标签及无关的标点符号会影响搜索的速度，同时mysql全文索引只支持 char varchar text三种数据类型\n那么当出现较多文字的同时就需要缩减文字精炼存储，在用专门的字段存储查询\nALTER TABLE &#96;works&#96; ADD COLUMN &#96;search_content&#96; text CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT &#39;&#39; COMMENT &#39;搜索文本&#39; AFTER &#96;rich_content&#96;;\nALTER TABLE &#96;works&#96; add fulltext index &#96;title_search_content&#96; (&#96;title&#96;, &#96;search_content&#96;) WITH PARSER ngram;\n先给对应的表结构加上字段及全文索引，包含标题及内容，采用分词的形式\n在作品添加及更新的时候用正则表达式匹配字符串中文精炼字符串长度保证text的长度能放下，同时过滤只存在中文去掉其他\npublic getSearchContent(content:string, rich_content:string)  &#123;\n        let str &#x3D; matchChinses(content) + matchChinses(rich_content);\n        if(str.length &gt; 16382)&#123;&#x2F;&#x2F;中文按4个字节来算\n            return str.slice(0,16382);\n        &#125;\n        return str;\n    &#125;\n\n&#x2F;**\n * 正则匹配中文\n *&#x2F;\n export function matchChinses(content: string): any &#123;\n    if (content !&#x3D;&#x3D; null &amp;&amp; content !&#x3D;&#x3D; &#39;&#39;) &#123;\n        const reg &#x3D; &#x2F;[\\u4e00-\\u9fa5]&#x2F;g;\n        return content.match(reg).join(&#39;&#39;);\n    &#125;\n    return &#39;&#39;;\n&#125;\n这样就能保证存储数据准确性又不太影响搜索的准确性及时效性\n对于之前发布的作品采用脚本的形式一次性做匹配更新操作，定到凌晨3点跑一次做同步，避免死循环加上超时机制\npublic async syncUpdateSearchContent(): Promise&lt;any&gt; &#123;\n        setTimeout(async () &#x3D;&gt;&#123;\n            let page &#x3D; 1;\n            while(1)&#123;\n                if(await this.worksService.updateSearchContent(page))&#123;\n                    page++;\n                &#125;else&#123;\n                    break;\n                &#125;\n            &#125;\n            return \n        &#125;, 60*5);\n    &#125;\n\npublic async updateSearchContent(page:number) &#123;\n        let repo &#x3D; WorksRepository.getInstance();\n        let ids &#x3D; await repo.getNeedSearchContent(page);&#x2F;&#x2F;取数据\n        if(!ids || !ids.length) return false;\n        let data &#x3D; await repo.getIdsWorksData(ids);\n        for(let i &#x3D; 0; i &lt; data.length; i++)&#123;\n            let worksData:Works &#x3D; data[i];\n            worksData.search_content &#x3D; this.getSearchContent(worksData.content,worksData.rich_content);\n            let editor &#x3D; this.getEditor(worksData);\n            await this.setCharacter(worksData, editor);\n        &#125;\n        return true;\n    &#125;\n如果是mysql 8.0以上版本可以用REGEXP_REPLACE的方法直接在sql中匹配替换更新\n\n有些不常被使用的mysql语法\n1.union 和 union all、 Intersect 这些sql语法主要用在当我们需要查询多表数据同时需要使用多表不同字段数据的时候用这个语句避免多次连接数据库查询如：SELECT ANY_VALUE(t.works_id) AS works_id, ANY_VALUE(SUM(t.score)) AS score FROM (SELECT ANY_VALUE(works_id) AS works_id, ANY_VALUE(SUM(click_num)) AS score FROM view_click WHERE works_id &#x3D; ? AND create_time &lt;&#x3D; ? GROUP BY works_id \n        UNION ALL SELECT ANY_VALUE(works_id) AS works_id, ANY_VALUE(COUNT(id) * 30) AS score FROM log_first_like WHERE works_id &#x3D; ? AND create_time &lt;&#x3D; ? GROUP BY works_id \n同时union 与 union all的区别在与 当连接查询的表有同样字段的时候union all中对两个结果集进行并集操作，包括重复行，不进行排序， union则会对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序， Intersect：对两个结果集进行交集操作，不包括重复行，同时进行默认规则的排序\n\n2.2.视图View 视图就是SELECT语句执行后返回的结果集，比如当我们需要用新表的替换旧表，但需要重旧表中获取数据，可以用视图 view，将两个结果集合并视图，在查询视图，但是视图肯定不会那么高效的，所以尽量少用如：\nCREATE VIEW view_click\nAS \nSELECT * FROM click UNION ALL SELECT * FROM log_click\n后续当我要按时间查找新旧表数据的时候就可以直接select * from view_click where … 查找视图来查找新旧数据\n2.3.ON DUPLICATE KEY UPDATE 这个是专门使用在插入语句中，在并发的情况的下有可能会导致业务数据判断错误，引起插入语句违反数据库限制，如主键唯一  或者 唯一索引限制引起报错，但实际上索要做的是更新对应业务数据的值就可以使用ON DUPLICATE KEY UPDATE在插入语句中去替换因为限制条件下的数据，需要注意的限制条件在插入语句中要去掉，如id做主键就需要在更新后面去掉id，唯一索引也是同理如：\nINSERT INTO table (a,b,c) VALUES (1,2,3)  ON DUPLICATE KEY UPDATE c&#x3D;c+1;  a为主键，b为唯一索引那么update语句中就不要带这两个字段\n但是这个语法容易导致死锁所以使用上要格外小心\n","slug":"mysql的一些不常用的规则","date":"2021-11-24T08:59:23.000Z","categories_index":"IT笔记","tags_index":"mysql","author_index":"Fly"},{"id":"a327ba097d8097f094e2ffa26497e116","title":"游戏成就任务系统设计","content":"游戏中的成就任务一般是伴随着玩家操作，及一些游戏次数记录所以可以用一个监听如node里面的\nvar EventEmitter &#x3D; require(&#39;events&#39;).EventEmitter;\nvar life &#x3D; new EventEmitter();\n\n&#x2F;&#x2F;这里不用on，也可以用addEventListener\nlife.on(&#39;doSth&#39;, function(who)&#123;\n　　console.log(&#39;给 &#39; + who + &#39; 倒水&#39;);\n&#125;)\n\nlife.emit(&#39;doSth&#39;,&#39;Sunny&#39;);\nEventEmitter相当于一个观察者模式，事件发布订阅的形式注册监听的请求回发数据，对应的请求去对应执行相应的成就改变请求的类型可以存放在map中，如\n&#123;&quot;server.game.inter&quot;:[...class],&quot;server.game.interAct&quot;:[...class]&#125;\n对应请求的列表取出后的对其中类的回调依次执行在返回类似的map\n&#123;&quot;1&quot;:&#123;“up”:1&#125;,&quot;2&quot;:&#123;“up”:1&#125;&#125;\n在更新任务返回给客户端显示\n成就任务中需要获得物品的可以定义一个基类  类属性self.idlist = list;list可以为传参进来的物品列表，该列表是需要我们监听的物品改变一般返回给客户端需要物品及数量，可以在返回的里面判断增加多少\nlet up &#x3D; 0;&#x2F;&#x2F;单一物品\nfor(k in returnData.gain)&#123;\n\tif(self.idlist.indexOf(k) &gt; -1)&#123;\n\t\tup+&#x3D; returnData.gain[k];\n\t&#125;\n&#125;\nreturn up;\n","slug":"游戏成就任务系统设计","date":"2020-06-29T01:07:21.000Z","categories_index":"设计方法","tags_index":"游戏","author_index":"Fly"},{"id":"f93992fa9cfdd90a84e68e7ac1ad2636","title":"作品合集-多对多对多关系表","content":"作品合集的背景是在原有话题上加入标签，让话题和标签有多对多的关系即 A-&gt;B，新的合集表C是由标签B合并成合集也是多对多关系即 B-&gt;C, 同时对于用户来说，用户只关心对应的话题，对应话题条件加入合集即 A-&gt;C,传统的多对多关系一般是建立中间关联表用作中转的关联（传统的关系表中A-B关系就分出一个A-B的各主键关联关系表，B-C和C-A也是一样，但是这时候如果改动一个A上的B属性，就需要改动复杂的关联关系这是必然的，所要改动的表数据可能就是5个，复杂。在表含量较小的情况下时，我们将关系存储于原始表字段，用数组或者map的形式做关系的关联能大大降低关系表的复杂性及查询次数。数据量大的情况下用mangodb的map存储会有更好的效果），但是这样的一般是在多对多一种关系中，在多种关系下就会显得臃肿复杂，所以分析情景细节后，将标签表做B-&gt;A的关联，将合集表做C-&gt;A， C-&gt;B的关联同时对用户发布需要判断话题对应合集的情况，将使用中的合集重要信息缓存一张新的缓存表，以下是标签表\n\n可以看到标签对应的话题已经做了关联，以下是合集表\n合集表中关联了标签及对应标签所有相关不重复的话题，重点就是将对应关系一一梳理对应存储，更改合集中的标签的时候，通过对标签与原数据不同的拆解分出添加和删除的标签，从中获取对应涉及的话题，去重合并更新缓存及数据库和用于给用户的使用的缓存表中的关系字段\n&#x2F;&#x2F;管理更改的标签\n   public async  manageTagMerge(mergeData:WorksMerge, tag_map:any): Promise&lt;string&gt;&#123;\n       let result &#x3D; mergeData.relevance_topic;\n       if(mergeData.topic_tag !&#x3D; JSON.stringify(tag_map))&#123;\n           let mergeTopicList &#x3D; await this.getMergeTagTopic(tag_map);\n           result &#x3D; JSON.stringify(mergeTopicList);\n       &#125;\n       \n       return result;\n   &#125;\n\n当更改或者添加话题标签时，同样也是分出添加和删除的标签，从标签中获取对应的联系的合集，取出合集管理的话题，在对关联话题进行修改达到去掉标签后的关联效果，同时修改标签表中关联的话题属性，将改完去重后完整数据更新缓存及数据库，同时更新用于用户部分的缓存数据\npublic async manageTagTopic(old_tag:string, tag_map:any, topic_id:string): Promise&lt;any&gt; &#123;\n        if(old_tag &#x3D;&#x3D; JSON.stringify(tag_map)) return true;\n        let oldTagMap &#x3D; JSON.parse(old_tag);\n        let newMap &#x3D; tag_map[&#39;0&#39;] || [];\n        let newAddMap &#x3D; await this.addNewTopicTag(topic_id, newMap);\n        if(!newAddMap)&#123;\n            logger.error(&#39;manageTagTopic new  error, topic_id:%s &#39;,topic_id);\n            return false;\n        &#125;\n        let addMap &#x3D; this.getAddMap(oldTagMap, tag_map);\n        if(!await this.addTagTopic(addMap, topic_id))&#123;\n            logger.error(&#39;manageTagTopic add  error, topic_id:%s &#39;,topic_id);\n            return false;\n        &#125;\n        let deleteMap &#x3D; this.getDeleteMap(oldTagMap, tag_map);\n        if(!await this.deleteTagTopic(deleteMap, topic_id))&#123;\n            logger.error(&#39;manageTagTopic delete error, topic_id:%s &#39;,topic_id);\n            return false;\n        &#125;\n        let result &#x3D; tag_map;\n        if(typeof newAddMap &#x3D;&#x3D; &quot;object&quot;)&#123;\n            delete result[0];\n            for(let k in newAddMap)&#123;\n                result[k] &#x3D; newAddMap[k];\n            &#125;\n        &#125;\n        return result;\n    &#125;\n\n&#x2F;**\n    * 删除已有话题标签\n    *&#x2F;\n   public async deleteTagTopic (tag_map:any, topic_id:string): Promise&lt;any&gt; &#123;\n       if(JSON.stringify(tag_map) &#x3D;&#x3D; &quot;&#123;&#125;&quot;) return true;\n       for(let k in tag_map)&#123;\n           let tagList &#x3D; await TopicTagRepository.getInstance().getCharacter(k);\n           let tagData &#x3D; tagList[0];\n           if(!tagData)&#123;\n               continue;\n           &#125;\n           let topicArr &#x3D; JSON.parse(tagData.relevance_topic);\n           if(topicArr &amp;&amp; topicArr.length &amp;&amp; topicArr.indexOf(topic_id) &gt;&#x3D; 0)&#123;\n               let index &#x3D; topicArr.indexOf(topic_id);\n               topicArr.splice(index, 1); \n               tagData.relevance_topic &#x3D; JSON.stringify(topicArr);\n               if(await TopicTagRepository.getInstance().setCharacter(tagData))&#123;&#x2F;&#x2F;更新合集作品关联\n                   let rows &#x3D; await WorksMergeRepository.getInstance().getMergeTagIds(k);\n                   for(let j &#x3D; 0; j &lt; rows.length; j++)&#123;\n                       let mergeOne &#x3D; rows[j];\n                       let rt &#x3D; JSON.parse(mergeOne.relevance_topic);\n                       if(rt &amp;&amp; rt.length &amp;&amp; rt.indexOf(topic_id) &gt;&#x3D; 0)&#123;\n                           rt.splice(index, 1); \n                           mergeOne.relevance_topic &#x3D; JSON.stringify(rt);\n                           await WorksMergeRepository.getInstance().setMergeTopic(mergeOne);\n                       &#125;\n                   &#125;\n               &#125;\n           &#125;\n       &#125;\n       return true;\n   &#125;\n\n&#x2F;**\n    * 添加已有标签\n    *&#x2F;\n   public async addTagTopic (tag_map:any, topic_id:string): Promise&lt;boolean&gt; &#123;\n       if(JSON.stringify(tag_map) &#x3D;&#x3D; &quot;&#123;&#125;&quot;) return true;\n       for(let k in tag_map)&#123;\n           let tagList &#x3D; await TopicTagRepository.getInstance().getCharacter(k);\n           let tagData &#x3D; tagList[0];\n           if(!tagData)&#123;\n               tagData &#x3D; await this.addNewTopicOneTag(topic_id, tag_map[k]);\n           &#125;\n           let topicArr &#x3D; JSON.parse(tagData.relevance_topic);\n           if(topicArr &amp;&amp; topicArr.indexOf(topic_id) &lt; 0)&#123;\n               topicArr.push(topic_id);\n               tagData.relevance_topic &#x3D; JSON.stringify(topicArr);\n               if(await TopicTagRepository.getInstance().setCharacter(tagData))&#123;&#x2F;&#x2F;更新合集作品关联\n                   let rows &#x3D; await WorksMergeRepository.getInstance().getMergeTagIds(k);\n                   for(let j &#x3D; 0; j &lt; rows.length; j++)&#123;\n                       let mergeOne &#x3D; rows[j];\n                       let rt &#x3D; JSON.parse(mergeOne.relevance_topic);\n                       if(rt &amp;&amp; rt.length &amp;&amp; rt.indexOf(topic_id) &lt; 0)&#123;\n                           rt.push(topic_id);\n                           mergeOne.relevance_topic &#x3D; JSON.stringify(rt);\n                           await WorksMergeRepository.getInstance().setMergeTopic(mergeOne);\n                       &#125;\n                   &#125;\n               &#125;\n           &#125;\n       &#125;\n       return true;\n   &#125;\n这样就将所有的关系都拆解串联了起来，达到统一。\n用户提交作品的时候获取缓存中正在使用中的话题，遍历判断下条件分配对应话题下即可\npublic static async addWorksMerge(works_id:string, owner_id:string, identity_id:string, file_type:number, topic_list:string):Promise&lt;any&gt;&#123;\n        let fileType &#x3D; &quot;&quot; + file_type;\n        let userMap &#x3D; await WorksMergeRepository.getInstance().getMergeMap();\n        let mergeList &#x3D; await WorksMergePoolRepository.getInstance().getWorkIdMerge(works_id);\n        for(let k in userMap)&#123;\n            if(userMap[k].identity_id &#x3D;&#x3D; identity_id &amp;&amp; userMap[k].file_type.indexOf(fileType) &gt;&#x3D;0 &amp;&amp; topic_list &#x3D;&#x3D; userMap[k].relevance_topic &amp;&amp; mergeList.indexOf(k) &lt; 0)&#123;\n                let opts &#x3D; &#123;\n                    merge_id:k,\n                    works_id:works_id,\n                    owner_id:owner_id,\n                    file_type:fileType,\n                    identity:identity_id,\n                    topic_tag:userMap.topic_tag,\n                    relevance_topic:userMap.relevance_topic\n                &#125;\n                WorksMergePoolRepository.getInstance().addCharacter(opts);\n            &#125;\n        &#125;\n    &#125;\n\n合集部分通过对话题标签取交集来获取当前合集下话题的关联\n&#x2F;&#x2F;取交集\n   public getMergeWorksTopic(mergeData:WorksMerge)&#123;\n       let rtMap &#x3D; typeof mergeData.relevance_topic &#x3D;&#x3D; &quot;string&quot; ? JSON.parse(mergeData.relevance_topic) : mergeData.relevance_topic;\n       let fileStr &#x3D; typeof mergeData.file_type &#x3D;&#x3D; &quot;string&quot; ? mergeData.file_type.split(&#39;,&#39;) : [];\n       let fileNum &#x3D; [];\n       for(let l &#x3D; 0; l &lt; fileStr.length; l++)&#123;\n           let str &#x3D; fileStr[l];\n           if(isNaN(Number(str)))continue;\n           fileNum.push(Number(str));\n       &#125;\n       let result:any &#x3D; &#123;&quot;merge_id&quot;:mergeData.id, &quot;topic_list&quot;:[], &quot;file_type&quot;:fileNum, &quot;identity_id&quot;:mergeData.identity, &quot;limit&quot;:1, &quot;is_good&quot;:mergeData.is_good&#125;;\n       let topic_list:any[] &#x3D; [];\n       let temp_list:any[] &#x3D; [];\n       for(let k in rtMap)&#123;\n           if(Array.isArray(rtMap[k]))\n           topic_list.push(rtMap[k]);\n       &#125;\n       if(!topic_list.length)result.limit &#x3D; 0;&#x2F;&#x2F;无限制\n       temp_list &#x3D; topic_list.shift(); \n       for(let i &#x3D; topic_list.length; i-- ;)&#123;\n           let p:any &#x3D; &#123;&#125;, obj:any &#x3D; [];\n           temp_list &#x3D; temp_list.concat(topic_list[i]).filter(function (x: string) &#123;\n               return !((x in p) ? !p[x] &amp;&amp; (p[x] &#x3D; 1) : obj.indexOf(x) &lt; 0 &amp;&amp; obj.push(x));\n           &#125;);\n           if(!temp_list.length) &#123;\n               result.topic_list &#x3D; []; \n               return result;\n           &#125;\n       &#125;\n       result.topic_list &#x3D; temp_list;\n       &#x2F;&#x2F; logger.error(&#39;topic_list:&#39;, result.topic_list);\n       return result;\n   &#125;","slug":"作品合集-多对多对多关系表","date":"2021-07-27T07:38:58.000Z","categories_index":"IT笔记","tags_index":"mysql","author_index":"Fly"},{"id":"c776e2dac8f01316cfe1fc728bbcc754","title":"node.js中常用的函数","content":"http部分\nimport fetch from &quot;node-fetch&quot;;\nimport &#123; RequestInit &#125; from &quot;node-fetch&quot;;\nimport &#123; URLSearchParams &#125; from &#39;url&#39;;\n\nexport enum ContentType &#123;\n    JSON &#x3D; &quot;application&#x2F;json&quot;,\n    FORM &#x3D; &quot;application&#x2F;x-www-form-urlencoded&quot;\n&#125;;\n\nexport enum ResponseType &#123;\n    JSON,\n    XML,\n    BUFFER_OR_JSON,\n    TEXT\n&#125;;\n\nexport async function doGet(url: string, headers?: &#123; [index: string]: string &#125;, reqFail?: (err: any) &#x3D;&gt; void,\n    responseType: ResponseType &#x3D; ResponseType.JSON) &#123;\n    let options: RequestInit &#x3D; &#123;\n        method: &quot;GET&quot;,\n        headers: &#123; &#39;Content-Type&#39;: ContentType.JSON &#125;,\n    &#125;;\n\n    if (headers) &#123;\n        Object.assign(options.headers, headers);\n    &#125;\n\n    return await doRequest(url, options, reqFail, responseType);\n&#125;\n\nexport async function doPost(url: string, body: (URLSearchParams | any), headers?: &#123; [index: string]: string &#125;,\n    reqFail?: (err: any) &#x3D;&gt; void, responseType: ResponseType &#x3D; ResponseType.JSON) &#123;\n    let options: RequestInit &#x3D; &#123;\n        method: &quot;POST&quot;\n    &#125;;\n\n    if (body &amp;&amp; body.constructor &amp;&amp; body.constructor.name &#x3D;&#x3D;&#x3D; &quot;URLSearchParams&quot;) &#123;\n        &#x2F;&#x2F; 表单类型直接赋值body\n        options.body &#x3D; body;\n        options.headers &#x3D; &#123; &#39;Content-Type&#39;: ContentType.FORM &#125;\n    &#125;\n    else &#123;\n        options.body &#x3D; JSON.stringify(body);\n        options.headers &#x3D; &#123; &#39;Content-Type&#39;: ContentType.JSON &#125;\n    &#125;\n\n    if (headers) &#123;\n        Object.assign(options.headers, headers);\n    &#125;\n\n    return await doRequest(url, options, reqFail, responseType);\n&#125;\n\nasync function doRequest(url: string, options: RequestInit, reqFail?: (err: any) &#x3D;&gt; void,\n    responseType: ResponseType &#x3D; ResponseType.JSON) &#123;\n    let fetchRes &#x3D; await fetch(url, options);\n\n    if (fetchRes.status !&#x3D; 200 &amp;&amp; fetchRes.status !&#x3D; 201) &#123;\n        try &#123;\n            if (reqFail) &#123;\n                let err &#x3D; await getError(fetchRes, responseType);\n\n                await reqFail(err);\n            &#125;\n        &#125;\n        catch &#123;\n            if (reqFail) &#123;\n                await reqFail(&#123; http_status_code: fetchRes.status, error: &#96;to json fail&#96; &#125;);\n            &#125;\n        &#125;\n\n        return undefined;\n    &#125;\n\n    let res &#x3D; undefined;\n\n    switch (responseType) &#123;\n        case ResponseType.JSON:\n            res &#x3D; await fetchRes.json();\n            break;\n        case ResponseType.XML:\n        case ResponseType.TEXT:\n            res &#x3D; await fetchRes.text()\n            break;\n        case ResponseType.BUFFER_OR_JSON:\n            if ((fetchRes.headers.get(&quot;content-type&quot;) || &quot;&quot;).includes(&quot;json&quot;)) &#123;\n                res &#x3D; await fetchRes.json();\n            &#125;\n            else &#123;\n                res &#x3D; await fetchRes.buffer();\n            &#125;\n            break;\n        default:\n            if (reqFail) &#123;\n                await reqFail(&#123; error: &#96;responseType error&#96; &#125;);\n            &#125;\n            break;\n    &#125;\n\n    return res;\n&#125;\n\nasync function getError(fetchRes: any, responseType: ResponseType) &#123;\n    let err: any &#x3D; &#123;&#125;;\n    switch (responseType) &#123;\n        case ResponseType.JSON:\n            err &#x3D; await fetchRes.json();\n            err.http_status_code &#x3D; fetchRes.status\n            break;\n        case ResponseType.XML:\n            let text &#x3D; await fetchRes.text();\n            err &#x3D; &#123; http_status_code: fetchRes.status, error: text &#125;;\n            break;\n        default:\n            err &#x3D; &#123; http_status_code: fetchRes.status, error: &#96;responseType error&#96; &#125;\n            break;\n    &#125;\n    return err;\n&#125;\n\n\nimport fetch from &quot;node-fetch&quot;;\nimport &#123; URL &#125; from &#39;url&#39;;\nimport &#123; RequestInit &#125; from &quot;node-fetch&quot;;\nimport logger &#x3D; require(&quot;.&#x2F;logger&quot;);\nconst FormData &#x3D; require(&#39;form-data&#39;);\n&#x2F;&#x2F; import &#123; URLSearchParams &#125; from &#39;url&#39;;\n\nexport function requestParam(url: string, method?: string, params?: any, headers?: any): Promise&lt;any&gt; &#123;\n    let form &#x3D; new FormData();\n    headers &#x3D; headers || form.getHeaders();\n    for (let key in params) &#123;\n        form.append(key, params[key]);\n    &#125;\n    return request(url, method, form, headers);\n&#125;\n\nexport function checkUrl(url: string) &#123;\n    try &#123;\n        let parsedURL &#x3D; new URL(url);\n        logger.info(&#39;url protocol:[%s] host:%s port:%s hostname:%s, path:%s&#39;, parsedURL.protocol, parsedURL.host, parsedURL.port, parsedURL.hostname, parsedURL.pathname);\n\n    &#125; catch (err) &#123;\n        logger.error(&#39;url:%s invoid, err:%j&#39;, url, err.message);\n    &#125;\n&#125;\n\nexport function request(url: string, method?: string, data?: any, headers?: any): Promise&lt;any&gt; &#123;\n    let options: RequestInit &#x3D; &#123;\n        method: method || &#39;GET&#39;,\n        headers: headers || &#123; &#39;Content-Type&#39;: &quot;application&#x2F;json&quot; &#125;\n    &#125;;\n    if (data) &#123;\n        options.body &#x3D; data;\n    &#125;\n    &#x2F;&#x2F;check url\n    &#x2F;&#x2F; checkUrl(url);\n\n    return new Promise((resolve, reject) &#x3D;&gt; &#123;\n        fetch(url, options).then(resp &#x3D;&gt; &#123;\n            if (resp.status !&#x3D; 200) &#123;\n                return reject(&#39;request status:&#39; + resp.status);\n            &#125;\n            &#x2F;&#x2F;尝试以json结果返回\n            resp.json().then(data &#x3D;&gt; &#123;\n                resolve(data);\n            &#125;).catch(_ &#x3D;&gt; &#123;\n                &#x2F;&#x2F;尝试以text结果返回\n                resp.text().then(data &#x3D;&gt; &#123;\n                    resolve(data);\n                &#125;).catch(error &#x3D;&gt; &#123;\n                    return reject(error);\n                &#125;);\n            &#125;)\n        &#125;).catch(err &#x3D;&gt; &#123;\n            return reject(err);\n        &#125;);\n    &#125;);\n&#125;\n\n加密部分\nmd5(data: string) &#123;\n    &#x2F;&#x2F; 以md5的格式创建一个哈希值\n    let hash &#x3D; crypto.createHash(&#39;md5&#39;);\n    return hash.update(data).digest(&#39;hex&#39;);\n&#125;,\nsha1(data: string) &#123;\n    &#x2F;&#x2F; 以md5的格式创建一个哈希值\n    let hash &#x3D; crypto.createHash(&#39;sha1&#39;);\n    return hash.update(data).digest(&#39;hex&#39;);\n&#125;,\nhmac(data: string, key: string, upperCase: boolean &#x3D; false) &#123;\n    if (!key) &#123;\n        throw &#39;invoid hmac &quot;key&quot; params.&#39;\n    &#125;\n    &#x2F;&#x2F; 以md5的格式创建一个哈希值\n    const hash &#x3D; crypto.createHmac(&#39;md5&#39;, key);\n    let result &#x3D; hash.update(data).digest(&#39;hex&#39;);\n    return upperCase ? result.toUpperCase() : result;\n&#125;,\nhmac_sha1(data:string, key:string)&#123;\n    return Base64.stringify((HmacSha1(data,key)));\n&#125;,\n&#x2F;** base64编码 *&#x2F;\nencodeBase64(str: string) &#123;\n    if (!str) &#123;\n        return &quot;&quot;\n    &#125;\n    let buff &#x3D; iconv.encode(str, &#39;utf8&#39;);\n    return iconv.decode(buff, &#39;base64&#39;);\n&#125;,\n\n时间部分\n&#x2F;**\n * 获取指定整点的时间\n *&#x2F;\nexport function getGivenHour(dateVal: Date, hour: number) &#123;\n    let t &#x3D; new Date(dateVal.getFullYear(), dateVal.getMonth(), dateVal.getDate(), hour);\n    return t;\n&#125;\n\n&#x2F;**\n * 获取本月第一天的时间\n *&#x2F;\nexport function getMonthFirstDay(dateVal: Date) &#123;\n    let t &#x3D; new Date(dateVal.getFullYear(), dateVal.getMonth(), 1);\n    return t;\n&#125;\n\nexport function getThirtyDay(dateVal: Date): number &#123;\n    let t &#x3D; new Date(dateVal.getFullYear(), dateVal.getMonth(), dateVal.getDate());\n    let time &#x3D; t.getTime() - 30 * 24 * 60 * 60 * 1000\n    return time;\n&#125;\n\n&#x2F;**\n * 获取下个月第一天的时间\n *&#x2F;\nexport function getNextMonthFirstDay(dateVal: Date) &#123;\n    let t &#x3D; new Date(dateVal.getFullYear(), dateVal.getMonth() + 1, 1);\n    return t;\n&#125;\n\n&#x2F;**\n * 一天的毫秒数\n *&#x2F;\nexport function getDayMs() &#123;\n    return 86400000;\n&#125;\n\n&#x2F;**\n * 获取本周第一天的时间\n *&#x2F;\nexport function getWeekFirstDay(dateVal: Date) &#123;\n    let day &#x3D; getDay(dateVal);\n\n    let dnum &#x3D; dateVal.getTime() - ((day - 1) * getDayMs());\n    let d &#x3D; new Date(dnum);\n    return getGivenHour(d, 0);\n&#125;\n\n&#x2F;**\n * 获取下个周第一天的时间\n *&#x2F;\nexport function getNextWeekFirstDay(dateVal: Date) &#123;\n    let day &#x3D; getDay(dateVal);\n\n    let dnum &#x3D; dateVal.getTime() + ((8 - day) * getDayMs());\n    let d &#x3D; new Date(dnum);\n    return getGivenHour(d, 0);\n&#125;\n\n&#x2F;**\n * 获取day，周日转为7\n * 周一：1，周二：2，周三：3，周四：4，周五：5，周六：6，周日：7\n *&#x2F;\nfunction getDay(dateVal: Date) &#123;\n    let day &#x3D; dateVal.getDay();\n    day &#x3D; day &#x3D;&#x3D; 0 ? 7 : day;\n    return day;\n&#125;\n\n&#x2F;**\n * 取当前时间(秒)\n *&#x2F;\nexport function now(): number &#123;\n    return Math.floor(Date.now() &#x2F; 1000);\n&#125;\n\n&#x2F;**\n * 时间戳转日期\n * @param date\n *&#x2F;\nexport function dateFormat(date: Date, fmtEnum: FmtOpsion): string &#123;\n    let o: Map&lt;string, number&gt; &#x3D; new Map()\n        .set(&quot;M+&quot;, date.getMonth() + 1)\n        .set(&quot;d+&quot;, date.getDate())\n        .set(&quot;H+&quot;, date.getHours())\n        .set(&quot;m+&quot;, date.getMinutes())\n        .set(&quot;s+&quot;, date.getSeconds())\n        .set(&quot;q+&quot;, Math.floor((date.getMonth() + 3) &#x2F; 3))   &#x2F;&#x2F; 季度\n        .set(&quot;S&quot;, date.getMilliseconds()); &#x2F;&#x2F; 毫秒\n\n    let fmt &#x3D; fmtEnum.toString();\n    if (new RegExp(&#x2F;(y+)&#x2F;).test(fmt)) &#123;\n        fmt &#x3D; fmt.replace(RegExp.$1, (date.getFullYear() + &quot;&quot;).substr(4 - RegExp.$1.length));\n    &#125;\n\n    o.forEach((_val, k) &#x3D;&gt; &#123;\n        if (new RegExp(&quot;(&quot; + k + &quot;)&quot;).test(fmt)) &#123;\n            let val &#x3D; (o.get(k) || &quot;&quot;).toString();\n            fmt &#x3D; fmt.replace(RegExp.$1, (RegExp.$1.length &#x3D;&#x3D; 1) ? (val) : ((&quot;00&quot; + val).substr((&quot;&quot; + val).length)));\n        &#125;\n    &#125;);\n\n    return fmt;\n&#125;\n\nexport enum FmtOpsion &#123;\n    longDateTime &#x3D; &quot;yyyy-MM-dd HH:mm:ss&quot;,\n    shortDateTime &#x3D; &quot;yyyy-MM-dd&quot;\n&#125;\n\nexport function getLongDateTime(date: Date &#x3D; new Date()) &#123;\n    return dateFormat(date, FmtOpsion.longDateTime);\n&#125;\n\n数据结构部分\nexport function ListToMap(list: any[], predicate: (item: any) &#x3D;&gt; any) &#123;\n    let map &#x3D; new Map&lt;any, any&gt;();\n\n    for (let i &#x3D; 0; i &lt; list.length; i++) &#123;\n        let item &#x3D; list[i];\n        let key &#x3D; predicate(item);\n        map.set(key, item);\n    &#125;\n\n    return map;\n&#125;","slug":"node-js中常用的函数","date":"2021-07-07T06:33:31.000Z","categories_index":"IT笔记","tags_index":"node.js","author_index":"Fly"},{"id":"2debb017808112f7c6dc95c7509d53b7","title":"加薪秘籍","content":"题目：从 innodb 的索引结构分析，为什么索引的 key 长度不能太长？key 太长会导致一个页当中能够存放的 key 的数目变少，间接导致索引树的页数目变多，索引层次增加，从而影响整体查询变更的效率。\n题目：请解释下为什么鹿晗发布恋情的时候，微博系统会崩溃，如何解决？A. 获取微博通过 pull 方式还是 push 方式\nB. 发布微博的频率要远小于阅读微博\nC. 流量明星的发微博，和普通博主要区分对待，比如在 sharding的时候，也要考虑这个因素\n题目：引用与指针有什么区别？引用与指针区别：引用只是取得数据,无权修改,句柄就是一种引用的方式；指针是直接指向内存的,可以修改数据的。　　引用访问一个变量是直接访问，而指针是间接访问。　　引用是一个变量的别名，本身不单独分配自己的内存空间，而指针有自己的内存空间。　　引用在开始的时候就绑定到了一个内存空间(开始必须赋初值),所以他只能是这个内存空间的名字,而不能改成其他的,当然可以改变这个内存空间的值.\n题目：mysql为什么要用b+树，不用平衡二叉树做索引结构平衡二叉树\n1.非叶子节点最多拥有两个子节点。\n2.非叶子节值大于左边子节点、小于右边子节点。\n3.树的左右两边的层级数相差不会大于1。\n4.没有值相等重复的节点。\n大规模数据存储的时候，平衡二叉树往往出现由于树的深度过大而造成磁盘IO读写过于频繁B+树只有叶节点存放数据，其余节点用来索引,索引也会被存储在磁盘上,层数很少,B+树天然具备排序功能,查询速度更稳定\n\n\n题目：多线程的优缺点(1)多线程技术使程序的响应速度更快 ,因为用户界面可以在进行其它工作的同时一直处于活动状态;\n(2)当前没有进行处理的任务时可以将处理器时间让给其它任务;\n(3)占用大量处理时间的任务可以定期将处理器时间让给其它任务;\n(4)可以随时停止任务;\n(5)可以分别设置各个任务的优先级以优化性能。是否需要创建多个线程取决于各种因素。在以下情况下,最适合采用多线程处理:(1)耗时或大量占用处理器的任务阻塞用户界面操作;\n(2)各个任务必须等待外部资源 (如远程文件或 Internet连接)。\n缺点：(1)等候使用共享资源时造成程序的运行速度变慢。这些共享资源主要是独占性的资源 ,如打印机等。\n(2)对线程进行管理要求额外的 CPU开销。线程的使用会给系统带来上下文切换的额外负担。当这种负担超过一定程度时,多线程的特点主要表现在其缺点上,比如用独立的线程来更新数组内每个元素。\n(3)线程的死锁。即较长时间的等待或资源竞争以及死锁等多线程症状。\n(4)对公有变量的同时读或写。当多个线程需要对公有变量进行写操作时,后一个线程往往会修改掉前一个线程存放的数据,从而使前一个线程的参数被修改;另外 ,当公用变量的读写操作是非原子性时,在不同的机器上,中断时间的不确定性,会导致数据在一个线程内的操作产生错误,从而产生莫名其妙的错误,而这种错误是程序员无法预知的。\n题目：数据库范式1.数据库表的每一列都是不可分割的基本数据项，同一列中不能有多个值2.要求数据库表中的每个实例或行必须可以被惟一地区分（主键）3.要求一个数据库表中不包含已在其它表中已包含的非主关键字信息（不要有重复一样属性的在别的表中）\n题目：堆栈溢出一般是由什么原因导致的？1.函数调用层次太深。函数递归调用时，系统要在栈中不断保存函数调用时的现场和产生的变量，如果递归调用太深，就会造成栈溢出，这时递归无法返回。再有，当函数调用层次过深时也可能导致栈无法容纳这些调用的返回地址而造成栈溢出。2.动态申请空间使用之后没有释放。由于C语言中没有垃圾资源自动回收机制，因此，需要程序主动释放已经不再使用的动态地址空间。申请的动态空间使用的是堆空间，动态空间使用不会造成堆溢出。3.数组访问越界。C语言没有提供数组下标越界检查，如果在程序中出现数组下标访问超出数组范围，在运行过程中可能会内存访问错误。4.指针非法访问。指针保存了一个非法的地址，通过这样的指针访问所指向的地址时会产生内存访问错误。\n题目：\n","slug":"加薪秘籍","date":"2021-07-01T06:58:40.000Z","categories_index":"IT笔记","tags_index":"面试","author_index":"Fly"},{"id":"7b15f460606fcb4d23e6a93344af8c37","title":"算法","content":"最常用的几种算法1.快速排序快速排序的最坏运行情况是 O(n²)，比如说顺序数列的快排。但它的平摊期望时间是 O(nlogn)，且 O(nlogn) 记号中隐含的常数因子很小，比复杂度稳定等于 O(nlogn) 的归并排序要小很多。所以，对绝大多数顺序性较弱的随机数列而言，快速排序总是优于归并排序\nfunction quickSort(arr, left, right) &#123;\n    var len &#x3D; arr.length,\n        partitionIndex,\n        left &#x3D; typeof left !&#x3D; &#39;number&#39; ? 0 : left,\n        right &#x3D; typeof right !&#x3D; &#39;number&#39; ? len - 1 : right;\n\n    if (left &lt; right) &#123;\n        partitionIndex &#x3D; partition(arr, left, right);\n        quickSort(arr, left, partitionIndex-1);\n        quickSort(arr, partitionIndex+1, right);\n    &#125;\n    return arr;\n&#125;\n\nfunction partition(arr, left ,right) &#123;     &#x2F;&#x2F; 分区操作\n    var pivot &#x3D; left,                      &#x2F;&#x2F; 设定基准值（pivot）\n        index &#x3D; pivot + 1;\n    for (var i &#x3D; index; i &lt;&#x3D; right; i++) &#123;\n        if (arr[i] &lt; arr[pivot]) &#123;\n            swap(arr, i, index);\n            index++;\n        &#125;        \n    &#125;\n    swap(arr, pivot, index - 1);\n    return index-1;\n&#125;\n\nfunction swap(arr, i, j) &#123;\n    var temp &#x3D; arr[i];\n    arr[i] &#x3D; arr[j];\n    arr[j] &#x3D; temp;\n&#125;\nfunction partition2(arr, low, high) &#123;\n  let pivot &#x3D; arr[low];\n  while (low &lt; high) &#123;\n    while (low &lt; high &amp;&amp; arr[high] &gt; pivot) &#123;\n      --high;\n    &#125;\n    arr[low] &#x3D; arr[high];\n    while (low &lt; high &amp;&amp; arr[low] &lt;&#x3D; pivot) &#123;\n      ++low;\n    &#125;\n    arr[high] &#x3D; arr[low];\n  &#125;\n  arr[low] &#x3D; pivot;\n  return low;\n&#125;\n\nfunction quickSort2(arr, low, high) &#123;\n  if (low &lt; high) &#123;\n    let pivot &#x3D; partition2(arr, low, high);\n    quickSort2(arr, low, pivot - 1);\n    quickSort2(arr, pivot + 1, high);\n  &#125;\n  return arr;\n&#125;\n\n\n2.冒泡排序O(n²)\nfunction bubbleSort(arr) &#123;\n    var len &#x3D; arr.length;\n    for (var i &#x3D; 0; i &lt; len - 1; i++) &#123;\n        for (var j &#x3D; 0; j &lt; len - 1 - i; j++) &#123;\n            if (arr[j] &gt; arr[j+1]) &#123;        &#x2F;&#x2F; 相邻元素两两对比\n                var temp &#x3D; arr[j+1];        &#x2F;&#x2F; 元素交换\n                arr[j+1] &#x3D; arr[j];\n                arr[j] &#x3D; temp;\n            &#125;\n        &#125;\n    &#125;\n    return arr;\n&#125;\n\n3.归并排序O(nlogn) 的时间复杂度。代价是需要额外的内存空间。申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列；\n设定两个指针，最初位置分别为两个已经排序序列的起始位置；\n比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置；\n重复步骤 3 直到某一指针达到序列尾；\n将另一序列剩下的所有元素直接复制到合并序列尾。\nfunction mergeSort(arr) &#123;  &#x2F;&#x2F; 采用自上而下的递归方法\n    var len &#x3D; arr.length;\n    if(len &lt; 2) &#123;\n        return arr;\n    &#125;\n    var middle &#x3D; Math.floor(len &#x2F; 2),\n        left &#x3D; arr.slice(0, middle),\n        right &#x3D; arr.slice(middle);\n    return merge(mergeSort(left), mergeSort(right));\n&#125;\n\nfunction merge(left, right)\n&#123;\n    var result &#x3D; [];\n\n    while (left.length &amp;&amp; right.length) &#123;\n        if (left[0] &lt;&#x3D; right[0]) &#123;\n            result.push(left.shift());\n        &#125; else &#123;\n            result.push(right.shift());\n        &#125;\n    &#125;\n\n    while (left.length)\n        result.push(left.shift());\n\n    while (right.length)\n        result.push(right.shift());\n\n    return result;\n&#125;\n\n4.选择排序首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。\n再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。\n重复第二步，直到所有元素均排序完毕。无论什么数据进去都是 O(n²) 的时间复杂度\nfunction selectionSort(arr) &#123;\n    var len &#x3D; arr.length;\n    var minIndex, temp;\n    for (var i &#x3D; 0; i &lt; len - 1; i++) &#123;\n        minIndex &#x3D; i;\n        for (var j &#x3D; i + 1; j &lt; len; j++) &#123;\n            if (arr[j] &lt; arr[minIndex]) &#123;     &#x2F;&#x2F; 寻找最小的数\n                minIndex &#x3D; j;                 &#x2F;&#x2F; 将最小数的索引保存\n            &#125;\n        &#125;\n        temp &#x3D; arr[i];\n        arr[i] &#x3D; arr[minIndex];\n        arr[minIndex] &#x3D; temp;\n    &#125;\n    return arr;\n&#125;\n\n5.插入排序将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。\n从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。）O(N^(1-2))\nfunction insertionSort(arr) &#123;\n    var len &#x3D; arr.length;\n    var preIndex, current;\n    for (var i &#x3D; 1; i &lt; len; i++) &#123;\n        preIndex &#x3D; i - 1;\n        current &#x3D; arr[i];\n        while(preIndex &gt;&#x3D; 0 &amp;&amp; arr[preIndex] &gt; current) &#123;\n            arr[preIndex+1] &#x3D; arr[preIndex];\n            preIndex--;\n        &#125;\n        arr[preIndex+1] &#x3D; current;\n    &#125;\n    return arr;\n&#125;\n\n6.桶排序桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。为了使桶排序更加高效，我们需要做到这两点：\n在额外空间充足的情况下，尽量增大桶的数量使用的映射函数能够将输入的 N 个数据均匀的分配到 K 个桶中同时，对于桶中元素的排序，选择何种比较排序算法对于性能的影响至关重要。\n\n什么时候最快当输入的数据可以均匀的分配到每一个桶中。O(n)\n\n什么时候最慢当输入的数据被分配到了同一个桶中。时间复杂度为O(nlogn)\nfunction bucketSort(arr, bucketSize) &#123;\n    if (arr.length &#x3D;&#x3D;&#x3D; 0) &#123;\n      return arr;\n    &#125;\n\n    var i;\n    var minValue &#x3D; arr[0];\n    var maxValue &#x3D; arr[0];\n    for (i &#x3D; 1; i &lt; arr.length; i++) &#123;\n      if (arr[i] &lt; minValue) &#123;\n          minValue &#x3D; arr[i];                &#x2F;&#x2F; 输入数据的最小值\n      &#125; else if (arr[i] &gt; maxValue) &#123;\n          maxValue &#x3D; arr[i];                &#x2F;&#x2F; 输入数据的最大值\n      &#125;\n    &#125;\n\n    &#x2F;&#x2F;桶的初始化\n    var DEFAULT_BUCKET_SIZE &#x3D; 5;            &#x2F;&#x2F; 设置桶的默认数量为5,理论上有多少数有多少桶最快，时间复杂度为O(n)\n    bucketSize &#x3D; bucketSize || DEFAULT_BUCKET_SIZE;\n    var bucketCount &#x3D; Math.floor((maxValue - minValue) &#x2F; bucketSize) + 1;  \n    var buckets &#x3D; new Array(bucketCount);\n    for (i &#x3D; 0; i &lt; buckets.length; i++) &#123;\n        buckets[i] &#x3D; [];\n    &#125;\n\n    &#x2F;&#x2F;利用映射函数将数据分配到各个桶中\n    for (i &#x3D; 0; i &lt; arr.length; i++) &#123;\n        buckets[Math.floor((arr[i] - minValue) &#x2F; bucketSize)].push(arr[i]);\n    &#125;\n\n    arr.length &#x3D; 0;\n    for (i &#x3D; 0; i &lt; buckets.length; i++) &#123;\n        insertionSort(buckets[i]);                      &#x2F;&#x2F; 对每个桶进行排序，这里使用了插入排序\n        for (var j &#x3D; 0; j &lt; buckets[i].length; j++) &#123;\n            arr.push(buckets[i][j]);                      \n        &#125;\n    &#125;\n\n    return arr;\n&#125;\n\n","slug":"算法","date":"2021-06-23T07:06:23.000Z","categories_index":"IT笔记","tags_index":"算法","author_index":"Fly"},{"id":"9d448e38833c6c56c1bb282d7671bf10","title":"微信Baidu审核对接方案实现","content":"微信和百度都有文字及图片视频啥的AI审核接口，文字审核这里就不说了，时间短也比较快，唯一缺点是测试版每秒的并发最多5个，在并发的情况下会出现未审核，有钱的可以升级付费版，没钱的可以在比较空闲的进程中对未审核的作品和评论，进行2次审核，起一个定时器半小时或者1小时来做\n下面着重说下图片审核，至于视频及其他的大文件类似\n百度审核图片分为2种，1种是图片下载地址的方式，1种是图片base64字符串，第一种方式依据下载图片的大小等因素变动比较大，普遍在2秒左右，所以顺序执行会阻塞当前进程，所以也得并行异步审核，审核结束去更新审核状态。第二种方式base64字符串，那么这里涉及的一个问题，图片如果保存在服务端本地必然占用空间，也不好管理（定期删除啥的），全依赖客户端传图片的网络消耗也比较大，所以用异步下载在直接取BUFFER数据base64转字符串就比较合适，当然存本地临时文件会更快，具体可以根据不同方案来定。\n微信审核图片只有1种，就是图片的buffer数据完整审核，性能也比较快，所以服务端的问题也是选择下载还是存临时文件读取临时文件来做审核，可根据需求来定\n具体实现代码如下\nexport async function check(consumer: any, msg: any, _msgObject: any) &#123;\n    &#x2F;&#x2F; consumer.shift(); &#x2F;&#x2F; 回复写入成功\n    const AiTypeMap:any &#x3D; &#123;&#39;1&#39;:&#123;&#39;1&#39;:true,&#39;10&#39;:true,&#39;13&#39;:true&#125;,&#39;4&#39;:&#123;&#39;1&#39;:true,&#39;6&#39;:true&#125;&#125;;&#x2F;&#x2F;AI审核类型初始\n    let files &#x3D; msg.files || [];\n    let id &#x3D; msg.id || &#39;&#39;;\n    let platform_id &#x3D; msg.platform_id || &#39;&#39;;\n    const wx &#x3D; &quot;103&quot;;&#x2F;&#x2F;微信小程序渠道号\n    if (!files || !files.length || !id) &#123;\n        logger.error(&quot;error checkImgSync&quot;);\n        consumer.shift(); &#x2F;&#x2F; 回复写入成功\n        return\n    &#125;\n    let errFlag &#x3D; false;\n    let imgSensitivePlugin &#x3D; pomelo.app.get(&#39;imgSensitiveService&#39;);\n    for(let i &#x3D; 0;files &amp;&amp; i &lt; files.length; i++)&#123;\n        let path &#x3D; files[i][&#39;path&#39;] || &#39;&#39;;\n        let n_type &#x3D; files[i][&#39;n_type&#39;] || 0;\n        let fileName &#x3D; files[i][&#39;fileName&#39;] || &#39;&#39;;\n        let result:any &#x3D; &#123;conclusionType : 2&#125;;\n        let pos &#x3D; fileName.indexOf(&#39;.&#39;);\n        let type &#x3D; fileName.substring(pos+1,fileName.length);\n        if(n_type &#x3D;&#x3D; 1)&#123;&#x2F;&#x2F;图片\n            if(platform_id &#x3D;&#x3D; wx)&#123;\n                let binaryData &#x3D; await downImg(path);\n                if(binaryData)&#123;\n                    let wxResult &#x3D; await wxImgCheck(binaryData, type);\n                    if(wxResult)&#123;\n                        let  base64Img &#x3D; binaryData.toString(&#39;base64&#39;);\n                        result &#x3D; await baiduImgCheck(base64Img, type);\n                    &#125;else&#123;&#x2F;&#x2F;审核不通过\n                        errFlag &#x3D; true;\n                        break;\n                    &#125;\n                &#125;\n            &#125;else&#123;\n                result &#x3D; await baiduImgPathCheck(path, type);\n            &#125;\n           \n            &#x2F;&#x2F; if(result)&#123;&#x2F;&#x2F;测试\n            if(result.conclusionType !&#x3D; 1 &amp;&amp; result.data)&#123;\n                let list &#x3D; result.data;\n                for(let l &#x3D;0; l &lt; list.length; l++)&#123;\n                    if(AiTypeMap[list[0][&#39;type&#39;]] &amp;&amp; AiTypeMap[list[0][&#39;type&#39;]][list[0][&#39;subType&#39;]])&#123;\n                        continue;\n                    &#125;else&#123;\n                        errFlag &#x3D; true;\n                        break;\n                    &#125;\n                &#125;\n            &#125;\n            if(errFlag)break;\n        &#125;\n    &#125;\n    if(!errFlag)&#123;\n        await imgSensitivePlugin.update(id);&#x2F;&#x2F;更新缓存及db数据\n    &#125;\n    consumer.shift(); &#x2F;&#x2F; 回复写入成功\n&#125;\n\n\n//百度图片路径审核\nasync function baiduImgPathCheck(path: string, type:string): Promise&lt;any&gt; &#123;\n    let imgSensitivePlugin &#x3D; pomelo.app.get(&#39;imgSensitiveService&#39;);\n    return new Promise((resolve, _reject) &#x3D;&gt; &#123;\n        imgSensitivePlugin.checkPath(path, type).then((res: any) &#x3D;&gt; &#123;\n            resolve(res);\n        &#125;).catch((_err: any) &#x3D;&gt; &#123;\n            logger.error(&#39;checkImg error error:%s&#39;, _err)\n            let data &#x3D; &#123;conclusionType : 2&#125;;\n            resolve(data)\n        &#125;)\n    &#125;);\n&#125;\n//百度图片审核\nasync function baiduImgCheck(binaryData: any, type:string): Promise&lt;any&gt; &#123;\n    let imgSensitivePlugin &#x3D; pomelo.app.get(&#39;imgSensitiveService&#39;);\n    return new Promise((resolve, _reject) &#x3D;&gt; &#123;\n        imgSensitivePlugin.checkImg(binaryData, type).then((res: any) &#x3D;&gt; &#123;\n            resolve(res);\n        &#125;).catch((_err: any) &#x3D;&gt; &#123;\n            logger.error(&#39;checkImg error error:%s&#39;, _err)\n            let data &#x3D; &#123;conclusionType : 2&#125;;\n            resolve(data)\n        &#125;)\n    &#125;);\n&#125;\n//微信图片审核\nasync function wxImgCheck(binaryData: any, type:string): Promise&lt;any&gt; &#123;\n    let imgSensitivePlugin &#x3D; pomelo.app.get(&#39;imgSensitiveService&#39;);\n    return new Promise((resolve, _reject) &#x3D;&gt; &#123;\n        imgSensitivePlugin.wxCheckImg(binaryData, type).then((res: any) &#x3D;&gt; &#123;\n            if(res &amp;&amp; res.errcode  &#x3D;&#x3D; 0)&#123;\n                resolve(true);\n            &#125;\n            resolve(false);\n        &#125;).catch((_err: any) &#x3D;&gt; &#123;\n            logger.error(&#39;wxCheck error error:%s&#39;, JSON.stringify(_err));\n            let data &#x3D; false;\n            resolve(data)\n        &#125;)\n    &#125;);\n&#125;\n//下载图片\nasync function downImg(path: string): Promise&lt;any&gt; &#123;\n    let imgSensitivePlugin &#x3D; pomelo.app.get(&#39;imgSensitiveService&#39;);\n    return new Promise((resolve, _reject) &#x3D;&gt; &#123;\n        imgSensitivePlugin.downImg(path).then((res: any) &#x3D;&gt; &#123;\n            resolve(res);\n        &#125;).catch((_err: any) &#x3D;&gt; &#123;\n            logger.error(&#39;downImg error error:%s&#39;, _err)\n            let data &#x3D; null;\n            resolve(data)\n        &#125;)\n    &#125;);\n&#125;\n下载图片异步下载下载完成后将图片数据保存或者直接使用，不用promise就是异步下载，但是因为审核需要逐一审核所以使用选择顺序执行，也可以异步下载保存后再需要使用的时候读取来使用\npublic downImg(path:string)&#123;\n        return new Promise((resolve, reject)&#x3D;&gt;&#123;\n            https.request(path, function(response) &#123;                                       \n                var data &#x3D; new stream.Transform();                                                   \n             \n                response.on(&#39;data&#39;, function(chunk) &#123;                                      \n                    data.push(chunk);                                 \n                &#125;); \n               \n                response.on(&#39;error&#39;, function(err) &#123;                                      \n                    return reject(err);                                       \n                &#125;); \n             \n                response.on(&#39;end&#39;, function() &#123;  \n                    &#x2F;&#x2F; fs.writeFileSync(&#39;image.png&#39;, data.read()); \n                    return resolve(data.read());                                                              \n                &#125;);                                                                        \n            &#125;).end();\n        &#125;); \n    &#125;\nbaidu的路径和图片两种审核方式区别就一个参数image:imgData,换成imgUrl:path\n&#x2F;**\n     * 检查图片\n     * @param imgData 图片二进制数据\n     * @see https:&#x2F;&#x2F;ai.baidu.com&#x2F;ai-doc&#x2F;ANTIPORN&#x2F;jk42xep4e\n     * @see http:&#x2F;&#x2F;wiki.bigdata.99.com&#x2F;bin&#x2F;view&#x2F;%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F&#x2F;AI%E6%95%8F%E6%84%9F%E8%AF%8D%E6%A8%A1%E5%9D%97&#x2F;\n     *&#x2F;\n     public async checkImg(imgData: any, type:string): Promise&lt;any&gt; &#123;\n        let conf &#x3D; this.app.get(&#39;imgSensitiveConfig&#39;);\n        if (!imgData) &#123;\n            throw &#39;invalid params &quot;checkImg&quot;.&#39;\n        &#125;\n        let url &#x3D;  conf.url || &#39;http:&#x2F;&#x2F;apiproxy.debug.web.nd&#x2F;v0.2&#x2F;&#39;,\n            ai_method &#x3D; conf.ai_method || &#39;visitor&#x2F;forwards&#x2F;baidu&#x2F;img_censor&#39;,\n            baidu_app_id &#x3D; conf.baidu_app_id || &#39;&#39;, &#x2F;&#x2F;增加应用自定义的敏感词库导入\n            baidu_api_key &#x3D; conf.baidu_api_key || &#39;&#39;,\n            baidu_secret_key &#x3D; conf.baidu_secret_key || &#39;&#39;;\n        let imgType &#x3D; type &#x3D;&#x3D; &quot;gif&quot; ? 1 : 0;\n        let data &#x3D; &#123;\n            baidu_app_id: baidu_app_id,\n            baidu_api_key:baidu_api_key,\n            baidu_secret_key:baidu_secret_key,\n            image:imgData,\n            imgType:imgType\n        &#125;\n        url &#x3D; url + ai_method;\n        return this.request(url, &#39;POST&#39;, data, baidu_app_id);\n    &#125;\nwx审核参数比较重要缺1不可，错误码41005一定是参数有误，41001一定是access_token不对\n&#x2F;**\n     * 微信检查图片\n     * @param imgData 图片二进制数据\n     * @see https:&#x2F;&#x2F;developers.weixin.qq.com&#x2F;miniprogram&#x2F;dev&#x2F;api-backend&#x2F;open-api&#x2F;sec-check&#x2F;security.imgSecCheck.html\n     * @see http:&#x2F;&#x2F;wiki.bigdata.99.com&#x2F;bin&#x2F;view&#x2F;%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F&#x2F;AI%E6%95%8F%E6%84%9F%E8%AF%8D%E6%A8%A1%E5%9D%97&#x2F;\n     *&#x2F;\n     public async wxCheckImg(imgData: any, type:string): Promise&lt;any&gt; &#123;\n        let conf &#x3D; this.app.get(&#39;imgSensitiveConfig&#39;);\n        if (!Buffer.isBuffer(imgData)) &#123;\n            throw &#39;invalid params &quot;wxCheckImg&quot;.&#39;\n        &#125;\n        let access_token &#x3D; await this.getWxAccessToken();\n        let checkUrl &#x3D; conf.wx_check_url || &quot;https:&#x2F;&#x2F;api.weixin.qq.com&#x2F;wxa&#x2F;&quot;;\n        checkUrl +&#x3D; &quot;img_sec_check?access_token&#x3D;&quot; + access_token;\n        return this.requestFrom(checkUrl, &#39;POST&#39;, imgData, &quot;image&#x2F;&quot;+type, &quot;1.png&quot;);\n    &#125;\nprivate async requestFrom(url: string, method: string, data: any, typeStr:string, fileName:string): Promise&lt;any&gt; &#123;\n        let formData &#x3D; new FormData();\n        formData.append(&#39;media&#39;, data, &#123;filename:fileName, contentType: typeStr&#125;);&#x2F;&#x2F;media必须是key,fileName必须要有\n        let resp &#x3D; await fetch(url, &#123; method: method, body: formData, headers: formData.getHeaders() &#125;);\n        return new Promise((resolve, reject) &#x3D;&gt; &#123;\n            if (!resp || resp.status !&#x3D; 200) &#123;\n                logger.warn(&#96;imgSnsitive $&#123;method&#125; $&#123;url&#125; body:%j&#96;, data);\n                let status &#x3D; resp &amp;&amp; resp.status || 0;\n                resp.json().then(res &#x3D;&gt; &#123;\n                    logger.warn(&#96;sensitive resp:%s res:%j&#96;, status, res);\n                &#125;);\n                return reject(&#39;sensitive resp status:&#39; + status);\n            &#125;\n            &#x2F;&#x2F; resolve(resp.json());\n            &#x2F;&#x2F;尝试以json结果返回\n            resp.json().then(data &#x3D;&gt; &#123;\n                resolve(data);\n            &#125;).catch(_ &#x3D;&gt; &#123;\n                &#x2F;&#x2F;尝试以text结果返回\n                resp.text().then(data &#x3D;&gt; &#123;\n                    resolve(data);\n                &#125;).catch(error &#x3D;&gt; &#123;\n                    return reject(error);\n                &#125;);\n            &#125;)\n        &#125;);\n    &#125;","slug":"微信baidu审核对接方案实现","date":"2021-05-10T10:03:17.000Z","categories_index":"IT笔记","tags_index":"node.js","author_index":"Fly"},{"id":"000e187a17a937440770c60b6bdf94f6","title":"Skynet","content":"Skynet 是一个基于 Actor 模式的开源并发框架。\nskynet 节点，通过 master ，认识网络中所有其它 skynet 节点。它们相互一一建立单向通讯通道。也就是说，如果一共有 100 个 skynet 节点，在它们启动完毕后，会建立起 1 万条通讯通道。\n这个系统是单进程多线程模型。\n1.安装linux下\nyum install git\n\nyum -y install autoconf\n\nyum -y install  readline-devel\n\ngit clone https:&#x2F;&#x2F;github.com&#x2F;cloudwu&#x2F;skynet.git\n\ncd skynet\nmake linux\nmac下\nbrew install autoconf\ngit clone https:&#x2F;&#x2F;github.com&#x2F;cloudwu&#x2F;skynet.git\n\ncd skynet\nmake macosx\n启动\n.&#x2F;skynet examples&#x2F;config\t#开启服务端节点\n.&#x2F;3rd&#x2F;lua&#x2F;lua examples&#x2F;client.lua \t#开启客户端测试\n\n2.编写其中的服务2.1 c服务service-src中为c服务的位置编写出基本的构造逻辑函数后需要在Makefile中CSERVICE = 后面加上对应的模块名，然后出来编译后出.so文件在examples文件夹下写lua服务，加配置config文件及lua服务文件，通过local  servera = skynet.launch(“zx”, “123”)加载对应的c文件进行交互\n2.2lua服务同上面的c，文件名为xx_service.lua,skynet.newservice(“xx_service”)创建服务handle,可以通过skynet.call 或者skynet.send来调用其中的函数\n2.3 tcp服务server主要调用skynet.socketdriver,skynet.netpack用来解2进制包数据client需要调用client.socket\n","slug":"skynet","date":"2021-02-20T09:26:44.000Z","categories_index":"IT笔记","tags_index":"游戏","author_index":"Fly"},{"id":"90377550ef5a56f28985406fa3be8444","title":"Redis 数据结构","content":"redis 的数据存储类型分为String Hash  List  Set(集合） zset(有序集合)\n1.String为最基本的类型， 及Key value的形式，我们可以根据具体业务上的需求去定义key来达到1对1的关系，可以理解为一个最简单的mstruct sdshdr {\n// 记录 buf 数组中已使用字节的数量\n// 等于 SDS 所保存字符串的长度\nint len;\n\n// 记录 buf 数组中未使用字节的数量\nint free;\n\n// 字节数组，用于保存字符串\nchar buf[];};\nSDS 的空间分配策略：\nlen 和free会分配扩充需要的同样空间，知道所有都不够才会在需要分配，string尽量不要超过1MB\n缩减字符串的时候原先的len减少多余的放到free中，总大小不变\n2.Hash是（key =&gt; value）的集合，相当于一个二级map ，可以通过secoundKey 来确定二级key下的唯一数据，如果遇到复杂业务逻辑需要多个字段来确定唯一性的时候可以考虑用hash的形式保存数据\nHash表的底层原理：\ntypedef struct dictht {\n// 哈希表数组\ndictEntry **table;\n\n// 哈希表大小\nunsigned long size;\n\n// 哈希表大小掩码，用于计算索引值\n// 总是等于 size - 1\nunsigned long sizemask;\n\n// 该哈希表已有节点的数量\nunsigned long used;} dictht;\n!hash1哈希表节点使用 dictEntry 结构表示\ntypedef struct dictEntry {\n// 键\nvoid *key;\n\n// 值\nunion &#123;\n    void *val;\n    uint64_t u64;\n    int64_t s64;\n&#125; v;\n\n// 指向下个哈希表节点，形成链表\nstruct dictEntry *next;} dictEntry;\nkey 属性保存着键值对中的键， 而 v 属性则保存着键值对中的值， 其中键值对的值可以是一个指针， 或者是一个 uint64_t 整数， 又或者是一个 int64_t 整数。\nnext 属性是指向另一个哈希表节点的指针， 这个指针可以将多个哈希值相同的键值对连接在一次， 以此来解决键冲突（collision）的问题。\n\n\nRedis 中的字典由 dict.h/dict 结构表示：\ntypedef struct dict {\n// 类型特定函数\ndictType *type;\n\n// 私有数据\nvoid *privdata;\n\n// 哈希表\ndictht ht[2];\n\n// rehash 索引\n// 当 rehash 不在进行时，值为 -1\nint rehashidx; /* rehashing not in progress if rehashidx == -1 */} dict;!hash2\nHash结构的扩容与回收是一种rehash的机制，类似string的扩容，将ht[1]中保存新的数据及同样大小的空数据[]，然后ht[0]释放ht[1]变ht[0],ht[1]重新变成空结构\nList是简单的字符串列表,是双向链表， 增删快，数据类型是可重复的，相当于一个数组，适合最新消息显示这样的，头插入或者尾插入\ntypedef struct listNode {\n// 前置节点\nstruct listNode *prev;\n\n// 后置节点\nstruct listNode *next;\n\n// 节点的值\nvoid *value;} listNode;\n用多个 listNode 结构就可以组成链表\ntypedef struct list {\n// 表头节点\nlistNode *head;\n\n// 表尾节点\nlistNode *tail;\n\n// 链表所包含的节点数量\nunsigned long len;\n\n// 节点值复制函数\nvoid *(*dup)(void *ptr);\n\n// 节点值释放函数\nvoid (*free)(void *ptr);\n\n// 节点值对比函数\nint (*match)(void *ptr, void *key);} list;\nset是String类型的无序集合，且集合的数据有唯一性，更新集合中的一条数据需要remove在add，最好在外部rowKey确定是唯一数据的时候，比如一个玩家包含玩家的关卡列表数据结构是intset或者hashtable\ntypedef struct intset &#123;\n\n    &#x2F;&#x2F; 编码方式\n    uint32_t encoding;\n\n    &#x2F;&#x2F; 集合包含的元素数量\n    uint32_t length;\n\n    &#x2F;&#x2F; 保存元素的数组\n    int8_t contents[];\n\n&#125; intset;\n\n比如1对1对多的形式，不要用多对1对多来去存储，在并发的时候会导致原子性取不到的情况\nzset是set的有序形式，多了一个socure字段进行排序，socure为double型，适用于排行榜去做自动排序\ntypedef struct zset &#123;\n\n    zskiplist *zsl;\n\n    dict *dict;\n\n&#125; zset;\nzset 结构中的 zsl 跳跃表按分值从小到大保存了所有集合元素， 每个跳跃表节点都保存了一个集合元素： 跳跃表节点的 object 属性保存了元素的成员， 而跳跃表节点的 score 属性则保存了元素的分值。 通过这个跳跃表， 程序可以对有序集合进行范围型操作， 比如 ZRANK 、 ZRANGE 等命令就是基于跳跃表 API 来实现的。zset 结构中的 dict 字典为有序集合创建了一个从成员到分值的映射， 字典中的每个键值对都保存了一个集合元素： 字典的键保存了元素的成员， 而字典的值则保存了元素的分值。 通过这个字典， 程序可以用 O(1) 复杂度查找给定成员的分值， ZSCORE 命令就是根据这一特性实现的， 而很多其他有序集合命令都在实现的内部用到了这一特性。\n参考文献：http://redisbook.com/\n","slug":"redis-数据结构","date":"2021-02-05T09:22:19.000Z","categories_index":"数据库","tags_index":"redis","author_index":"Fly"},{"id":"a238c8f44f70d50de3377d42da7a86a2","title":"消息队列","content":"消息队列是分布式应用间交换信息的重要组件，消息队列可驻留在内存或磁盘上, 队列可以存储消息直到它们被应用程序读走。\n通过消息队列，应用程序可以在不知道彼此位置的情况下独立处理消息，或者在处理消息前不需要等待接收此消息。\n所以消息队列可以解决应用解耦、异步消息、流量削锋等问题，是实现高性能、高可用、可伸缩和最终一致性架构中不可以或缺的一环。\n现在比较常见的消息队列产品主要有ActiveMQ、RabbitMQ、ZeroMQ、Kafka、RocketMQ等\n自己的理解就是在进程间以队列的形式去管理数据交互的方式，主要用发布/订阅的形式，Mqtt是消息队列中间件的协议Mqtt是基于tcp/ip的\n具体性能分析如下\n着重说下RabbitMQ\n1.mac安装首先需要安装brew\n&#x2F;bin&#x2F;zsh -c &quot;$(curl -fsSL https:&#x2F;&#x2F;gitee.com&#x2F;cunkai&#x2F;HomebrewCN&#x2F;raw&#x2F;master&#x2F;Homebrew.sh)&quot;\n\nbrew install rabbitmq\n\n#程序目录\ncd &#x2F;usr&#x2F;local&#x2F;sbin&#x2F;\n#启动\nsudo .&#x2F;rabbitmq-server\n\n浏览器访问:localhost:15672,默认账号为:guest 密码: guest\n## 添加账号\n.&#x2F;rabbitmqctl add_user admin admin\n## 添加访问权限\n.&#x2F;rabbitmqctl set_permissions -p &quot;&#x2F;&quot; admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;\n## 设置超级权限\n.&#x2F;rabbitmqctl set_user_tags admin administrator\n\n\n","slug":"消息队列","date":"2021-01-22T08:57:26.000Z","categories_index":"IT笔记","tags_index":"MQ","author_index":"Fly"},{"id":"772f75bc85a5f28f8e914897060b12ef","title":"node.js插件","content":"方便开发者根据自身的需求对pomelo原有的功能进行有效的扩展，此目录下可以扩展业务插件。\n1.高并发下的统计数据插件\nimport readNumPlugin &#x3D; require(&#39;.&#x2F;plugins&#x2F;read-num-plugin&#39;);\n\napp.use(readNumPlugin, &#123;\n     readNum: &#123;\n        minute:10,\n        expired:24 * 3600,\n        redis_dbid:dbConfig.REDIS.master,\n        worksTable:&quot;works&quot;,\n        clickTable:&quot;click&quot;\n    &#125;\n&#125;);\n\n调用方式let readNum &#x3D; pomelo.app.get(&#39;readNumService&#39;);\nlet arrWorks &#x3D; [];\nlet res &#x3D; await readNum.addWorksClick(arrWorks);\n\nlet readNum &#x3D; pomelo.app.get(&#39;readNumService&#39;);\nlet workId &#x3D; &quot;123456&quot;;\nlet res &#x3D; await readNum.getWorkClick(workId);\n\n\n\n游客或者会员在点击文章的时候，需要对文章的点击量做一个计数统计。考虑到点击量计数的准确性，有以下几个需求：\n用户可以不需要登录每当用户点击文章的详情页面，这个文章的点击量+1用户能实时看到文章点击量，也就是用户点击后能及时看到+1点击量最终保存在数据库中，最终一致性作者在后台编辑文章然后保存时，如果这期间有点击量的增加，保存文章时不能覆盖掉这段时间的增量需要对用户去重处理，也就是一个人在一定时间内多次点击只计数一次，防止用户不断刷新或者使用爬虫不断请求某个API要过滤掉百度和谷歌的爬虫请求（根据User-Agent头判断，可以先不做）一、设计思路\n1、因为用户的数量可能很多，所以要求做到高并发，直接在数据库做加1操作不行，考虑利用缓存计数；\n2、要求最终数据库数据一致性，考虑利用定时任务从缓存中获取；\n3、用户可以匿名，所以缓存的key设计可以用文章标题的hash+用户ip；\n4、防止爬虫或者快速刷接口，需要在后端对同一个用户的同一篇文章在缓存中打标；\n5、保存文章更新的时候，不能更新点击量，点击量通过定时任务从缓存中获取，防止数据被覆盖；\n5、考虑到缓存的使用效率，需要对缓存的key做过期设置，或者主动清除旧的key。\n 所以设计的时候将统计在缓存中进行统计每隔10分钟（可配置）更新一次统计数据到db，减小了db再高并发情况下的压力\n用string类型缓存用户ip的时间，10分钟内只计算一次\n用hash类型缓存作品点击数，定时更新，及删除\n//验证添加点击\n\npublic async checkAndAdd(works_id: string, ip: string): Promise&lt;any&gt; &#123;\n        let update_time &#x3D; await this.getWorkIp(works_id, ip);\n        let now &#x3D; Math.floor(new Date().getTime() &#x2F; 1000 &#x2F; 60 &#x2F; this.minute);\n        if(update_time &lt; now)&#123;\n            let addWorkClick &#x3D; await this.addWorkIp(works_id, ip, now);\n            if(addWorkClick)&#123;\n                await this.addWorkClick(works_id, now);&#x2F;&#x2F;1\n            &#125;\n        &#125;\n        return true;\n    &#125;\n//统计更新db\npublic async sensitiveReadNum():Promise&lt;any&gt;&#123;\n        let now &#x3D; Math.floor(new Date().getTime() &#x2F; 1000 &#x2F; 60 &#x2F; this.minute);\n        let create_time &#x3D; new Date(new Date().toLocaleDateString() + &quot; 00:00:00&quot;).getTime()&#x2F;1000;\n        let ret &#x3D; await this.getAllWorkClick(now - 1);\n        if(!ret) return false;\n        for(let k in ret)&#123;\n            let workInfo &#x3D; await this.getWorkInfo(k);\n            if(workInfo &amp;&amp; workInfo.length &gt; 0)&#123;\n                workInfo[0].click_num +&#x3D; Number(ret[k]);\n            &#125; \n            this.execSync(&#39;worksSync.update&#39;, workInfo[0]);\n            if(!await this.addDailyClicks(workInfo[0].id, workInfo[0].user_id, ret[k], workInfo[0].click_num, create_time))&#123;\n                logger.error(&quot;addDailyClicks fail&quot;, now);\n            &#125;\n        &#125;\n        return ret;\n    &#125;\ndb更新用mq队列的形式保证更新正常执行及并发压力，同时可以将统计的丢到另一个进程，在另一个进程异步做统计\n\n2.验证码插件将验证码写成一个外置插件，这样需要调用的时候只需要在入口处引入在特定地方调用即可非常方便，同时也可挂载到别的应用\nimport verifierApiPlugin &#x3D; require(&#39;.&#x2F;plugins[表情]erifier-api-plugin&#39;);\n\n    app.use(verifierApiPlugin, &#123;\n         verifierApi: &#123;\n            file:&#39;verifierApi.json&#39;,\n            codeNum:4,\n            expired:24 * 3600,\n            redis_dbid:dbConfig.REDIS.master,\n            tableName:&quot;verifier&quot;\n        &#125;\n    &#125;);\n\n调用方式    let verifierApi &#x3D; pomelo.app.get(&#39;verifierApiService&#39;);\n    let code &#x3D; &#39;xxxx&#39;;\n    let res &#x3D; await verifierApi.check(text);\n&#96;&#96;&#96;   \n\n前置依赖需要安装\n\n&#96;&#96;&#96; bash\n    cnpm i svg-captcha --save \n  或者npm install --save svg-captcha\n\n\n\n主要功能是验证验证码和刷新生成验证码\n&#x2F;**\n     * 检查验证码\n     *\n     *&#x2F;\n    public async check(text: string, route:string, userCode:string, platformId:number): Promise&lt;number&gt; &#123;\n        let conf &#x3D; this.app.get(&#39;verifierApiConfig&#39;);\n        let platform &#x3D; conf[route].platform;\n        let max &#x3D; conf[route].max_pre_day || 10;\n        let begin &#x3D; conf[route].bagin_pre_day || 1;\n        if(platform &amp;&amp; platform[platformId])&#123;\n            max &#x3D; platform[platformId].max_pre_day || 21;\n            begin &#x3D; platform[platformId].bagin_pre_day || 20;\n        &#125;\n        \n        let date &#x3D; new Date().toLocaleDateString();\n        if(!conf[route])&#123;\n            throw &#39;invalid params &quot;route&quot;.&#39;\n        &#125;\n        let storage &#x3D; this.app.get(&#39;dbstorageService&#39;);\n        let rows &#x3D; await this.getCache(date, route, userCode, storage);\n        if (rows &amp;&amp; rows.length) &#123;\n            if(rows[0].num &gt; max)&#123;\n                return 2;\n            &#125;else if(rows[0].num &lt; begin || rows[0].code &#x3D;&#x3D; text.toLowerCase())&#123;\n                rows[0].num++;\n                if(await this.addCache(rows[0], storage))&#123;\n                    return 1;\n                &#125;\n            &#125; \n        &#125;\n        return 0;\n    &#125;\n\n&#x2F;&#x2F;刷新验证码得到图形验证码\n\n public async getCode(route:string, userCode:string): Promise&lt;any&gt; &#123;\n        let conf &#x3D; this.app.get(&#39;verifierApiConfig&#39;);\n        let date &#x3D; new Date().toLocaleDateString();\n        if(!route)&#123;\n            throw &#39;invalid params &quot;route&quot;.&#39;\n        &#125;\n        if(conf[route])&#123;\n            let begin &#x3D; conf[route].bagin_pre_day || 1;\n            let storage &#x3D; this.app.get(&#39;dbstorageService&#39;);\n            let rows &#x3D; await this.getCache(date, route, userCode, storage);\n            let codeMap &#x3D; this.createCode();\n            if (rows &amp;&amp; rows.length) &#123;\n                rows[0].code &#x3D; codeMap.code;\n                if(rows[0].num &gt;&#x3D; begin)&#123;\n                    if(await this.addCache(rows[0], storage))&#123;\n                        return &#123;is_verify:1, verify_svg:codeMap.data&#125;;\n                    &#125;\n                &#125; \n            &#125;else&#123;\n                let opts &#x3D; &#123;\n                    userCode:userCode,\n                    date:date,\n                    route:route,\n                    code:codeMap.code,\n                    num:0\n                &#125;\n                await this.addCache(opts, storage);\n            &#125;\n        &#125;\n        return &#123;is_verify:0, verify_svg:&#39;&#39;&#125;;\n    &#125;\n\n&#x2F;&#x2F;插件生成验证码部分 可根据需求自行更改生成字数及干扰条纹配置\n\npublic createCode():any&#123;\n        const colorMap &#x3D; [&#39;#eeeeee&#39;, &#39;skyblue&#39;, &#39;#c8c8c8&#39;] &#x2F;&#x2F; 配置背景图片颜色集合\n     const randomColor &#x3D; colorMap[Math.floor(Math.random() * colorMap.length)] &#x2F;&#x2F;随机颜色\n        let option &#x3D; &#123;\n            size: this.codeNum,  &#x2F;&#x2F;验证码长度\n            width: 200,\n            height: 150,\n            background: randomColor,&#x2F;&#x2F;干扰线条数\n            noise: 2,\n            fontSize: 32,\n            ignoreChars: &#39;0o1i&#39;,   &#x2F;&#x2F;验证码字符中排除&#39;0o1i&#39;\n            color: true &#x2F;&#x2F; 验证码的字符是否有颜色，默认没有，如果设定了背景，则默认有\n        &#125;\n        let code &#x3D; svgCaptcha.create(option);\n        let strCode &#x3D; code.text.toLowerCase();\n        &#x2F;&#x2F; let sCode &#x3D; &quot;A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,1,2,3,4,5,6,7,8,9,0&quot;;\n  &#x2F;&#x2F; let arrCode &#x3D; sCode.split(&quot;,&quot;);\n        &#x2F;&#x2F; let strCode &#x3D; &quot;&quot;;\n        &#x2F;&#x2F; for(let i &#x3D; 0;i &lt; this.codeNum; i++)&#123;\n        &#x2F;&#x2F;     let random &#x3D; Math.floor(Math.random()*arrCode.length);\n        &#x2F;&#x2F;     strCode +&#x3D; arrCode[random];\n        &#x2F;&#x2F; &#125;\n        return &#123;code:strCode, data:code.data&#125;;\n    &#125;","slug":"node-js插件","date":"2020-11-11T07:03:25.000Z","categories_index":"IT笔记","tags_index":"node.js","author_index":"Fly"},{"id":"03ffe00e2e1072f20d7bd09de5fd3f01","title":"Mongodb笔记","content":"下载地址：https://www.mongodb.com/download-center#community\n解压sudo tar -zxvf mongodb-osx-ssl-x86_64-4.0.9.tgzexport PATH=/usr/local/mongodb/bin:$PATH\n1、首先我们创建一个数据库存储目录 /data/db：\nsudo mkdir -p /data/dbsudo mongod –dbpath=/data/db#建议换一个路径，然后先启动mongod进程会卡着日志的地方，再开一个窗口启动mongo就可以了\nsudo mount -uw / #增加写权限\n使用用户名密码连接mongodb://admin:123456@localhost/\n一般的命令show dbs\nuse runoob #如果数据库不存在，则创建数据库，否则切换到指定数据库。\n\ndb.dropDatabase() #删除当前db指向的数据库\nMongoDB 中使用 createCollection() 方法来创建集合db.createCollection(name, options) #在 MongoDB 中，你不需要创建集合。当你插入一些文档时，MongoDB 会自动创建集合\n增删改查db.test.drop() #删除集合\ndb.col.insert()\ndb.col.update(&#123;&#39;title&#39;:&#39;MongoDB 教程&#39;&#125;,&#123;$set:&#123;&#39;title&#39;:&#39;MongoDB&#39;&#125;&#125;,&#123;multi:true&#125;)#更新多条有同一标签的数据\ndb.col.save()#入的文档来替换已有文档，_id 主键存在就更新，不存在就插入\n\n# 条件\n\n$lt &lt; \n$lte 小于等于\n$gt &gt;\n$gte 大于\n$ne 不等\n\ndb.col.find(&#123;key1:value1, key2:value2&#125;).pretty()   #and\ndb.col.find(   \t#or\n   &#123;\n      $or: [\n         &#123;key1: value1&#125;, &#123;key2:value2&#125;\n      ]\n   &#125;\n).pretty()\ndb.col.find(&#123;&quot;title&quot; : &#123;$type : &#39;string&#39;&#125;&#125;)\ndb.col.find().limit(1) #限制1条数 数组\ndb.col.find().skip(1)  #跳过1条\ndb.col.find().sort(1)  #1升序  -1降序  3者同时的时候优先顺序是  sort  skip  limit\n\ndb.values.createIndex(&#123;open: 1, close: 1&#125;, &#123;background: true&#125;)  #建立索引1正序  -1反序 创建工作在后台执行\n1、查看集合索引\ndb.col.getIndexes()\n2、查看集合索引大小\ndb.col.totalIndexSize()\n3、删除集合所有索引\ndb.col.dropIndexes()\n4、删除集合指定索引\ndb.col.dropIndex(&quot;索引名称&quot;)\n\ndb.mycol.aggregate([&#123;$group : &#123;_id : &quot;$by_user&quot;, num_tutorial : &#123;$sum : 1&#125;&#125;&#125;])\n&#x3D; select by_user, count(*) from mycol group by by_user\n\n$sum\t计算总和\n$avg\t计算平均值\n$min\t获取集合中所有文档对应值得最小值\n\nmongoDB的主从副本集mongod –port “PORT” –dbpath “YOUR_DB_DATA_PATH” –replSet “REPLICA_SET_INSTANCE_NAME”mongod –port 27017 –dbpath “D:\\set up\\mongodb\\data” –replSet rs0以上实例会启动一个名为rs0的MongoDB实例，其端口号为27017。启动后打开命令提示框并连接上mongoDB服务。在Mongo客户端使用命令rs.initiate()来启动一个新的副本集。我们可以使用rs.conf()来查看副本集的配置查看副本集状态使用 rs.status() 命令添加副本集的成员，我们需要使用多台服务器来启动mongo服务。进入Mongo客户端，并使用rs.add()方法来添加副本集的成员rs.add(“mongod1.net:27017”)db.isMaster()# 判断当前运行的Mongo服务是否为主节点可以使用命令副本集在主机宕机后，副本会接管主节点成为主节点 （渣男的品质）\nmongo备份mongodump -h dbhost -d dbname -o dbdirectory   #-d 数据库实例  -o 备份数据存放位置\nmongo监控mongostat是mongodb自带的状态检测工具 bin/mongostat   bin/mongotop\nmongo覆盖查询db.users.ensureIndex(&#123;gender:1,user_name:1&#125;)\ndb.users.find(&#123;gender:&quot;M&quot;&#125;,&#123;user_name:1,_id:0&#125;)\n#MongoDB的不会去数据库文件中查找。相反，它会从索引中提取数据\n\nmongo查询分析db.users.find(&#123;gender:&quot;M&quot;&#125;,&#123;user_name:1,_id:0&#125;).explain()\nindexOnly: 字段为 true ，表示我们使用了索引\nmongodb原子操作$set用来指定一个键并更新键值，若键不存在并创建。{ $set : { field : value } }$unset用来删除一个键。{ $unset : { field : 1} }$inc$inc可以对文档的某个值为数字型（只能为满足要求的数字）的键进行增减的操作。{ $inc : { field : value } }$push用法：{ $push : { field : value } }把value追加到field里面去，field一定要是数组类型才行，如果field不存在，会新增一个数组类型加进去$pushAll同$push,只是一次可以追加多个值到一个数组字段内。{ $pushAll : { field : value_array } }$pull从数组field内删除一个等于value值。{ $pull : { field : value } }$addToSet增加一个值到数组内，而且只有当这个值不在数组内才增加。$pop删除数组的第一个或最后一个元素{ $pop : { field : 1 } }$rename修改字段名称{ $rename : { old_field_name : new_field_name } }$bit位操作，integer类型{$bit : { field : {and : 5}}}\ndb.collection.findAndModify()  #查询并更新\ndb.col.findAndModify ( &#123;\n   query: &#123;\n            _id: 123456789,\n            available: &#123; $gt: 0 &#125; \n          &#125;, #查询\n   update: &#123;\n             $inc: &#123; available: -1 &#125;,\n             $push: &#123; checkout: &#123; by: &quot;abc&quot;, date: new Date() &#125; &#125;\n           &#125;  #更新\n&#125; )\n\n\n","slug":"mongodb笔记","date":"2020-07-28T04:54:03.000Z","categories_index":"IT笔记","tags_index":"mongodb","author_index":"Fly"},{"id":"95c23f559d3556b23b5f7de5b6f172a9","title":"Node中间件","content":"node中间件可以概括为在请求的过程中或者进程间通信过程中过滤，交给函数处理之前先交给他处理比如用来做中间件的 body-parser  method-override  自己写的心跳及检测用户登录验证功能\napp.use(&#39;&#x2F;&#39;,function(req,res,next)&#123;\n\n　　　　console.log(&#39;1&#39;);\n\n　　　　next();  &#x2F;&#x2F;重要代码\n\n&#125;\n\nbodyParser.js 原理解析判断请求为 post 请求，则进行解析。因为是 post 请求，传输数据可能会很大，需要一点一点传。创建 postData 变量，存储在变量里面使用 querystring模块解析post参数将解析好的参数对象添加到req的属性中 req.body执行下一个中间件 next()\nmethod-override增加请求类型\n错误处理可以自定义一个中间件做最外层处理app.use(&#39;&#x2F;&#39;, function(err,req,res,next)&#123;\n\nres.send(&#39;网络异常。。。&#39;) &#x2F;&#x2F;要改提示信息在这里改即可：res.send(&#39;网络异常，请稍后重试&#39;)\n\n&#125;\n\n\n\n","slug":"node中间件","date":"2020-07-14T08:01:50.000Z","categories_index":"IT笔记","tags_index":"node.js","author_index":"Fly"},{"id":"d0c8d2c20d89823379ca4a9355ecc003","title":"Python学习笔记","content":"1.遇到的问题SyntaxError: Non-ASCII character ‘\\xe4’#-- coding: utf-8 -- 或者 #coding=utf-8\nmac上的环境变量open ~/.bash_profile中加入如下然后保存   source ~/.bash_profile#Setting PATH for Python 3.8\nexport PYTHON3&#x3D;&#x2F;Library&#x2F;Frameworks&#x2F;Python.framework&#x2F;Versions&#x2F;3.8&#x2F;bin\nalias python3&#x3D;&quot;&#x2F;Library&#x2F;Frameworks&#x2F;Python.framework&#x2F;Versions&#x2F;3.8&#x2F;bin&#x2F;python3&quot;\nexport PATH&#x3D;$MYSQL:$PYTHON3:$PATH:\nzip函数&gt;&gt;&gt;a &#x3D; [1,2,3]\n&gt;&gt;&gt; b &#x3D; [4,5,6]\n&gt;&gt;&gt; c &#x3D; [4,5,6,7,8]\n&gt;&gt;&gt; zipped &#x3D; zip(a,b)     # 打包为元组的列表\n[(1, 4), (2, 5), (3, 6)]\n&gt;&gt;&gt; zip(a,c)              # 元素个数与最短的列表一致\n[(1, 4), (2, 5), (3, 6)]\n&gt;&gt;&gt; zip(*zipped)          # 与 zip 相反，*zipped 可理解为解压，返回二维矩阵式\n[(1, 2, 3), (4, 5, 6)]\n\n","slug":"python学习笔记","date":"2020-07-09T08:20:08.000Z","categories_index":"IT笔记","tags_index":"python","author_index":"Fly"},{"id":"01997d5dc8999c6dc19f4a1759fa3505","title":"Mysql笔记","content":"第1章 SQL基础1.数据分为DDL(数据定义语言)，DML(数据操纵语言)，DCL(数据控制语言)    1.1 DDL语句    mysql -uroot -p\ncreate database test1;\nuse test1;\nshow tables;   \t\t\t\t\t\t\t\t#查看所有表\ndrop database test1;\ncreate table emp(ename varchar(10),hiredate date,sal decimal(2,10),deptno int(2));\ndesc emp;\t\t\t\t\t\t\t\t\t#查看表信息\nshow create table emp \\G;\t\t\t\t\t#\\G使得记录能够按照字段竖向排列 以便显示更长内容\ndrop table emp;\nalter table emp modify ename varchar(20);\t#修改表字段\nalter table emp add column age int(3);\t\t#添加字段\nalter table emp drop colum age\t\t\t\t#删除字段\nalter table emp change age age123 int(4);\t#字段改名同时修改类型\nalter table emp add birth date after ename;\t#修改字段排列顺序\nalter table emp rename emp1;\n\n1.2 DML语句 增删改查\ninsert into emp (ename,sal) values(&#39;dony&#39;,1000);\ndelete from emp where ename &#x3D; &#39;xxx&#39;;\nselect distinct age from emp1;\t\t\t\t\t\t\t\t\t\t\t\t#查询的内容去重\nselect * from emp order by age,deptno desc;\t\t\t\t\t\t\t\t\t#根据某个字段排序\n\tselect age,count(1) from emp group by age with rollup;\t\t\t\t\t\t#分类统计计数及总数\n\tselect age,count(1) from emp group by age having count(1)&gt;1;\n\tselect ename,deptname from emp,dept where emp.age &#x3D; dept.age;\t\t\t\t#联查,内链接\n\tselect ename,deptname from emp left jion dept on emp.deptno &#x3D; dept.deptno;\t#表链接很多情况下优于子查询\n\tselect * from dept union all select * from emp;\t\t\t\t\t\t\t\t#集合显示不去重\n\tselect * from dept union select * from emp;\t\t\t\t\t\t\t\t\t#集合显示去重\nYou can&#39;t specify target table &#39; for update in FROM clause\nMysql不让对查询到的目标语句进行更新\nDELETE FROM playeritems WHERE id IN(SELECT mid FROM (SELECT min(id) as mid FROM playeritems WHERE uid &#x3D; &#39;1300200112870961&#39; GROUP BY iname HAVING count(iname) &gt; 1 )as tmp);\n\n1.3 DCL语句\ngrant select,insert on sakila.* to &#39;z1@localhost&#39; identified by &#39;123&#39;; \t\t#赋予用户权限\nrevoke insert on sakila.* from &#39;z1@localhost&#39;;\t\t\t\t\t\t\t\t#回收权限2.常用函数    select NOW();\t\t\t\t\t\t\t\t\t#xxxx-xx-xx xx:xx:xx\nselect UNIX_TIMESTAMP(now());\t\t\t\t\t#时间戳\nselect FROM_UNIXTIME(时间戳);\t\t\t\t\t#xxxx-xx-xx xx:xx:xx\nIF(value,t,f)\t\t\t\t\t\t\t\t\t#如果value为真，返回t,否则返回f\nselect if(a &gt; 2000, &#39;high&#39;,&#39;low&#39;) from B\nIFNULL(value1,value2)\t\t\t\t\t\t\t#如果value1不为空，返回value1,否则返回value2\nselect ifnull(a , 0) from B\nCASE WHEN value THEN res1 ... ELSE def END\t\t#如果value1真，返回res1,否则返回def\nselect case when a&lt;2000 then &#39;low&#39; else &#39;high&#39; end from B\nCASE exp WHEN value THEN res1 ... ELSE def END\t#如果exp &#x3D; value1真，返回res1,否则返回def\nselect case a when 1000 then &#39;low&#39; when 2000 then &#39;mid&#39; else &#39;high&#39; end from B\n第2章 存储引擎1.mysql的存储引擎有好多种，这边记录2种    1.1 MyISAM 不支持事务、不支持外键、速度快、表锁    1.2 InnoDB 支持提交、回滚、奔溃恢复能力的事务安全，行锁\n2.myssql事务\nstart transaction;\nsql 操作\ncommit and chain;\n\n3.防止sql注入\n$re &#x3D; &quot;&#x2F;(|\\&#39;|(\\%27)|\\;|(\\%3b)|\\&#x3D;|(\\%3d)|\\(|(\\%28)|\\)|(\\%29)|(\\&#x2F;*) |(\\%2f%2a)|(\\ *&#x2F;)|(\\%2a%2f)|\\+|(\\%2b)|\\&lt;|(\\%3c)|\\&gt;|(\\%3e)|\\(--))|\\[|\\%5b|\\]|\\%5d)&#x2F;&quot;;\n\nif(preg_match($re, $aa) &gt;0)&#123;\n\techo(&quot;参数不对&quot;);\n\treturn 0;\n&#125;\n\n4.SQL MODEANSI 使语法行为更符合sqlSTRICT_TRANS_TABLES 试用于事务，严格模式，报错不警告,不允许非法日期TRADITIONAL 严格模式，适用于事务非事务，不警告直接报错\n5.sql分区RANGE分区：基于一个给定连续区间范围，把数据分配到不同分区LIST分区：类似RANGEHASH分区：基于给定的分区个数，把数据分配到不同分区KEY分区：类似于HASH分区RANGE\\LIST\\HASH分区键必须INT型\n好处4点存储更多数据、优化查询、快速删除数据、获得更大查询吞吐量Range分区利用取值范围将数据分成分区\nCREATE TABLE emp(\nid INT NOT NULL,\nNAME VARCHAR(20),\nage INT\n)\nPARTITION BY RANGE(ID)(\nPARTITION p0 VALUES LESS THAN (6),\nPARTITION p1 VALUES LESS THAN (11),\nPARTITION pmax VALUES LESS THAN maxvalue\n);\nLIST分区是建立离散的之列表告诉数据库特定值在哪个分区\nCREATE TABLE expense(\nexpense_date DATE NOT NULL,\ncategory INT,\namount DECIMAL (10,3)\n)\nPARTITION BY LIST(category)(\nPARTITION p0 VALUES IN(3,5),#可字符串在5.5版本后\nPARTITION p1 VALUES IN(1,10),\nPARTITION p2 VALUES IN(4,9),\nPARTITION p3 VALUES IN(2),\nPARTITION p4 VALUES IN(6)\n);\nColumns分区可分为 RANGE Columns和LIST Columns分区都支持int\\date\\string,还支持多列\nCREATE TABLE expense(\na INT,\nb INT\n)\nPARTITION BY RANGE COLUMS(a,b)(\nPARTITION p0 VALUES IN(0,10),#可字符串在5.5版本后\nPARTITION p1 VALUES IN(10,10),\nPARTITION p2 VALUES IN(10,29)\n);\nHASH分区用来分散热点读，确保数据在预留分区平均分布，有常规分区和线性分区\n#常规 平衡不方便\nCREATE TABLE emp(\nid INT NOT NULL,\nNAME VARCHAR(20),\nage INT\n)\nPARTITION BY HASH(ID) PARTITIONS 4;\n#线性 快速不平衡\nCREATE TABLE emp(\nid INT NOT NULL,\nNAME VARCHAR(20),\nage INT\n)\nPARTITION BY LINEAR HASH(ID) PARTITIONS 4;\nkey分区类似HASH分区，数据类型除TEXThe BLOB以外都可以\nRANGE&amp;LIST 分区管理 分区被删除了分区中的数据也被删除了\nalter table xxx drop partition p2; #删\nalter table xxx add partition (partiton p5 values less than (2025)) #增  不能添加一个包含现有分区值列表中的任意值分区\nalter table xxx reorganize partition p3 into (\n\tpartition p2 values less than (2005),\n\tpartition p3 values less than (2015)\n);\t\t\t#拆分\nalter table xxx reorganize partition p1,p2,p3 into (\n\tpartition p1 values less than (2015)\n);\t\t#合并\n\nHASH&amp;KEY 分区管理\nalter table xxx coalesce partition 2; #原4删2\nalter table xxx coalesce partition 8; #原4加8\n\n6.SQL优化\n\n通过慢查询日志定位效率低的sql,在查询过程中出现的情况可以用show processlist命令查看mysql进程，看锁表及进程状态\n将慢的sql提取做explain分析，type的性能如下 ALL,全表扫瞄 index,索引全扫描 range,索引范围扫描 常见&lt;&lt;=&gt;&gt;=\\between ref,使用非唯一索引扫描或者唯一索引前缀扫描（联合索引） eq_ref,使用唯一索引 const/system,单表中最多有一个匹配行 NULL，不查表直接得到结果 自上而下效率越来越高\n通过show profile分析sqlselect @@have_profiling;\t#查询是否支持\nselect @@profiling;\t\t#查询是否开启\nset profiling&#x3D;1;\t\t#开启\nshow profiles;\t\t\t#显示sql的执行排列\nshow profile for query 4;\t#查找具体某一条的状态\nshow profile cpu for query 4;\t#查询莫一条在具体（all\\cpu\\block io\\context\\switch\\page faults）\n\n\n\nmac或者linux当mysql连接不上的时候加ALTER USER ‘root’@’localhost’ IDENTIFIED WITH mysql_native_password BY ‘password’;\n7.mysql配置优化在mysqld下\n为所有线程打开的表的数量。增加这个值会增加mysqld需要的文件描述符的数量。因此，您必须确保在[mysqld_safe]节中的变量“open-files-limit”中将允许打开的文件数量至少设置为4096table_open_cache=2000\n内部(内存)临时表的最大大小。如果一个表比这个值大，那么它将自动转换为基于磁盘的表。可以有很多。tmp_table_size=94M\n我们应该在缓存中保留多少线程以供重用。当客户机断开连接时，如果之前的线程数不超过thread_cache_size，则将客户机的线程放入缓存。如果您有很多新连接，这将大大减少所需的线程创建量(通常，如果您有一个良好的线程实现，这不会带来显著的性能改进)。thread_cache_size=10\n如果用于快速创建索引的临时文件比这里指定的使用键缓存的文件大，则首选键缓存方法。这主要用于强制大型表中的长字符键使用较慢的键缓存方法来创建索引。key_buffer_size=8M\n用于对MyISAM表执行全表扫描的缓冲区的大小。如果需要完整的扫描，则为每个线程分配。read_buffer_size=16Mread_rnd_buffer_size=32M\n如果在SHOW GLOBAL STATUS输出中每秒看到许多sort_merge_passes，可以考虑增加sort_buffer_size值，以加快ORDER BY或GROUP BY操作的速度，这些操作无法通过查询优化或改进索引来改进。sort_buffer_size=16M\nInnoDB用于缓冲日志数据的缓冲区大小。一旦它满了，InnoDB就必须将它刷新到磁盘。由于它无论如何每秒刷新一次，所以将它设置为非常大的值是没有意义的(即使是长事务)。innodb_log_buffer_size=5M\n与MyISAM不同，InnoDB使用缓冲池来缓存索引和行数据。设置的值越大，访问表中的数据所需的磁盘I/O就越少。在专用数据库服务器上，可以将该参数设置为机器物理内存大小的80%。但是，不要将它设置得太大，因为物理内存的竞争可能会导致操作系统中的分页。注意，在32位系统上，每个进程的用户级内存可能被限制在2-3.5G，所以不要设置得太高。innodb_buffer_pool_size=20M\nORDER BY 或者GROUP BY 操作的buffer缓存大小innodb_sort_buffer_size = 64M\n为了提升扩展性和刷脏效率，在5.7.4版本里引入了多个page cleaner线程。从而达到并行刷脏的效果在该版本中，Page cleaner并未和buffer pool绑定，其模型为一个协调线程 + 多个工作线程，协调线程本身也是工作线程。因此如果innodb_page_cleaners设置为8，那么就是一个协调线程，加7个工作线程innodb_page_cleaners = 4\nmysql客户端连接数据库是交互式连接，通过jdbc连接数据库是非交互式连接interactive_timeout = 100 # 交互式连接超时wait_timeout = 100 # 非交互连接超时\n8.mysql索引背后的数据结构及算法\nB-Tree为了描述B-Tree，首先定义一条数据记录为一个二元组[key, data]，key为记录的键值，对于不同数据记录，key是互不相同的；data为数据记录除key外的数据。那么B-Tree是满足下列条件的数据结构：d为大于1的一个正整数，称为B-Tree的度。h为一个正整数，称为B-Tree的高度。每个非叶子节点由n-1个key和n个指针组成，其中d&lt;=n&lt;=2d。每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null 。所有叶节点具有相同的深度，等于树高h。key和指针互相间隔，节点两端是指针。一个节点中的key从左到右非递减排列。所有节点组成树结构。每个指针要么为null，要么指向另外一个节点。如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于(v(key_1))，其中(v(key_1))为node的第一个key的值。如果某个指针在节点node最右边且不为null，则其指向节点的所有key大于(v(key_m))，其中(v(key_m))为node的最后一个key的值。如果某个指针在节点node的左右相邻key分别是(key_i)和(key_{i+1})且不为null，则其指向节点的所有key小于(v(key_{i+1}))且大于(v(key_i))。图2是一个d=2的B-Tree示意图。\n由于B-Tree的特性，在B-Tree中按key检索数据的算法非常直观：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到null指针，前者查找成功，后者查找失败。B-Tree上查找算法的伪代码如下：\nBTree_Search(node, key) &#123;\n    if(node &#x3D;&#x3D; null) return null;\n    foreach(node.key)\n    &#123;\n        if(node.key[i] &#x3D;&#x3D; key) return node.data[i];\n            if(node.key[i] &gt; key) return BTree_Search(point[i]-&gt;node);\n    &#125;\n    return BTree_Search(point[i+1]-&gt;node);\n&#125;\ndata = BTree_Search(root, my_key);关于B-Tree有一系列有趣的性质，例如一个度为d的B-Tree，设其索引N个key，则其树高h的上限为(log_d((N+1)/2))，检索一个key，其查找节点个数的渐进复杂度为(O(log_dN))。从这点可以看出，B-Tree是一个非常有效率的索引数据结构。\nB+TreeMySQL就普遍使用B+Tree实现其索引结构与B-Tree相比，B+Tree有以下不同点：每个节点的指针上限为2d而不是2d+1。内节点不存储data，只存储key；叶子节点不存储指针。图3是一个简单的B+Tree示意。\n一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针\nMyISAM索引使用的是B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址\nInnoDB索引InnoDB也使用B+Tree作为索引结构第一重大区别是InnoDB的数据文件本身就是索引文件，InnoDB表数据文件本身就是主索引因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有）如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择\nInnoDB的主键选择与插入优化在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键 （百万条以下的数据看不出来多大区别）\n1、B+树的层级更少。\n相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快；\n2、B+树查询速度更稳定。\nB+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;\n3、B+树天然具备排序功能。\nB+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。\n4、B+树全节点遍历更快。\nB+树遍历整棵树只需要遍历所有的叶子节点即可，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。\n9.mysql 调优过程中的常用命令ps -es|grep mysql\n当启动不了或者报错的时候，mysql Password字段是authentication_string,配置太多会报错启动用/usr/local/mysql/bin/mysqld –user=mysql \n刷新数据库 进mysql后Access denied for user ‘root@localhost’报错update mysql.user set authentication_string=’123’ where user=’root’;\nmacs上的环境变量open ~/.bash_profile中加入如下然后保存   source ~/.bash_profile#windos下 安装要装一个vcredistx64mysqld –skip-grant-tables 进入后修改密码\n#mysql\nexport MYSQL&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin\nexport PATH&#x3D;$MYSQL:$PYTHON3:$PATH:\n查看MySQL服务器配置信息mysql&gt; show variables;\n查看MySQL服务器运行的各种状态值mysql&gt; show global status;\nmysql一定要定期清理日志，不然会出莫名其妙的问题，什么有的库打开就断开连接这样的ERROR 1030 (HY000) at line 33: Got error 168 from storage enginemysql&gt; reset master;#清除日志\n连接数查看show status like ‘Threads%’;SHOW VARIABLES LIKE ‘%max_connections%’;set global max_connections = 1000;flush privileges;\n#!/bin/bashexport pid=ps -ef | grep mysql | head -n 1 | awk &#39;&#123;print $2&#125;&#39; 取mysql的pidecho password | sudo kill -9 $pidmysql -uroot -pxx -e “set global max_connections = 1000;reset master;…”sh -x xxx.sh 看问题\n","slug":"mysql笔记","date":"2020-07-06T08:40:36.000Z","categories_index":"IT笔记","tags_index":"mysql","author_index":"Fly"},{"id":"892e834e7d38475802e25b3393e5a70c","title":"游戏中写出的Bug及思考","content":"1.如果存在小游戏版本，写出的功能要兼容旧版本及新版本，因为小游戏渠道如果拦截就版本会导致玩家无法更新到新版本无法游戏\n2.node版本要用双数的正式版本，单数为测试版本，容易存在不可预知的问题，比如之前时区的双数上会出现无法识别的问题\n3.进程间通信的逻辑一定要注意，进程间的内存是单独的，所以如果没有公共存储最好不要做交互的操作容易把本方的数据写到对方进程中\n4.node.js的传参方式是按址传递的，在对传参对象.push的时候一定要注意，会改到原始对象\n5.node中的cb用起来要注意，漏写或者多写，会导致绕过继续执行，或者回调地狱，抛出错误用throw\n6.对单一修改的时候一定要全局查找下对应的，看看会不会改到其他连用没注意的部分，特别是function 参数  传参结构体\n","slug":"游戏中写出的bug及思考","date":"2020-06-16T01:48:20.000Z","categories_index":"IT笔记","tags_index":"游戏","author_index":"Fly"},{"id":"07efd5dd1c92b0165acc3d4c1fb4bbbd","title":"Es6 Js规范","content":"数组拷贝\nconst itemsCopy &#x3D; [...items];\n\n取值方式\nconst [first, second] &#x3D; arr;\n\n函数初始化\nfunction f3(a) &#123;\n  const b &#x3D; a || 1;\n  &#x2F;&#x2F; ...\n&#125;\n\nfunction f4(a &#x3D; 1) &#123;\n  &#x2F;&#x2F; ...\n&#125;\n\n输出数组\nconst x &#x3D; [1, 2, 3, 4, 5];\nconsole.log(...x);\n\nnew Date(...[2016, 8, 5]);\n\n数组遍历\nlet sum &#x3D; 0;\nnumbers.forEach((num) &#x3D;&gt; &#123;\n  sum +&#x3D; num;\n&#125;);\nsum &#x3D;&#x3D;&#x3D; 15;\n\n","slug":"js规范","date":"2020-06-09T09:59:15.000Z","categories_index":"","tags_index":"","author_index":"Fly"},{"id":"7f9eaea51aac5991b1ad0d8e6f097110","title":"基础知识","content":"异步：异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。\n基本功能\n\n进程管理进程控制、进程同步、进程通信、死锁处理、处理机调度等。\n\n内存管理内存分配、地址映射、内存保护与共享、虚拟内存等。\n\n文件管理文件存储空间的管理、目录管理、文件读写管理和保护等。\n\n设备管理完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。\n\n\n主要包括缓冲管理、设备分配、设备处理、虛拟设备等。\n\nps查看某个时间点的进程信息。\n\n示例：查看自己的进程\nps -l示例：查看系统所有进程\nps aux示例：查看特定的进程\nps aux | grep threadxps aux | grep node 查看所有node进程\npstree查看进程树。\n\n示例：查看所有进程树\npstree -A\ntop实时显示进程信息。\n\n示例：两秒钟刷新一次\ntop -d 2\nnetstat查看占用端口的进程\n\n示例：查看特定端口的进程\nnetstat -anp | grep portlsof -i:42031实时读取文件\ntail -fn 100 xxx.log\nkill杀进程kill 9 29876\n\n\n\n#计算机网络物理层、数据链路层、网络层、传输层、应用层物理层：单工通信：单向传输半双工通信：双向交替传输全双工通信：双向同时传输\n数据链路层：模拟信号转换成数字信号，封装成帧等特点\n网络层：IP协议\n传输层：TCP/UDP协议\n应用层：HTTP协议\n长连接与短连接的理解：之所以网络上说HTTP分为长连接和短连接，其实本质上是说的TCP连接。TCP连接是一个双向dao的通道，它是可以保持一段时间不关闭的，因此TCP连接才有真正的长连接和短连接这一说。HTTP协议说到底是应用层的协议，而TCP才是真正的传输层协议，只有负责传输的这一层才需要建立连接。因此“HTTP连接”这一概念压根就不应该出现，HTTP只是一个应用层的协议，根本就没有连接这一说法，就像FTP协议一样，我们从来不会说“FTP连接”吧。归根到底，其实说的连接都是只传输层的TCP连接。相反说HTTP请求和HTTP响应反而更加准确一些都是通过TCP连接这个数据通道来传输请求和响应的。说到这里就彻底的改变了之前的错误认识，以后记住长连接，短连接都是指的传输层的TCP连接，而不是应用层的HTTP协议。HTTP的长连接和短连接本质上是TCP长连接和短连接。HTTP属于应用层协议，在传输层使用TCP协议，在网络层使用IP协议。IP协议主要解决网络路由和寻址问题，TCP协议主要解决如何在IP层之上可靠的传递数据包，使在网络上的另一端收到发端发出的所有包，并且顺序与发出顺序一致。TCP有可靠，面向连接的特点。现在的疑问既然说到了长连接，那么什么是长连接，短连接呢？HTTP1.1中又是如何实现长连接的呢？那么长短连接又分别有什么优缺点呢？正如我们学习一个新知识的时候，总是会问自己这三个问题一样：XXX是什么？XXX怎么用？XXX的好处？像我们一般的普通web应用，csdn写博客的平台，这种采用长连接有什么用呢？1，如何理解HTTP协议是无状态的HTTP协议是无状态的，指的是协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。也就是说，打开一个服务器上的网页和你之前打开这个服务器上的网页之间没有任何联系。HTTP是一个无状态的面向连接的协议，无状态不代表HTTP不能保持TCP连接，更不能代表HTTP使用的是UDP协议（无连接）。2，什么是长连接、短连接？在HTTP/1.0中，默认使用的是短连接。也就是说，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。如果客户端浏览器访问的某个HTML或其他类型的 Web页中包含有其他的Web资源，如JavaScript文件、图像文件、CSS文件等；当浏览器每遇到这样一个Web资源，就会建立一个HTTP会话。但从 HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头有加入这行代码：Connection:keep-alive 服务器和客户端都要设置在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的 TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接要客户端和服务端都支持长连接。HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。3，TCP连接当网络通信时采用TCP协议时，在真正的读写操作之前，server与client之间必须建立一个连接，当读写操作完成后，双方不再需要这个连接 时它们可以释放这个连接，连接的建立是需要三次握手的，而释放则需要4次握手，所以说每个连接的建立都是需要资源消耗和时间消耗的。经典的三次握手示意图：经典的四次分手关闭图：4，TCP短连接我们模拟一下TCP短连接的情况，client向server发起连接请求，server接到请求，然后双方建立连接。client向server发送消息，server回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close操作，不过一般都是client先发起close操作。为什么呢，一般的server不会回复完client后立即关闭连接的，当然不排除有特殊的情况。从上面的描述看，短连接一般只会在client/server间传递一次读写操作。短连接的操作步骤是：建立连接——数据传输——关闭连接…建立连接——数据传输——关闭连接5，TCP长连接接下来我们再模拟一下长连接的情况，client向server发起连接，server接受client连接，双方建立连接。Client与server完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。比如你请求了csdn的一个网页，这个网页里肯定还包含了CSS、JS等等一系列资源，如果你是短连接（也就是每次都要重新建立TCP连接）的话，那你每打开一个网页，基本要建立几个甚至几十个TCP连接，但如果是长连接的话，那么这么多次HTTP请求（这些请求包括请求网页内容，CSS文件，JS文件，图片等等），其实使用的都是一个TCP连接，很显然是可以节省很多消耗的。另外，最后关于长连接还要多提一句，那就是，长连接并不是永久连接的。如果一段时间内（具体的时间长短，是可以在header当中进行设置的，也就是所谓的超时时间），这个连接没有HTTP请求发出的话，那么这个长连接就会被断掉。这一点其实很容易理解，否则的话，TCP连接将会越来越多，直到把服务器的TCP连接数量撑爆到上限为止。现在想想，对于服务器来说，服务器里的这些个长连接其实很有数据库连接池的味道，大家都是为了节省连接重复利用嘛，对不对？长连接的操作步骤是：建立连接——数据传输…（保持连接）…数据传输——关闭连接\n","slug":"基础知识","date":"2020-05-22T06:42:58.000Z","categories_index":"IT笔记","tags_index":"","author_index":"Fly"},{"id":"e88abce89c8aca44a71f313b7a0268e8","title":"游戏中的运营活动框架思路","content":"游戏的运营活动一般会有好多种类型，但是这些类型的功能一般是有共同和非共同的部分，这里记录一个对多类型运营活动的管理框架通过模板表录入运营活动的参数，包括跳转模块，开启方法，红点方法，等级等。如果有类似活动结束发奖的奖励表也可以用表来记录不同活动operation_id对应的奖励进行管理。1.初始化玩家排行\ninit_sky_bless_rank() -&gt;\n    List &#x3D; [PlayerSkyBless || PlayerSkyBless &lt;- get_all_player_st_sky_bless(),\n        PlayerSkyBless #player_st_sky_bless.bless_times &gt; 0],\n    SortFunction &#x3D; fun(A,B) -&gt;\n        if  A #player_st_sky_bless.bless_times &#x3D;:&#x3D; B #player_st_sky_bless.bless_times -&gt;\n                A #player_st_sky_bless.last_time &#x3D;&lt; B #player_st_sky_bless.last_time;\n            true -&gt;\n                A #player_st_sky_bless.bless_times &gt; B #player_st_sky_bless.bless_times\n        end\n    end,\n    SortList &#x3D; lists:sort(SortFunction,List),\n    Num &#x3D; length(SortList),\n    Tran &#x3D; fun() -&gt;\n        if  Num &gt; 0 -&gt;\n                lists:foreach(\n                    fun(Seq) -&gt;\n                        PlayerSkyBless &#x3D; lists:nth(Seq,SortList),\n                        lib_ets:insert(sky_bless_player_ranking,#sky_lantern_bless_player_ranking&#123;\n                            player_id &#x3D; PlayerSkyBless #player_st_sky_bless.player_id,ranking &#x3D; Seq&#125;,replace),\n                        BlessRanking &#x3D; #sky_lantern_bless_ranking&#123;\n                            ranking &#x3D; Seq,\n                            player_id &#x3D; PlayerSkyBless #player_st_sky_bless.player_id,\n                            times   &#x3D; PlayerSkyBless #player_st_sky_bless.bless_times,\n                            bless_time &#x3D; PlayerSkyBless #player_st_sky_bless.last_time\n                        &#125;,\n                        lib_ets:insert(sky_bless_ranking,BlessRanking,replace)\n                    end,\n                    lists:seq(1,Num)\n                );\n            true -&gt;\n                noop\n        end\n    end,\n    game_db:do(Tran).\n\n2.处理玩家排行\ndeal_update_player_ranking(PlayerId) -&gt;\n    PlayerSkyBless &#x3D; get_player_st_sky_bless(PlayerId),\n    BlessTimes &#x3D; PlayerSkyBless #player_st_sky_bless.bless_times,\n    BlessTime  &#x3D; PlayerSkyBless #player_st_sky_bless.last_time,\n    NowRanking &#x3D; get_sky_bless_player_ranking(PlayerId),\n    Tran &#x3D; fun() -&gt;\n        if  NowRanking &#x3D;&#x3D; 0 -&gt;\n                Len &#x3D; length(get_all_sky_bless_ranking()),\n                NewRanking &#x3D; #sky_lantern_bless_ranking&#123;\n                    ranking     &#x3D; Len + 1,\n                    player_id   &#x3D; PlayerId,\n                    times       &#x3D; BlessTimes,\n                    bless_time  &#x3D; BlessTime\n                &#125;,\n                lib_ets:insert(sky_bless_ranking,NewRanking,replace),\n                lib_ets:insert(sky_bless_player_ranking,#sky_lantern_bless_player_ranking&#123;\n                    player_id &#x3D; PlayerId,ranking &#x3D; Len + 1&#125;,replace),\n                ranking_sort(PlayerId,BlessTimes,BlessTime,Len);\n            true -&gt;\n                lib_ets:update(sky_bless_ranking,NowRanking,[&#123;#sky_lantern_bless_ranking.times,BlessTimes&#125;,\n                    &#123;#sky_lantern_bless_ranking.bless_time,BlessTime&#125;]),\n                ranking_sort(PlayerId,BlessTimes,BlessTime,NowRanking - 1)\n        end\n    end,\n    game_db:do(Tran).\n\nranking_sort(_,_,_,0) -&gt;\n    noop;\n\nranking_sort(PlayerId,BlessTimes,Time,Ranking) -&gt;\n    BlessRanking &#x3D; get_sky_bless_ranking(Ranking),\n    case sort(BlessTimes,Time,BlessRanking #sky_lantern_bless_ranking.times,BlessRanking #sky_lantern_bless_ranking.bless_time) of\n        true -&gt;\n            NewRanking &#x3D; #sky_lantern_bless_ranking&#123;\n                ranking &#x3D; Ranking,\n                player_id &#x3D; PlayerId,\n                times   &#x3D; BlessTimes,\n                bless_time &#x3D; Time\n            &#125;,\n            ARanking &#x3D; #sky_lantern_bless_ranking&#123;\n                ranking &#x3D; Ranking + 1,\n                player_id &#x3D; BlessRanking #sky_lantern_bless_ranking.player_id,\n                times &#x3D; BlessRanking #sky_lantern_bless_ranking.times,\n                bless_time &#x3D; BlessRanking #sky_lantern_bless_ranking.bless_time\n            &#125;,\n            lib_ets:insert(sky_bless_player_ranking,#sky_lantern_bless_player_ranking&#123;\n                player_id &#x3D; BlessRanking #sky_lantern_bless_ranking.player_id,ranking &#x3D; Ranking + 1&#125;,replace),\n            lib_ets:insert(sky_bless_player_ranking,#sky_lantern_bless_player_ranking&#123;\n                player_id &#x3D; PlayerId,ranking &#x3D; Ranking&#125;,replace),\n            lib_ets:insert(sky_bless_ranking,NewRanking,replace),\n            lib_ets:insert(sky_bless_ranking,ARanking,replace),\n            ranking_sort(PlayerId,BlessTimes,Time,Ranking - 1);\n        false -&gt;\n            noop\n    end.\n\n3.通过公共管理进程对活动进行管理发奖及消息通知\nhandle_cast(&#123;async_send&#125;, &#123;true,State&#125;) -&gt;\n    catch api_st_sky_bless:timer_notify(State),\n    start_timer(1),\n    &#123;noreply, &#123;true,[]&#125;&#125;;\n\nhandle_cast(&#123;activity_stop&#125;,State) -&gt;\n    mod_st_sky_bless:give_award(),\n    &#123;noreply,State&#125;;","slug":"游戏中的运营活动框架和思路","date":"2019-11-22T08:15:07.000Z","categories_index":"设计方法","tags_index":"游戏","author_index":"Fly"},{"id":"c3f4727b2c3a19f39df59e9531fb513f","title":"游戏全局通知红点系统","content":"红点功能贯穿游戏所有功能，像是一个全局的通知，用一个配置表记录所有游戏功能及入口和红点、开启的方法名加载进内存主入口界面时候调用取得已开启的功能列表mod_function:get_all_game_function() 构造成带父子关系的功能列表\n&#123;Id,[&#123;GameFunction #game_function.id&#125;|List1]&#125;\n|\nlists:delete(&#123;Id,List1&#125;,L)\n通过核心回调到所有模块的红点方法\nIsRed &#x3D; if\n    Mod &#x3D;&#x2F;&#x3D; &#39;&#39;, Func &#x3D;&#x2F;&#x3D; &#39;&#39; -&gt;\n        try erlang:apply(Mod,Func,[PlayerId]) of\n            Result -&gt;\n                Result\n        catch\n            _ : _ -&gt;\n                false\n        end;\n    true -&gt;\n        false\nend,\n最后将缓存中的玩家红点数据替换\nlib_ets:delete(player_red, PlayerId),\n    lib_ets:insert(\n        player_red,\n        #player_red&#123;\n            player_id &#x3D; PlayerId,\n            red_list  &#x3D; N\n        &#125;,\n        replace\n    ),\n\n不同的功能触发红点改变需要有个打点的函数,在功能需要改变红点状态的时候通知进来更新缓存\nnotify_game_function_is_red (PlayerId,FunctionId) -&gt;\n    case mod_function:check_lock(PlayerId,FunctionId) of\n        false -&gt;\n            noop;\n        _ -&gt;\n            GameFunction &#x3D; code_db:get(game_function,[FunctionId]),\n            Mod   &#x3D; list_to_atom(GameFunction #game_function.red_mod),\n            Func  &#x3D; list_to_atom(GameFunction #game_function.red_func),\n            IsRed &#x3D; if\n                Mod &#x3D;&#x2F;&#x3D; &#39;&#39;, Func &#x3D;&#x2F;&#x3D; &#39;&#39; -&gt;\n                   try erlang:apply(Mod,Func,[PlayerId]) of\n                        Result -&gt;\n                            Result\n                    catch\n                        _ : _ -&gt;\n                            false\n                    end;\n                true -&gt;\n                    false\n            end,\n            if\n                GameFunction #game_function.relation &gt; 0 -&gt;\n                    notify_relation_game_function_is_red(PlayerId,GameFunction #game_function.relation,FunctionId,IsRed);%通知父类联动的函数\n                true -&gt;\n                    update_game_function_cache(PlayerId,FunctionId,IsRed)\n            end\n    end.","slug":"游戏全局通知红点系统","date":"2019-08-23T09:44:00.000Z","categories_index":"设计方法","tags_index":"游戏","author_index":"Fly"},{"id":"cf4d6c3460b72521408e1365a505bd53","title":"Redis笔记","content":"\nRedis是什么、特点、优势redis是Key-Value数据库,数据包含各种数据 字符串String、字典Hash、列表List、集合Set、有序集合SortedSet等redis支持数据持久化，重启再次加载,支持数据备份(支持分布式),Redis是单进程单线程的Redis的优势性能高 读速度110000/s 写速度81000/s丰富的数据类型\n\nredis安装（Linux）、启动、退出、设置密码、远程连接\n\n1 安装redis下载redis安装包（如：redis-2.8.17.tar.gz）cd  redis-5.0.5makesrc/redis-server  也可改配置redis.conf 并修改 daemonize no 为 daemonize yes  启动服务端redis-server /usr/local/redis-5.0.5/redis.confsrc/redis-cli 启动客户端src/redis-cli shutdown 停止服务\ntar -zxvf redis-2.8.17.tar.gz\ncd redis-2.8.17\nmake\nsudo make install\n2 后台启动服务端\nnohup redis-server &amp;\n3 启动客户端、验证\ncd &#x2F;usr&#x2F;local&#x2F;bin\nredis-cli\nset var &quot;hello world&quot;\nget var\n\n\nReis key序号    Redis keys命令及描述1    DEL key该命令用于在 key 存在是删除 key。2    DUMP key序列化给定 key ，并返回被序列化的值。3    EXISTS key检查给定 key 是否存在。4    EXPIRE key seconds为给定 key 设置过期时间。5    EXPIREAT key timestampEXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。6    PEXPIRE key milliseconds设置 key 的过期时间亿以毫秒计。7    PEXPIREAT key milliseconds-timestamp设置 key 过期时间的时间戳(unix timestamp) 以毫秒计8    KEYS pattern查找所有符合给定模式( pattern)的 key 。例如keys * 返回所有的key9    MOVE key db将当前数据库的 key 移动到给定的数据库 db 当中。10    PERSIST key移除 key 的过期时间，key 将持久保持。11    PTTL key以毫秒为单位返回 key 的剩余的过期时间。12    TTL key以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。13    RANDOMKEY从当前数据库中随机返回一个 key 。14    RENAME key newkey修改 key 的名称15    RENAMENX key newkey仅当 newkey 不存在时，将 key 改名为 newkey 。16    TYPE key返回 key 所储存的值的类型。…中文文档\n\nRedis 发布订阅占时没用过，看起来跟微信公众号一样,Pub/Sub做延时队列可以用在玩家登录排队上\n\nRedis事务一个事务从开始到结束经过以下三个阶段：\n\n\n开始事务命令入队执行事务例子\nlocalhost:6379&gt; MULTI\nOK\nlocalhost:6379&gt; set name jihite\nQUEUED\nlocalhost:6379&gt; get name\nQUEUED\nlocalhost:6379&gt; sadd language &quot;c++&quot; &quot;python&quot; &quot;java&quot;\nQUEUED\nlocalhost:6379&gt; smembers language\nQUEUED\nlocalhost:6379&gt; exec\n说明：事务以MULTI开始，以EXEC结束\n\n关闭持久化与持久化(RDB)bgsave做镜像全量持久化，aof做增量持久化RDB相当于快照，是fork一个子进程，快照成功后替换aof相当于日志，cow，copy and write,一条一条的数据\n\n这是redis与其他缓存服务的比较明显的特点,如memcache修改配置文件，改完后重启。\n#save 900 1  \n#save 300 10  \n#save 60 10000  \n或执行操作命令\nCONFIG SET save &quot;&quot;\n\n\nredis相比memcached有哪些优势？\n\n(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型(2) redis的速度比memcached快很多(3) redis可以持久化其数据\n\nredis常见性能问题和解决方案：\n\n(1) Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件(2) 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次(3) 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内(4) 尽量避免在压力很大的主库上增加从库(5) 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3…\n这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。\n\nRedis 常见的性能问题都有哪些？如何解决？1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。4). Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内\n\nRedis分布式锁拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。\n\nRedis做异步队列一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。\n\nHash结构原子性操作Redis中提供了原子性命令SETEX或SET来写入STRING类型数据并设置Key的过期时间：\nSET key value EX 60 NX\nok\n&gt; SETEX key 60 value\nok\n但对于HASH结构则没有这样的命令，只能先写入数据然后设置过期时间：\nHSET key field value\nok\n&gt; EXPIRE key 60\nok\n这样就带了一个问题：HSET命令执行成功而EXPIRE命令执行失败（如命令未能成功发送到Redis服务器），那么数据将不会过期。推荐2种解决方式\n\n\n一.LUA脚本形式\n脚本部分的lua代码如下\nlocal fieldIndex&#x3D;3\nlocal valueIndex&#x3D;4\nlocal key&#x3D;KEYS[1]\nlocal fieldCount&#x3D;ARGV[1]\nlocal expired&#x3D;ARGV[2]\nfor i&#x3D;1,fieldCount,1 do\n  redis.pcall(&#39;HSET&#39;,key,ARGV[fieldIndex],ARGV[valueIndex])\n  fieldIndex&#x3D;fieldIndex+2\n  valueIndex&#x3D;valueIndex+2\nend\nredis.pcall(&#39;EXPIRE&#39;,key,expired)\n具体可以根据需求改造\n一般有2种形式\n1).eval 立即执行一段lua脚本代码，redisAPI函数有两个参数，第一个是lua脚本的字符串，第二个是对应脚本参数数组项目中具体使用如下\n&#x2F;**\n* hash原子批量操作\n* count 插入多少条数据\n* time 过期时间\n* data 数据key - value\n*&#x2F;\n    public async setOrAddList(databaseId: string, rowKey:string, count:number, time:number, data: any, flag?: QueryFlag): Promise&lt;boolean&gt; &#123;\n        rowKey &#x3D; this.getRowKey(rowKey);\n        let redisDb: Database &#x3D; this.service.connect(databaseId);\n        let dispatch &#x3D; redisDb.dispatch(flag);\n        let client &#x3D; dispatch.adapter;\n        let arr &#x3D; [];\n        arr.push(CommandMode.Key);&#x2F;&#x2F;key 标识1\n        arr.push(rowKey);\n        arr.push(count);\n        arr.push(time);\n        for(let k in data)&#123;\n            arr.push(k);\n            arr.push(data[k]);\n        &#125;\n        let luaStr &#x3D; &quot;local fieldIndex&#x3D;3;local valueIndex&#x3D;4;local key&#x3D;KEYS[1];local fieldCount&#x3D;ARGV[1];local expired&#x3D;ARGV[2];for i&#x3D;1,fieldCount,1 do redis.pcall(&#39;HSET&#39;,key,ARGV[fieldIndex],ARGV[valueIndex]) fieldIndex&#x3D;fieldIndex+2 valueIndex&#x3D;valueIndex+2 end;redis.pcall(&#39;EXPIRE&#39;,key,expired);&quot;\n        let result &#x3D; await client.EVAL(luaStr, arr);\n        if(!result)&#123;\n            logger.error(&#39;setOrAddList rowKey:%s count:%s&#39;, rowKey, count)\n        &#125;\n        return result\n    &#125;\n2). evalsha 这个先将lua脚本加载内存中得到一串文件码字符串，在通过字符串读取及传参\nSCRIPT LOAD &quot;local fieldIndex&#x3D;3;local valueIndex&#x3D;4;local key&#x3D;KEYS[1];local fieldCount&#x3D;ARGV[1];local expired&#x3D;ARGV[2];for i&#x3D;1,fieldCount,1 do redis.pcall(&#39;HSET&#39;,key,ARGV[fieldIndex],ARGV[valueIndex]) fieldIndex&#x3D;fieldIndex+2 valueIndex&#x3D;valueIndex+2 end;redis.pcall(&#39;EXPIRE&#39;,key,expired);&quot;\n&quot;e03e7868920b7669d1c8c8b16dcee86ebfac650d&quot;\n&gt; evalsha e03e7868920b7669d1c8c8b16dcee86ebfac650d 1 key 2 1000 field1 value1 field2 value2\n二：事务Redis命令只会在有语法错误或对Key使用了错误的数据类型时执行失败。因此，只要我们保证将正确的写数据和设置过期时间的命令作为一个整体发送到服务器端即可，使用Lua脚本正式基于此。 public async Task&lt;bool&gt; WriteAsync(string key, IDictionary&lt;string, string&gt; valueDict, TimeSpan expiry)\n&#123;\n    var tranc &#x3D; Database.CreateTransaction();\n    foreach (var item in valueDict)\n    &#123;\n        tranc.HashSetAsync(key, item.Key, item.Value);\n    &#125;\n    tranc.KeyExpireAsync(key, expiry);\n    return await tranc.ExecuteAsync();\n&#125;\n","slug":"redis笔记","date":"2019-08-01T08:52:31.000Z","categories_index":"IT笔记","tags_index":"redis","author_index":"Fly"},{"id":"64fa7148428d7d977cb2502b7dbd3115","title":"游戏中大型自动比赛玩法设计","content":"争霸赛赛程范例3月1日 0：00~3月3日 12:00    报名    40级以上手动报名3月3日 13：00    淘汰赛    “13:00取数据，提前1小时向玩家发送邮件提醒13:10开始出战报，每隔5分钟出1场战报天榜负5局进入地榜，地榜负5局则被淘汰”3月4日 14:00    16强赛（32进16）    “每小时1局，每局取1次数据，5局3胜制天地榜同时进行比赛开始前1小时向玩家发送邮件提醒取数据制度”3月5日 14:00    16进83月6日 14:00    8进43月7日 14:00    半决赛3月8日 14:00    决赛3月8日 决赛全部结束    统一发放奖励    \n比赛的时间控制由单独时间进程来控制时间的推进，相当于php中的crontab,表结构上一个玩家比赛进程表player_race,一个各阶段玩家成员信息表player_race_member，后期系统匹配各阶段玩家匹配信息表player_race_opponent，一个各阶段玩家战报信息表player_race_report，一个各阶段玩家结果表player_race_result，玩家表可以分为  玩家比赛信息表  player_st_jjc_race 玩家匹配信息表 player_st_jjc_race_opponent 玩家日志表 player_st_jjc_race_score_log\n第一步 报名很简单直接报名请求记录玩家数据就行,报名时间结束时触发事件对所有玩家进行匹配\ncase try_get_player_server_war(PlayerId) of\n    null -&gt;\n        Tran &#x3D; fun() -&gt;\n            game_db:write(#player_server_war &#123;\n                player_id  &#x3D; PlayerId, \n                apply_time &#x3D; lib_misc:get_local_timestamp()\n            &#125;)\n            % mod_deploy:get(PlayerId, ?RACE_SERVER_WAR)\n        end, \n        game_db:do(Tran);\n    _ -&gt;\n        exit(already_apply)\nend.\n\n% 本服报名结束手机玩家数据\napply_over() -&gt;\n    List &#x3D; get_all_player_server_war(),\n    Tran &#x3D; fun() -&gt;\n        lists:foreach(\n            fun(Rec) -&gt;\n                game_db:write(Rec #player_server_war &#123;\n                    race_step &#x3D; ?RS_TIAN_BANG_TAOTAI\n                &#125;)\n            end, \n            List\n        )\n    end,\n    game_db:do(Tran),\n    ?INFO(&quot;apply_over&quot;,[]),\n    ZoneList &#x3D; lists:foldl(\n        fun(PlayerServerWar, R) -&gt;\n            [PlayerServerWar #player_server_war.player_id | R]\n        end,\n        [],\n        get_all_player_server_war()\n    ),\n\n    mod_race:init_race_member(\n       ?RACE_SERVER_WAR,\n       0,\n       ?RS_TIAN_BANG_TAOTAI,\n       0,\n       ZoneList,\n       normal\n    ).\n注意的是用一个单独的进程来管理活动步骤开启结束\n\n% 每一个活动开始所要做的处理\nactivity_start (ActivityId) -&gt;\n    case mod_server:is_game_server() of\n        true -&gt;\n            xdh_race_srv:activity_start(ActivityId);\n        false -&gt;\n            case mod_server:is_cc_server() of\n                true -&gt;\n                    % cc_server_war_cron_srv:activity_start(Id);\n                    noop;\n                false -&gt;\n                    noop\n            end\n    end.\n\n% 每一个活动结束所要做的处理\nactivity_stop (ActivityId) -&gt;\n   case mod_server:is_game_server() of\n        true -&gt;\n            xdh_race_srv:activity_stop(ActivityId);\n        false -&gt;\n            case mod_server:is_cc_server() of\n                true -&gt;\n                    % cc_server_war_cron_srv:activity_stop(Id);\n                    noop;\n                false -&gt;\n                    noop\n            end\n    end.\n在到点时间的相应上做特殊处理\n第二步 开启淘汰赛淘汰赛的开启同样用时间进程来控制，到点后调用启动方法 （判断结束 、清上一轮数据）淘汰赛相当于一个递归的过程，全服玩家进行了一场比赛后记录玩家信息及淘汰结果直到淘汰赛结束的条件,同时需要一个全服步骤数据记录，然后循环比赛其中每一轮淘汰赛可分为 判断结束 、清上一轮数据 、不重复随机匹配 、 战斗及数据记录 、 循环 （不重复随机匹配 循环）\n&lt;!-- 战斗部分及记录 --&gt;\nrace_fight (RaceId, ZoneId, RaceStep, TeamIdA, TeamIdB) -&gt;\n    #player_race &#123;\n        race_times &#x3D; RaceTimes\n    &#125; &#x3D; get_player_race(RaceId, ZoneId), \n\n    Tran &#x3D; fun() -&gt;\n        case race_call(RaceId, fight, [RaceStep, TeamIdA, TeamIdB]) of\n            [] -&gt;\n                exit(&#123;invalid_fight, RaceId, TeamIdA, TeamIdB&#125;);\n            ReportList -&gt;\n                &#123;_, WinTeamId&#125; &#x3D; lists:foldr(\n                    fun(Report, &#123;NowIndex, NowWinTeamId&#125;) -&gt;\n                        #war_result &#123;\n                            winner       &#x3D; &#123;_, WinnerId&#125;, \n                            army_result1 &#x3D; #army_result &#123;\n                                army_key &#x3D; &#123;_, PlayerIdA&#125;\n                            &#125;, \n                            army_result2 &#x3D; #army_result &#123;\n                                army_key &#x3D; &#123;_, PlayerIdB&#125;\n                            &#125;\n                        &#125; &#x3D; Report, \n\n                        NewWinTeamId &#x3D; if\n                            NowIndex &#x3D;:&#x3D; length(ReportList) -&gt;\n                                WinTeamId &#x3D; if\n                                    WinnerId &#x3D;:&#x3D; PlayerIdA -&gt;\n                                        TeamIdA;\n                                    true -&gt;\n                                        TeamIdB\n                                end, \n\n                                game_db:write(#player_race_result &#123;\n                                    race_id     &#x3D; RaceId, \n                                    zone_id     &#x3D; ZoneId, \n                                    race_step   &#x3D; RaceStep, \n                                    player_id   &#x3D; TeamIdA, \n                                    player_id1  &#x3D; TeamIdB, \n                                    race_times  &#x3D; RaceTimes, \n                                    version     &#x3D; ?GET_ENV(vsn, &quot;&quot;), \n                                    report_time &#x3D; lib_misc:get_local_timestamp(), \n                                    winner_id   &#x3D; WinTeamId\n                                &#125;), \n\n                                WinTeamId;\n                            true -&gt;\n                                NowWinTeamId\n                        end, \n\n                        game_db:write(#player_race_report &#123;\n                            race_id     &#x3D; RaceId, \n                            zone_id     &#x3D; ZoneId, \n                            race_step   &#x3D; RaceStep, \n                            player_id   &#x3D; TeamIdA, \n                            race_times  &#x3D; RaceTimes, \n                            index       &#x3D; NowIndex, \n                            attacker_id &#x3D; PlayerIdA, \n                            defender_id &#x3D; PlayerIdB, \n                            winner_id   &#x3D; WinnerId, \n                            report_id   &#x3D; war_report_srv:record_war_report(Report, 30 * 86400)\n                        &#125;), \n\n                        &#123;\n                            NowIndex - 1, \n                            NewWinTeamId\n                        &#125;\n                    end, \n                    &#123;length(ReportList), 0&#125;, \n                    ReportList\n                ), \n\n                WinTeamId\n        end\n    end, \n\n    &#123;atomic, TeamId&#125; &#x3D; game_db:do(Tran), \n    TeamId.\n在淘汰赛结束后，将剩余晋级玩家进入晋级赛步骤，同时初始化随机匹配一下两种匹配方式\ninit_race_member(RaceId, ZoneId, RaceStep, Group, TeamIdList, normal) -&gt;\n    Tran &#x3D; fun() -&gt;\n        lists:foldl(\n            fun(TeamId, NowIndex) -&gt;\n                game_db:write(#player_race_member &#123;\n                    race_id   &#x3D; RaceId, \n                    race_step &#x3D; RaceStep, \n                    zone_id   &#x3D; ZoneId, \n                    group     &#x3D; Group, \n                    index     &#x3D; NowIndex, \n                    player_id &#x3D; TeamId\n                &#125;), \n\n                NowIndex + 1\n            end, \n            1, \n            TeamIdList\n        )\n    end, \n\n    game_db:do(Tran);\n\ninit_race_member(RaceId, ZoneId, RaceStep, Group, TeamIdList, random) -&gt;\n    #race_step &#123;\n        match_num &#x3D; MatchNum\n    &#125; &#x3D; get_race_step(RaceStep), \n\n    Step &#x3D; get_index_step(length(TeamIdList), MatchNum), \n\n    Tran &#x3D; fun() -&gt;\n        lists:foldl(\n            fun(TeamId, NowIndex) -&gt;\n                game_db:write(#player_race_member &#123;\n                    race_id   &#x3D; RaceId, \n                    race_step &#x3D; RaceStep, \n                    zone_id   &#x3D; ZoneId, \n                    group     &#x3D; Group, \n                    index     &#x3D; NowIndex, \n                    player_id &#x3D; TeamId\n                &#125;), \n\n                if\n                    NowIndex + Step &gt; MatchNum * 2 -&gt;\n                        1 + Step div 2;\n                    true -&gt;\n                        NowIndex + Step\n                end\n            end, \n            1, \n            lib_misc:shuffle(TeamIdList)\n        )\n    end, \n\n    game_db:do(Tran);\n\n第三步 战报战报开启也是进程时间来控制\n第四步 开启晋级赛同样是进程计时器开启，比赛流程除了一局定输赢以外和淘汰赛基本一致，比赛也是一次性打完，战报根据时间慢慢的播放\n% 开启杯赛\ntimer_start_race() -&gt;\n    case mod_server:is_cc_server() of\n        true -&gt;\n            % cc_server_war_cron_srv:start_race(0);\n            noop;\n        false -&gt;\n            Times &#x3D; mod_server:get_player_server_int_data(?SDT_SERVER_WAR_RACE_TIMES),\n            xdh_race_srv:try_apply(mod_server,set_player_server_int_data,[?SDT_SERVER_WAR_RACE_TIMES,Times + 1]),\n            start_race(),\n            mod_timer:reset(1, ?TIMER_XIAN_DAO_HUI_BEI_SAI)\n    end. \n\nstart_race() -&gt;\n    RaceStep    &#x3D; get_server_war_race_step(), \n    PlayerRace  &#x3D; mod_race:get_player_race(?RACE_SERVER_WAR,0),\n    IsOver &#x3D; case mod_race:start_race(?RACE_SERVER_WAR, 0, RaceStep, 3) of\n        true -&gt;\n            true;\n        _ -&gt; \n            mod_timer:reset(0, ?TIMER_XIAN_DAO_HUI_BEI_SAI, 3420),\n            false\n    end,\n\n    RaceTimes &#x3D; if\n        RaceStep &#x3D;&#x2F;&#x3D; PlayerRace #player_race.race_step -&gt;\n            1;\n        true -&gt;\n            PlayerRace #player_race.race_times + 1\n    end,\n    xdh_race_srv:try_apply(mod_server,set_player_server_int_data,[?SDT_SERVER_WAR_RACE_TIMES,RaceTimes]),\n    deal_receive_beisai_data(RaceStep,IsOver).\n\n战斗部分基本一致多一个匹配结果记录表\nstart_race(RaceId, ZoneId, RaceStep, WinTimes) -&gt;\n    #race_step &#123;\n        match_num &#x3D; MatchNum, \n        next_race &#x3D; NextRace, \n        next_step &#x3D; NextStep\n    &#125; &#x3D; get_race_step(RaceStep), \n\n    Tran &#x3D; fun() -&gt;\n        PlayerRace &#x3D; get_player_race(RaceId, ZoneId), \n\n        if\n            PlayerRace #player_race.race_step &#x3D;:&#x3D; RaceStep,\n                PlayerRace #player_race.race_times &#x3D;&#x2F;&#x3D; 0 -&gt;\n                case check_race_over(RaceId, ZoneId, RaceStep) of\n                    true -&gt;\n                        exit(race_over);\n                    _ -&gt;\n                        noop\n                end, \n\n                game_db:write(PlayerRace #player_race &#123;\n                    race_times &#x3D; PlayerRace #player_race.race_times + 1, \n                    last_time  &#x3D; lib_misc:get_local_timestamp()\n                &#125;);\n            true -&gt;\n                clear_race_data(RaceId, ZoneId, RaceStep), \n                init_race_opponent(RaceId, ZoneId, RaceStep), \n\n                game_db:write(PlayerRace #player_race &#123;\n                    race_step  &#x3D; RaceStep, \n                    race_times &#x3D; 1, \n                    last_time  &#x3D; lib_misc:get_local_timestamp(), \n                    win_times  &#x3D; WinTimes\n                &#125;)\n        end, \n\n        lists:foreach(\n            fun(Group) -&gt;\n                lists:foreach(\n                    fun(Index) -&gt;\n                        RaceMemberA &#x3D; try_get_player_race_member(RaceId, ZoneId, RaceStep, Group, Index * 2 - 1), \n                        RaceMemberB &#x3D; try_get_player_race_member(RaceId, ZoneId, RaceStep, Group, Index * 2), \n\n                        if\n                            RaceMemberA &#x3D;:&#x3D; null, RaceMemberB &#x3D;:&#x3D; null -&gt;\n                                noop;\n                            %%轮空为全空或者B为空\n                            % RaceMemberA &#x3D;:&#x3D; null -&gt;\n                            %     game_db:write(#player_race_member &#123;\n                            %         race_id   &#x3D; RaceId, \n                            %         race_step &#x3D; NextRace, \n                            %         group     &#x3D; Group, \n                            %         index     &#x3D; Index, \n                            %         player_id &#x3D; RaceMemberB #player_race_member.player_id\n                            %     &#125;);\n                            RaceMemberB &#x3D;:&#x3D; null -&gt;\n                                TeamIdA  &#x3D; RaceMemberA #player_race_member.player_id, \n\n                                case check_opponent_over(RaceId, ZoneId, RaceStep, TeamIdA) of\n                                    true -&gt;\n                                        noop;\n                                    _ -&gt;\n                                        Opponent &#x3D; try_get_player_race_opponent(RaceId, ZoneId, RaceStep, TeamIdA), \n\n                                        game_db:write(Opponent #player_race_opponent &#123;\n                                            winner_id &#x3D; TeamIdA\n                                        &#125;), \n\n                                        game_db:write(#player_race_member &#123;\n                                            race_id   &#x3D; RaceId,\n                                            zone_id   &#x3D; ZoneId, \n                                            race_step &#x3D; NextRace, \n                                            group     &#x3D; Group, \n                                            index     &#x3D; Index, \n                                            player_id &#x3D; TeamIdA\n                                        &#125;), \n\n                                        race_call(RaceId, race_win, [TeamIdA, Group, RaceStep, NextRace])\n                                end;\n                            true -&gt;\n                                TeamIdA &#x3D; RaceMemberA #player_race_member.player_id, \n                                TeamIdB &#x3D; RaceMemberB #player_race_member.player_id, \n\n                                case check_opponent_over(RaceId, ZoneId, RaceStep, TeamIdA) of\n                                    true -&gt;\n                                        noop;\n                                    _ -&gt;\n                                        case race_fight(RaceId, ZoneId, RaceStep, TeamIdA, TeamIdB) of\n                                            0 -&gt;\n                                                noop;\n                                            WinnerId -&gt;\n                                                case check_opponent_over(RaceId, ZoneId, RaceStep, TeamIdA, TeamIdB) of\n                                                    true -&gt;\n                                                        Opponent &#x3D; try_get_player_race_opponent(RaceId, ZoneId, RaceStep, TeamIdA), \n\n                                                        game_db:write(Opponent #player_race_opponent &#123;\n                                                            winner_id &#x3D; WinnerId\n                                                        &#125;), \n\n                                                        game_db:write(#player_race_member &#123;\n                                                            race_id   &#x3D; RaceId,\n                                                            zone_id   &#x3D; ZoneId, \n                                                            race_step &#x3D; NextRace, \n                                                            group     &#x3D; Group, \n                                                            index     &#x3D; Index, \n                                                            player_id &#x3D; WinnerId\n                                                        &#125;), \n\n                                                        race_call(RaceId, race_win, [WinnerId, Group, RaceStep, NextRace]);\n                                                    _ -&gt;\n                                                        noop\n                                                end\n                                        end\n                                end\n                        end\n                    end, \n                    lists:seq(1, MatchNum)\n                )\n            end, \n            get_all_race_group()\n        ), \n\n        IsOver &#x3D; check_race_over(RaceId, ZoneId, RaceStep), \n\n        if\n            IsOver &#x3D;:&#x3D; true -&gt;\n                NowPlayerRace &#x3D; get_player_race(RaceId, ZoneId), \n\n                game_db:write(NowPlayerRace #player_race &#123;\n                    race_step  &#x3D; NextStep, \n                    race_times &#x3D; 0, \n                    last_time  &#x3D; lib_misc:get_local_timestamp()\n                &#125;);\n            true -&gt;\n                noop\n        end, \n\n        IsOver\n    end, \n\n    &#123;atomic, Result&#125; &#x3D; game_db:do(Tran), \n    Result.\n\n第五步 出晋级赛战报\n% 播报战报及通知\ndeal_receive_beisai_data(RaceStep,IsOver) -&gt;\n    Tran &#x3D; fun() -&gt;\n        % write_race_data(RaceReportList,RaceResultList,MemberList,OpponentList, WorldWarList),\n        if  \n            IsOver &#x3D;:&#x3D; true -&gt;\n                #race_step &#123;\n                    next_step &#x3D; NextStep\n                &#125; &#x3D; mod_race:get_race_step(RaceStep),\n                % return_bet(RaceStep),\n                if\n                    RaceStep &#x3D;:&#x3D; ?RS_RACE_1 -&gt;\n                        % give_award(),给予奖励\n                        ZoneId &#x3D; 0,\n                        case mod_race:try_get_player_race_member(?RACE_SERVER_WAR, ZoneId, ?RS_RACE_1_OVER, ?RG_TIAN_BANG, 1) of\n                            null -&gt;\n                                noop;\n                            Member -&gt;\n                                ServerId   &#x3D; mod_player:get_player_data(Member #player_race_member.player_id,server_id),\n                                ServerName &#x3D; mod_server:get_server_name(ServerId),\n                                NickName   &#x3D; mod_player:get_player_data(Member #player_race_member.player_id,nickname),\n                                api_chat:centre_screen_message_notify(\n                                    ?MEST_XIAN_DAO_HUI_GUAN_JUN, \n                                    [&#123;ServerName&#125;,&#123;NickName&#125;]\n                                )\n                        end;\n                    true -&gt;\n                        noop\n                end,\n                mod_server:set_player_server_int_data(?SDT_SERVER_WAR_RACE_STEP, NextStep), \n                mod_server:set_player_server_int_data(?SDT_SERVER_WAR_RACE_TIMES, 0),\n                mod_timer:close(1,?TIMER_XIAN_DAO_HUI_BEI_SAI);\n            true -&gt;\n                noop\n        end\n    end,\n    game_db:do(Tran).\n    % api_server_war:notify_new_report().","slug":"游戏中大型比赛玩法设计思路","date":"2019-07-30T08:08:45.000Z","categories_index":"设计方法","tags_index":"游戏","author_index":"Fly"},{"id":"dfb30fc03fd62385d2aef0d277edc760","title":"Erlang List模块函数使用大全","content":"Erlang List模块函数使用大全\n一，带函数Pred1, all(Pred, List) -&gt; boolean()如果List中的每个元素作为Pred函数的参数执行，结果都返回true，那么all函数返回true，否则返回false\n例子：\nlists:all(fun(E) -&gt; true end,[1,2,3,4]).\n结果\ntrue\n2, any(Pred, List) -&gt; boolean()如果List中至少有一个元素作为Pred函数的参数执行，结果返回true，那么any函数返回true，否则返回false\n例子\nlists:any(fun(E) -&gt; is_integer(E) end,[q,2,a,4]).\n结果\ntrue\n3，dropwhile(Pred, List1) -&gt; List2将List1列表中的元素作为参数执行Pred函数，如果返回true，将其丢弃，最后返回剩余元素组成的列表\n例子\nlists:dropwhile(fun(E) -&gt; is_atom(E) end,[a,1,2,a,b]).\n结果\n[1,2,a,b]\n4，filter(Pred, List1) -&gt; List2返回一个列表，这个列表是由List1中执行Pred函数返回true的元素组成。\nlists:filter(fun(E) -&gt; is_integer(E) end,[q,2,a,4]).\n结果：\n[2,4]\n \n\n5，map(Fun, List1) -&gt; List2将List1中的每个元素去在Fun中执行，然后返回一个元素，最后返回的这些元素组成一个列表，返回给List2例子：lists:map(fun(X)-&gt;[X,X] end, [a,b,c]).结果：[[a,a],[b,b],[c,c]]\n6，flatmap(Fun, List1) -&gt; List2这个函数和map比较类似，相当于执行了lists:append(lists:map(List1)).也就是把map的结果进行append处理例子：lists:flatmap(fun(X)-&gt;[X,X] end, [a,b,c]).结果：[a,a,b,b,c,c]\n7，foldl(Fun, Acc0, List) -&gt; Acc1Fun这个函数有两个参数第一个参数是List中的元素，第二个参数是Fun函数执行完后的返回值，这个参数第一次执行时就是Acc0例子：对[1,2,3,4,5]求和lists:foldl(fun(X, Sum) -&gt; X + Sum end, 0, [1,2,3,4,5]).结果：15执行过程：首先，Fun第一次执行时，X的值取列表List的第一个元素1，Sum取0,  Fun第二次执行时，X的值取列表List的第二个元素2，Sum取Fun第一次的返回值  依次轮推，直到List中每个元素执行完，最后foldl返回最后一次的结果。\n8，foldr(Fun, Acc0, List) -&gt; Acc1foldr这个函数和foldl比较相似不过是Fun执行时，X的值先取List的最后一个，然后取倒数第二个。\n9，foreach(Fun, List) -&gt; ok以List中的每个元素为参数执行Fun函数，执行顺序按照List中元素的顺序，这个函数最后返回ok。是单边的例子 lists:foreach(fun(X)-&gt;  %%using X to do somethings  %%  end,List)\n10，keymap(Fun, N, TupleList1) -&gt; TupleList2对TupleList1中的每个元素的第N项作为参数在Fun中处理，然后这个第N项最后就被替换为Fun执行完返回的值例子：List1 = [{name,”zhangjing”},{name,”zhangsan”}].lists:keymap(fun(X)-&gt;  list_to_atom(X)  end,2,List1).结果：[{name,zhangjing},{name,zhangsan}]\n11，mapfoldl(Fun, Acc0, List1) -&gt; {List2, Acc1}这个函数等于是把map和foldl函数结合起来。将List1中的每一个元素执行Fun函数，执行后花括号的第一个值作为返回值返回，第二个值作为参数传给Fun，作为下一次用。例子：lists:mapfoldl(fun(X, Sum) -&gt; {2*X, X+Sum} end,0, [1,2,3,4,5]).{[2,4,6,8,10],15}\n12，mapfoldr(Fun, Acc0, List1) -&gt; {List2, Acc1}这个函数相当于将map和foldr结合起来\n13，merge(Fun, List1, List2) -&gt; List3这个函数的功能也是把List1和List2合并到一起，只不过是List1和List2的元素要作为参数在Fun中执行，如果Fun返回true，那么返回值就是List1在前，List2在后。否则，反之。例子lists:merge(fun(A,B)-&gt; false end, [3,4],[2,1]).结果[2,1,3,4]\n14，partition(Pred, List) -&gt; {Satisfying, NotSatisfying}这个函数的功能是将List分成两个List1和List2，List1是将List元素作为参数去Pred函数中执行返回true的元素组成，List2由Pred返回false的元素组成。注意，返回的是一个元组例子lists:partition(fun(A) -&gt; A rem 2 == 1 end, [1,2,3,4,5,6,7]).结果{[1,3,5,7],[2,4,6]}\n15，sort(Fun, List1) -&gt; List2如果Fun函数返回true，则排序是从小到大的顺序，否则，从大到小。其中Fun有两个参数。例子lists:sort(fun(A,B)-&gt; false end,[1,2,3]).结果[3,2,1]\n16，splitwith(Pred, List) -&gt; {List1, List2}将List分成List1和List2，List1由List中元素在Pred函数返回true的组成，但是有一点，如果遇到为false的，则将剩下的元素全部放到List2中，List1中就只有前面为true的。例子lists:splitwith(fun(A) -&gt; is_atom(A) end, [a,b,1,c,d,2,3,4,e]).结果{[a,b],[1,c,d,2,3,4,e]}\n17，takewhile(Pred, List1) -&gt; List2List1中的元素element依次执行Pred(element),如果返回true，则获取这个元素，直到有元素执行Pred(element)返回false例子lists:takewhile(fun(E)-&gt; is_atom(E) end,[a,b,1,e,{c},[d]]).结果[a,b]\n18,umerge(Fun, List1, List2) -&gt; List3这个函数和merge不同的是 当Fun返回true时，返回的List3中不能出现相同的元素疑问：但是当Fun返回false时，List3中可以有相同的元素。例子(Fun返回true的情况)lists:umerge(fun(A,B)-&gt; true end,[1,2],[2,3]).结果[1,2,3](Fun为false的情况)lists:umerge(fun(A,B)-&gt; false end,[1,2],[2,3]).[2,3,1,2]好神奇，竟然2有重复\n19，usort(Fun, List1) -&gt; List2按照Fun函数进行排序，如果Fun返回true，那么只返回List1的第一个元素如果Fun返回false，那么List1从大到小排序例子1lists:usort(fun(A,B) -&gt; true end, [1,2,2,3,4]).结果[1]\n例子2lists:usort(fun(A,B) -&gt; false end, [1,2,2,3,4]).结果[4,3,2,2,1]\n20，zipwith(Combine, List1, List2) -&gt; List3将List1和list2中的每个元素执行Combine函数，然后返回一个元素，List3就是由Combine函数返回的一个个元素组成的。功能和map有点像，但是这里是对两个列表的操作。例子lists:zipwith(fun(X, Y) -&gt; X+Y end, [1,2,3], [4,5,6]).结果[5,7,9]\n21，zipwith3(Combine, List1, List2, List3) -&gt; List4将List1和list2，list3中的每个元素执行Combine函数，然后返回一个元素，List4就是由Combine函数返回的一个个元素组成的。功能和map有点像，但是这里是对三个列表的操作。例子lists:zipwith3(fun(X, Y, Z) -&gt; X+Y+Z end, [1,2,3], [4,5,6],[7,8,9]).结果[12,15,18]\n二，不带函数Pred1，append(ListOfLists) -&gt; List1ListOfLists都是由List组成的，而List一个列表，里面可以是任何类型的元素这个函数就是将ListOfLists里面的所有列表的元素按顺序编成一个列表提示：ListOfLists里面的元素必须都是列表才能用这个函数\n例子\nlists:append([[1, 2, 3], [a, b], [4, 5, 6]]).\n结果：\n[1,2,3,a,b,4,5,6]\n2，append(List1, List2) -&gt; List3将List1和List2两个列表连接起来，组成一个列表，然后返回新的这个列表这个函数的功能等同于List1 ++ List2\n例子\nlists:append(“abc”, “def”).\n结果\n“abcdef”\n3，concat(Things) -&gt; string()这里的Things是一个列表，里面由atom() | integer() | float() | string()将这个列表里面的元素拼成一个字符串，然后返回\n例子\nlists:concat([doc, ‘/‘, file, ‘.’, 3]).\n结果\ndoc/file.3”\n4，delete(Elem, List1) -&gt; List2List1是由很多Element组成的，这个函数的功能是在List1中寻找第一个和Elem元素一样的，然后删除之，返回删除后新的列表。\n例子\nlists:delete({name,”zhangsan”},[{name,”lisi”},{name,”zhangsan”},{name,”wangmazi”})).\n结果\n[{name,”lisi”},{name,”wangmazi”}]\n5，duplicate(N, Elem) -&gt; List返回一个由N个Elem组成的列表。\n例子\nlists:duplicate(5,”test”).\n结果\n[“test”,”test”,”test”,”test”,”test”]\n6，flatlength(DeepList) -&gt; integer() &gt;= 0我的理解是DeepList就是列表里面套列表计算列表的长度，即用flatten函数将DeepList转化成List后元素的个数这个函数和length()的区别就是：length函数是得到列表元素的个数，而flatlength函数是先将DeepList转化成List后的个数譬如说List = [1,2,[3,4]]这个列表用length(List)求的值是：3lists:flatlength(List)求的值是：4其实lists:flatlength(List) = length(flatten(List))\n7，flatten(DeepList) -&gt; List将DeepList变成只有term()的list例子：lists:flatten([[a,a],[b,b],[c,c]]).结果：[a,a,b,b,c,c]\n8，flatten(DeepList, Tail) -&gt; List就是将DeepList变成只有term的List后，在后面再加一个Tail。例子：lists:flatten([[a,a],[b,b],[c,c]],[dd]).结果：[a,a,b,b,c,c,dd]\n9,keydelete(Key, N, TupleList1) -&gt; TupleList2这个函数适合处理列表里面的元素是元组的情况删除TupleList1中元素第N个元素和Key一致的元素，只删除第一个一样的，后面一样的不删除例子：List = [{name,”zhangjing”},{sex,”male”},{name,”zhangsan”},{sex,”male”}],lists:keydelete(“male”,2,List)结果：[{name,”zhangjing”},{name,”zhangsan”},{sex,”male”}]\n10,keyfind(Key, N, TupleList) -&gt; Tuple | false查找TupleList中的一个Tuple，如果查找到，返回，如果没有查找到，则返回false这个Tuple必须满足第N个元素和key是一样。例子：List1 = [{name,”zhangjing”},{name,”zhangsan”}].lists:keyfind(“zhangjing”,2,List1)结果：{name,”zhangjing”}\n11，keymember(Key, N, TupleList) -&gt; boolean()如果TupleList中的元素中存在第N个元素和key一致，则返回true，否则返回false例子：List1 = [{name,”zhangjing”},{name,”zhangsan”}].lists:keymember(“zhangjing”,2,List1).结果：true\n12，keymerge(N, TupleList1, TupleList2) -&gt; TupleList3将TupleList1和TupleList2进行混合，组成一个TupleList，新组成的TupleList是按照Tuple的第N个元素进行排序的例子：List1 = [{name,”zhangjing”},{name,”zhangsan”}].List2 = [{nick,”zj”},{nick,”zs”}].lists:keymerge(2,List1,List2).结果：[{name,”zhangjing”}, {name,”zhangsan”}, {nick,”zj”}, {nick,”zs”}]\n13，keyreplace(Key, N, TupleList1, NewTuple) -&gt; TupleList2在TupleList1的Tuple中找出第N个元素和Key一致，然后用NewTuple将这个Tuple替换掉，如果没有找到，则返回原来的TupleList1例子：List1 = [{name,”zhangjing”},{name,”zhangsan”}]lists:keyreplace(“zhangjing”,2,List1,{nickname,”netzj”}).结果：[{nickname,”netzj”},{name,”zhangsan”}]\n14，keysearch(Key, N, TupleList) -&gt; {value, Tuple} | false这个函数和keyfind差不多，就是返回值的结构不一样也是在TupleList中找一个Tuple，这个Tuple的第N个元素和Key一样。例子：List1 = [{name,”zhangjing”},{name,”zhangsan”}]lists:keysearch(“zhangjing”,2,List1).结果：{value,{name,”zhangjing”}}\n15，keysort(N, TupleList1) -&gt; TupleList2对TupleList1中的Tuple按照第N个元素进行排序，然后返回一个新的顺序的TupleList。不过这种排序是固定的。例子：List1 = [{name,”zhangsan”},{name,”zhangjing”}].lists:keysort(2,List1).结果：[{name,”zhangjing”},{name,”zhangsan”}]\n16，keystore(Key, N, TupleList1, NewTuple) -&gt; TupleList2这个函数和keyreplace函数比较像，不同的是，这个keystore在没有找到对应的Tuple时，会将这个NewTuple追加在这个TupleList1的最后。例子：List1 = [{name,”zhangsan”},{name,”zhangjing”}].找到了的情况lists:keystore(“zhangjing”,2,List1,{name,”netzhangjing”}).[{name,”netzhangjing”},{name,”zhangsan”}]没有找到的情况lists:keystore(“zhanging”,2,List1,{name,”netzhangjing”}).[{name,”zhangjing”},{name,”zhangsan”},{name,”netzhangjing”}]\n17，keytake(Key, N, TupleList1) -&gt; {value, Tuple, TupleList2} | false在TupleList1中找Tuple，这个Tuple的第N个元素和Key一致，如果找到了这么一个Tuple那么返回，{value, Tuple, TupleList2} 其中TupleList2是去掉Tuple的TupleList1.例子：List1 = [{name,”zhangjing”},{name,”zhangsan”},{name,”lisi”}].lists:keytake(“zhangjing”,2,List1).结果：{value,{name,”zhangjing”},[{name,”zhangsan”},{name,”lisi”}]}\n18，last(List) -&gt; Last返回：List最后一个元素例子：List1 = [{name,”zhangjing”},{name,”zhangsan”},{name,”lisi”}].lists:last(List1).结果：{name,”lisi”}\n19，max(List) -&gt; Max取出List中最大的元素，一般List是整型时比较适合。例子：lists:max([1,10,15,6]).结果：15\n20，member(Elem, List) -&gt; boolean()如果Elem和List中的某个元素匹配（相同），那么返回true，否则返回false例子lists:member({sex,”1”},[{sex,”1”},{sex,”2”},{sex,”3”}]).结果：true\n21，merge(ListOfLists) -&gt; List1ListOfLists是一个列表，里面由子列表构成这个函数的功能就是将这些子列表合并成一个列表。例子：lists:merge([[{11}],[{22}],[{33}]]).结果[{11},{22},{33}]\n22，merge(List1, List2) -&gt; List3List1和List2分别是一个列表，这个函数的功能是将这两个列表合并成一个列表。例子：lists:merge([11],[22]).结果[11,22][2,1,3,4]\n23, merge3(List1, List2, List3) -&gt; List4将List1，List2，List3合并成一个列表例子lists:merge3([11],[22],[33,44]).结果：[11,22,33,44]\n24，min(List) -&gt; Min返回List中的最小的元素，和max函数对应例子lists:min([1,2,3]).结果1\n25，nth(N, List) -&gt; Elem返回List中的第N个元素。例子lists:nth(2,[{name,”zhangsan”},{name,”lisi”},{name,”wangmazi”}]).结果{name,”lisi”}\n26，nthtail(N, List) -&gt; Tail返回List列表中第N个元素后面的元素例子lists:nthtail(3, [a, b, c, d, e]).结果[d,e]\n27，prefix(List1, List2) -&gt; boolean()如果List1是List2的前缀(也就是说List1和List2前部分相同)，那么返回true，否则返回false\n28，reverse(List1) -&gt; List2将List1反转例子lists:reverse([1,2,3,4]).结果[4,3,2,1]\n29,reverse(List1, Tail) -&gt; List2将List1反转，然后将Tail接在反转List1的后面，然后返回例子lists:reverse([1, 2, 3, 4], [a, b, c]).[4,3,2,1,a,b,c]\n30，seq(From, To) -&gt; Seq其中From和To都是整型，这个函数返回一个从From到To的一个整型列表。例子lists:seq(1,10).结果[1,2,3,4,5,6,7,8,9,10]\n31，seq(From, To, Incr) -&gt; Seq返回一个整型列表，这个列表的后一个元素比前一个元素大Incr。例子lists:seq(1,10,4).[1,5,9]\n32，sort(List1) -&gt; List2将List1中的元素从小到大排序，然后返回新的一个列表。例子lists:sort([3,2,1]).结果[1,2,3]\n33，split(N, List1) -&gt; {List2, List3}将List1分成List2和List3其中List2包括List1的前N个元素，List3包含剩余的。例子lists:split(3,[1,2,3,4,5]).结果{[1,2,3],[4,5]}\n这个函数和partition数有区别，partition是遍历全部的List，而splitwith在遍历时遇到false的情况则马上结束遍历，返回结果。\n34，sublist(List1, Len) -&gt; List2返回从第一个元素到第Len个元素的列表，这个Len大于List1的长度时，返回全部。例子lists:sublist([1,2,3,4,5,6],3).结果[1,2,3]\n35，sublist(List1, Start, Len) -&gt; List2返回从List1的第Start个位置开始，后面Len个元素的列表。例子lists:sublist([1,2,3,4], 2, 2).结果[2,3]\n36，subtract(List1, List2) -&gt; List3等同于 List1 – List2这个函数功能是返回一个List1的副本，对于List2中的每个元素，第一次在List1副本中出现时被删掉。例子lists:subtract(“112233”,”12”).结果“1233”\n37，suffix(List1, List2) -&gt; boolean()如果List1是List2的后缀，那么返回true，否则返回false例子lists:suffix(“22”,”1122”).结果true\n38，sum(List) -&gt; number()返回List中每个元素的和。其中List中的元素都应该是number()类型的。例子lists:sum([1,2,3,4]).结果10\n39，ukeymerge(N, TupleList1, TupleList2) -&gt; TupleList3TupleList1和TupleList2里面的元素都是元组将TupleList1和TupleList2合并，合并的规则是按照元组的第N个元素，如果第N个元素有相同的，那么保留TupleList1中的，删除TupleList2中的。\n40，ukeysort(N, TupleList1) -&gt; TupleList2TupleList1里面的元素都是元组这个函数也同样返回一个元素是元组的列表，返回的这个列表是按照元组的第N个元素来排序的，如果元组中有出现第N个元素相同的情况，删除掉后面的一个元组。例子lists:ukeysort(1,[{name,”zhangsan”},{sex,”male”},{name,”himan”}]).结果[{name,”zhangsan”},{sex,”male”}]\n41，umerge(ListOfLists) -&gt; List1这个函数和merge唯一不同的就是，里面不能出现相同的元素，如果出现相同的，那么删除之，只保留一个唯一的例子lists:umerge([[1,2],[2,3]]).结果[1,2,3]分析：由于[[1,2],[2,3]]中merge后是[1,2,2,3],这个时候有两个相同的元素2，所以只保存一个2，所以结果是[1,2,3].\n42，umerge3(List1, List2, List3) -&gt; List4将List1, List2, List3合并和merge3不同的是返回的List4中不能出现重复的元素例子lists:merge3([1,2],[2,3],[3,4]).结果[1,2,3,4]\n43，unzip(List1) -&gt; {List2, List3}List1里面的元素是元组，每个元组由两个元素组成，返回值List2包含每个List1中每个元组的第一个元素返回值List3包含每个List1中每个元组的第二个元素。例子lists:unzip([{name,”zhangsan”},{sex,”male”},{city,”hangzhou”}]).结果{[name,sex,city],[“zhangsan”,”male”,”hangzhou”]}\n44，unzip3(List1) -&gt; {List2, List3, List4}List1里面的元素是元组，每个元组由三个元素组成，返回值List2包含每个List1中每个元组的第一个元素；返回值List3包含每个List1中每个元组的第二个元素；返回值List4包含每个List1中每个元组的第三个元素。例子lists:unzip3([{name,”zhangsan”,”apple”},{sex,”male”,”banana”},{city,”hangzhou”,”orange”}]).结果{[name,sex,city], [“zhangsan”,”male”,”hangzhou”], [“apple”,”banana”,”orange”]}注意，最终返回的是一个元组。\n45，usort(List1) -&gt; List2将List1按照从小到大的顺序排序，如果排序后有重复的元素，删除重复的，只保存一个唯一的。例子lists:usort([4,3,2,1,2,3,4]).结果[1,2,3,4]\n46，zip(List1, List2) -&gt; List3将两个长度相同的列表合并成一个列表List3是里面的每一个元组的第一个元素是从List1获取的，而每个元组的第二个元素是从List2中获取的例子lists:zip([name,sex,city],[“zhangsan”,”male”,”hangzhou”]).结果[{name,”zhangsan”},{sex,”male”},{city,”hangzhou”}]注意，如果List1和List2长度不一致，那么这个函数将会报错。\n47，zip3(List1, List2, List3) -&gt; List4将三个长度相同的列表合并成一个列表List3是里面的每一个元组的第一个元素是从List1获取的，而每个元组的第二个元素是从List2中获取的每个元组的第三个元素是从List3中获取的。例子lists:zip3([name,sex,city],[“zhangsan”,”male”,”hangzhou”],[“nick”,”1”,”zhejiang”]).结果[{name,”zhangsan”,”nick”}, {sex,”male”,”1”}, {city,”hangzhou”,”zhejiang”}]\n","slug":"Erlang List模块函数使用大全","date":"2019-05-07T11:49:16.000Z","categories_index":"IT笔记","tags_index":"Erlang","author_index":"Fly"},{"id":"6977849a35ac85d5974580bb39a3c432","title":"Erlang OTP学习","content":"1.-behaviour(gen_server)它表示让编译器检查，当前module是否实现了gen_server指定的所有回调接口\n2.gen_server:start_link(ServerName, Module, Args, Options) -&gt; Result这个方法用来启动一个server，其中：参数ServerName指定了服务名参数Module指定了该server的callback模块参数Args将作为服务初始化的启动参数（服务初始化时会调用：Module:init([Args])）参数Options指定了一些特性参数，通常可以直接使用[] \n如果服务启动成功，返回{ok, Pid} \n3.Module:init([Args])这个方法会在服务初始化时被回调，参数Args就是gen_server:start_link中倒数第二个参数，若初始化成功，该方法放回{ok, State},其中State将作为启动服务的State \n4.gen_server:call(ServerRef, Request)这个方法供callback模块向ServerRef代表的服务发送Request请求（callback模块通常会在之上再封装一层接口供客户端调用，譬如这里的add，find方法），注意该方法是一个同步调用，它会一直等待服务器返回一个响应消息（除非等待超时，默认5s） \n5.Module:handle_call(Request, From, State) -&gt; Result这是一个回调方法，用来处理gen_server:call(ServerRef, Request)发出的请求，其中：Request，表示客户端请求From，表示请求来自哪个客户端State，表示当前服务器状态 \nResult为handle_call 请求处理结果，它有以下几种类型{reply,Reply,NewState}{reply,Reply,NewState,Timeout}{reply,Reply,NewState,hibernate}{noreply,NewState}{noreply,NewState,Timeout}{noreply,NewState,hibernate}{stop,Reason,Reply,NewState} | {stop,Reason,NewState} \n这几种返回值有什么区别呢？如果返回的是以reply开头，那么Reply将会作为响应返回给客户端如果返回的是以noreply开头，那么服务器将不会返回任何消息给客户端（这会导致客户端阻塞，因为客户端调用的gen_server:call方法是一个同步调用，当它发出请求后，会一直等待服务器发送响应消息，除非等待超时） \n6.gen_server:cast(ServerRef, Request)这个方法同gen_server:call(ServerRef, Request)，但它最大的区别就是该调用是异步的，它不需要等待服务器返回任何处理结果 \n7.Module:handle_cast(Request, State) -&gt; Result这个方法用来处理gen_server:cast(ServerRef, Request)发出的请求，由于不会返回结果给客户端，所以参数列表中也没有From \n8.检查进程是否加载\nerlang:whereis(?MODULE).\n\n9.查看进程的信息\nerlang:process_info(pid(0,PID,0)).","slug":"Erlang-OTP学习","date":"2019-04-09T08:50:32.000Z","categories_index":"IT笔记","tags_index":"Erlang","author_index":"Fly"},{"id":"defb885747aad5561de89a9d3d99e7f0","title":"充值流程","content":"接触到的充值流程是这样的1.客户端发起请求-&gt;lcm后台，lcm后台确认充值成功，会将充值的金额变成平台货币保存在平台端，并通知到客户端充值成功，收到充值成功的客户端对游戏服务端发起请求，游戏服务端收到请求后，请求lcm平台调用spend方法，平台确认信息相符就扣币并告诉游戏服务端消费成功，游戏服务端在将平台货币转换为对应的游戏币，同时告诉客户端充值成功\n2.平台充值成功会产生回调直接通知游戏服务端，服务端接收请求，后请求平台spend，成功后发币记录，客户端请求服务端查到有记录就告知客户端成功不做spend\n掉单：如果掉单1.平台回调请求会保证执行spend方法，达到补单的效果2.客户端能读到平台币，直接通过平台剩余币与游戏服务端直接交易\n注意：任何时间判断以天为单位要特别小心，如果出现两版批次连续很容易出问题\n","slug":"充值流程","date":"2019-03-06T12:01:38.000Z","categories_index":"设计方法","tags_index":"游戏","author_index":"Fly"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2019-01-01T08:50:32.000Z","categories_index":"","tags_index":"","author_index":"Fly"},{"id":"7a8e11fd23f49077811a339d4019e863","title":"C++设计模式","content":"c++设计模式：\n简单工厂模式\n工厂模式有一种非常形象的描述，建立对象的类就如一个工厂，而需要被建立的对象就是一个个产品；在工厂中加工产品，使用产品的人，不用在乎产品是如何生产出来的。从软件开发的角度来说，这样就有效的降低了模块之间的耦合。\n使用情景：  在不确定会有多少个处理操作时应该考虑使用简单工厂模式，如针对同样的接收到的数据，处理的逻辑可能会不同，可能以后还会增加新的操作。案例：如果实现计算器的功能时，对于同样的输入数据，可能执行加、减、乘、除，甚至其他的功能。因此可以抽象出一个操作的抽象类或是接口，提供一个统一的处理方法(此处为process)，然后每种操作创建出一个子类出来。而判断具体使用哪个具体的实现类是在工厂类中进行判断的(将存放操作的变量传递给工厂的生产方法)。工厂类始终返回的是这个抽象类，这样如果对原有功能进行更改或是新添加新的功能，也不会对原来的其他类做修改，只编译修改的那个类或是新的类就可以了。这样就做到了把耦合降到最低，同时也便于维护。 \n简单工厂：针对同样的数据，不同的操作用同一个接口\n工厂方法：针对同样的数据，不同的操作用不同的接口\n抽象工厂：针对不同的数据，不同的操作用不同的接口\n策略模式：依赖c++的多态，抽象类的指针可以访问所有子类对象，（纯虚函数），可以用一个指针访问所有策略的实现类\n单例模式：单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例单例模式(不能让一个程序打开两次  如：不能同时打开2个迅雷  迅雷用的单例模式)\n访问者模式:适用于数据结构相对未定的系统，它把数据结构和作用于结构上的操作之间的耦合解脱开，使得操作集合可以相对自由的演化。访问者模式使得增加新的操作变的很容易，就是增加一个新的访问者类。访问者模式将有关的行为集中到一个访问者对象中(做任何更改不需要修改基类，不依赖虚函数)\n观察者模式：定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态上发生变化时，会通知所有观察者对象，使他们能够自动更新自己。(QT的信号机制，Windows的消息机制都应用了观察者模式，还有订阅邮件，邮件到了就会给你发邮件)\n建造者模式：使得产品内部表象可以独立地变化，客户不必知道产品内部组成的细节。可以强制实行一种分步骤进行的建造过程。用一个接口完成不同的操作，需要对客户的需求进行把握。(如：登陆QQ，自动选择所在地的服务器)\n解释器模式：给定一个语言后，解释器模式可以定义出其文法的一种表示，并同时提供一个解释器。客户端可以使用这个解释器来解释这个语言中的句子。(如：360读取lua脚本，这个细节的实现就是解释器模式)\n命令模式：把发出命令的责任和执行命令的责任分割开，委派给不同的对象允许请求的一方和发送的一方独立开来，使得请求的一方不必知道接收请求的一方的接口，更不必知道请求是怎么被接收，以及操作是否执行，何时被执行以及是怎么被执行的。(命令模式在客户端与服务器之间用的最多 (C/S架构))\n模板模式：不同的子类可以以不同的方式实现这些抽象方法，\n从而对剩余的逻辑有不同的实现。先制定一个顶级逻辑框架，\n而将逻辑的细节留给具体的子类去实现。(适用于本地化，做一个软件，在日本是日文，美国是英语…)\n桥接模式：将抽象化与实现化脱离，使得二者可以独立的变化，\n也就是指在一个软件系统的抽象化和实现化之间使用组合聚合关系而不是继承关系，从而使两者可以独立的变化。(相当于配电脑去装机，把各个模块组合到一起)\n适配器模式：把一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口原因不匹配而无法一起工作的两个类能够一起工作。\n外观模式：外部与一个子系统的通信必须通过一个统一的外观对象进行。每一个子系统只有一个外观类，而且此外观类只有一个实例，也就是说它是一个单例模式。但整个系统可以有多个外观类。(多个子系统方法都需要一个外观类统一管理，用统一的接口方便消费者使用)\n享元模式：享元模式大幅度的降低内存中对象的数量，使用享元模式主要是为了优化内存，相同功能可以并行使用。\n原型模式：允许动态的增加或减少产品类，产品类不需要非得有任何事先确定的等级结构，原始模型模式适用于任何的等级结构。缺点是每一个类都必须配备一个克隆方法。\n责任链模式：在责任链模式中，很多对象由每一个对象对其下家的引用而接起来形成一条链。请求在这个链上传递，直到链上的某一个对象决定处理此请求。处理者有两个选择：承担责任或者把责任推给下家。一个请求可以最终不被任何接收端对象所接受。(例如：晚上去上英语课，为了好开溜坐到了最后一排，哇，前面坐了好几个漂亮的MM哎，找张纸条，写上“Hi, 可以做我的女朋友吗？如果不愿意请向前传”，纸条就一个接一个的传上去了，糟糕，传到第一排的MM把纸条传给老师了)\n中介者模式：中介者模式包装了一系列对象相互作用的方式，\n使得这些对象不必相互明显作用。从而使他们可以松散偶合。\n当某些对象之间的作用发生改变时，不会立即影响其他的一些对象之间的作用。（如：TCP/IP打洞技术）\n装饰模式：装饰模式以对客户端透明的方式扩展对象的功能是继承关系的一个替代方案，提供比继承更多的灵活性。动态给一个对象增加功能，这些功能可以再动态的撤消。增加由一些基本功能的排列组合而产生的非常大量的功能。\n状态模式：意图是让一个对象在其内部状态改变的时候，其行为也随之改变。状态模式需要对每一个系统可能取得的状态创立一个状态类的子类。当系统的状态变化时，系统便改变所选的子类。(如：到了晚上12点要睡觉，到了早上8点要起床…这就是状态)\n合成模式：将对象组织到树结构中，可以用来描述整体与部分的关系。合成模式就是一个处理对象的树结构的模式。合成模式把部分与整体的关系用树结构表示出来。(用于树状结构)\n","slug":"c++设计模式","date":"2018-12-25T14:38:51.000Z","categories_index":"IT笔记","tags_index":"c++,设计模式","author_index":"Fly"},{"id":"eb22ca4ed9e8d1628dcb03e5412b9b1b","title":"Pomelo学习笔记","content":"重新认识pomelo服务器配置在server.json里，通过app.js设置服务器及路由，每一个服务器在server下对应一个文件及为一个进程，其中一定包含handler逻辑代码部分不一定包含remote（远程通信、服务器监听用）例如以下\nself.app.rpc.chat.chatRemote.add(session, uid, self.app.get(&#39;serverId&#39;), rid, true, function(users)&#123;\n\t\tnext(null, &#123;\n\t\t\tusers:users\n\t\t&#125;);\n\t&#125;);\n增加服务器改server.json扩充，然后在连接服务器中逻辑进行选服\nmodule.exports.dispatch &#x3D; function(uid, connectors) &#123;\n\tvar index &#x3D; Math.abs(crc.crc32(uid)) % connectors.length;\n\treturn connectors[index];\n&#125;;\nfilter用于请求前及请求后的处理,可以用于请求排队，或者测试接口时间app.js中可以配置路由压缩及回包压缩方式\napp.set(&#39;connectorConfig&#39;,\n\t&#123;\n\t\tconnector : pomelo.connectors.hybridconnector,\n\t\tuseProtobuf : true,\n\t\tuseDict: true &#x2F;&#x2F; enable dict\n\t&#125;);\n&#125;);\n自建组件在app文件夹下在建立一个自己定义的文件夹，里面有start afterStart stop\napp.configure(&#39;production|development&#39;, &#39;master&#39;, function() &#123;\n  app.load(helloWorld, &#123;interval: 5000&#125;);\n&#125;);\n\n一个admin module中一般包括四个回调方法，monitorHandler，masterHandler，clientHandler, start。其中monitorHandler是monitor收到master的请求或者通知时由monitor回调，masterHandler是master收到monitor的请求或者通知时回调，clientHandler是master收到client的请求或通知时回调的, start是当admin module加载完成后，用来执行一些初始化监控时调用。\n组件master组件monitor组件connector组件session组件connection组件server组件pushScheduler组件proxy组件remote组件dictionary组件protobuf组件channel组件backendSession组件具体看https://github.com/NetEase/pomelo/wiki/%E7%BB%84%E4%BB%B6%E6%A6%82%E8%BF%B0\n环境\ngetBase()\t Application.getBase(); 获取应用程序的基本路径\nset(setting, val, attach);\t Application.set();  setting:应用程序的配置；val:需要设置的值；attach:是否将设配置应用到程序。设置或返回配置的值。\nget(setting)\t Application.get(); setting:应用程序的配置。获取配置的值\nenabled(setting)\t Application.enabled(); setting:应用程序的配置。检查配置是否启用\ndisabled(setting)\t Application.disabled(); setting:应用程序的配置。检查配置是否禁用\nenbale(setting)\t Application.enbale(); setting:应用程序的配置。启用配置\ndisable(setting)\t Application.disabled(); setting:应用程序的配置。禁用配置\nconfigure(env,fn,type)\tApplication.configure();env:应用环境;fn:回调函数;type:服务类型.\n初始化\nstart()\t Application.start(); 启动应用程序。它会加载默认的组件和启动所有加载的组件。\nregisterAdmin(moduleId,module,opts)\t Application.registerAdmin();  moduleId:(可选参数)模块id或者有modeule提供的模块Id;module:模块对象或者模块的工程函数;opts:模块构造函数的参数。\nfilter(filter)\t Application.filter(); filter:provide before and after filter method。add a filter to before and after filter\nbefore(bf)\t Application.before(); bf:before filter。Add before filter\nafter(af)\t Application.after(); af:after filter。Add after filter\nload(name, component, opts)\t Application.load(); name:组件的名称（可选）；component：组件的实例或者组件的工厂函数；opts：组件构造函数的参数（可选）。加载组件\nloadConfig(key,val)\t Application.loadConfig(); key:环境配置的关键字;val:环境配置的值。导入json文件来配置环境。\n\n组件相关\nroute(serverType, routeFunc)\t\n Application.route(); serverType:服务类型;routeFunc:路由功能函数,如：routeFunc(session, msg, app, cb)\n\n未指定的服务类型设置路由功能。如：\n\napp.route(&#39;area&#39;, routeFunc);\n\nvar routeFunc &#x3D; function(session, msg, app, cb) &#123;\n\n　　&#x2F;&#x2F; all request to area would be route to the first area server\n\n　　var areas &#x3D; app.getServersByType(&#39;area&#39;);\n\n　　cb(null, areas[0].id);\n\n&#125;\n获取相关配置，组件方法\ngetMaster()\tApplication.getMaster() 获得Maseter服务的信息\ngetCurServer()\tApplication.getCurServer() 获得当前服务的信息\ngetServerId()\tApplication.getServerId() 获得当前服务的ID\ngetServerType()\tApplication.getServerType() 获得当前服务的类型\ngetServers()\tApplication.getServers() 获得所有当前服务的信息\ngetServersFromConfig()\tApplication.getServersFromConfig() 从server.json中获得所有服务的信息\ngetServerTypes()\tApplication.getServerTypes() 获得所有服务的类型\ngetServerById(serverId)\tApplication.getServerById() 根据服务ID从服务集群中获得服务的信息\ngetServerFromConfig(serverId)\tApplication.getServerFromConfig() 根据服务ID从server.json中获得服务的信息\ngetServersByType(serverType)\tApplication.getServersByType() 根据服务类型获取服务信息\nisFrontend(server)\tApplication.isFrontend() 检查服务是否是一个前端服务\nisBackend(server)\tApplication.isBackend() 检查服务是否是一个后端服务\nisMaster()\tApplication.isMaster() 检查当前服务是否是主服务\naddServers(servers)\tApplication.addServers() servers：新服务信息列表。添加新服务信息到正在运行的应用程序中\nremoverServers(ids)\tApplication.removerServers() ids：服务id列表。从当前运行的应用程序中删除服务信息。\n创建和维护本地服务的信道。\ncreateChannel(name)\tChannelService.prototype.createChannel() 根据信道名称创建信道，如果该信道已存在则返回已存在的信道\ngetChannel(name,create)\tChannelService.prototype.getChannel() name:信道名称，create:如果为true，并且信道不存在时，则创建新的信道。根据信道名称获取信道\ndestroyChannel(name)\tChannelService.prototype.destroyChannel() 根据信道名称，删除信道\npushMessageByUids(route, msg, uids, cb)\tChannelService.prototype.pushMessageByUids() route：消息路由；msg：发送到客户端的消息；uids：接收消息的客户端列表，格式 [&#123;uid: userId, sid: frontendServerId&#125;]；cb：回调函数 cb(err)。根据uids将消息推送给客户端，如果uids中的sid未指定，则忽略相应的客户端\nbroadcast(stype,route, msg, opts, cb)\tChannelService.prototype.broadcast() stype：前端服务的类型;route：路由;msg：消息;opts：广播参数;cb：回调函数。广播消息到所有连接的客户端。\nChannel\nadd(uid,sid)\tChannel.prototype.add() uid:用户编号；sid：用户连接到的前端服务id。添加指定用户到信道。\nleave(uid,sid)\tChannel.prototype.leave() uid:用户编号；sid：用户连接到的前端服务id。从信道中移除用户。\ngetMembers()\tChannel.prototype.getMembers() 获得信道中的成员\ngetMember(uid)\tChannel.prototype.getMember() 根据uid获取成员信息\ndestroy()\tChannel.prototype.destroy() 销毁信道\npushMessage(route,msg,cb)\tChannel.prototype.pushMessage()  route：消息路由，msg：要推送的消息，cb：回调函数。将消息推送给信道的所有成员。\nGlobalChannelService\ndestroyChannel(name,cb)\tGlobalChannelService.prototype.destroyChannel() uid:用户编号；sid：用户连接到的前端服务id。添加指定用户到信道。\nadd(name,uid,sid,cb)\t\nGlobalChannelService.prototype.add() name:信道名称；uid：用户id；sid：前端服务id；cb：回调函数。\n\n添加成员到信道。\n\nleave(name,uid,sid,cb)\tGlobalChannelService.prototype.leave() \nname:信道名称；uid：用户id；sid：前端服务id；cb：回调函数。\n\n从信道中移除成员。\n\npushMessage()\t\nGlobalChannelService.prototype.pushMessage(serverType, route, msg,channelName, opts, cb)\n\nserverType：前端服务的类型, route：路由, msg：需要推送的消息,channelName：信道名称, opts：参数, cb：回调函数\n\n通过全局信道发送消息\nLocalSessionService\nget(frontendId,sid,cb)\tLocalSeesionService.prototype.get() frontendId:会话链接的前端服务id,sid:会话Id,cb:回调函数。根据前端服务和会话id获得本地会话\ngetByUid(name,uid,sid,cb)\t\nLocalSeesionService.prototype.getByUid()  frontendId:会话链接的前端服务id,uid：绑定到会话的用户id，cb：回调函数。args: cb(err, localSessions)。根据前端服务和用户id获取本地会话。\n\nkickBySid(name,uid,sid,cb)\tLocalSeesionService.prototype.kickBySid() frontendId:会话链接的前端服务id,sid:会话Id,cb:回调函数。根据会话id踢掉该会话。\nkickByUid()\t\nLocalSeesionService.prototype.kickByUid() frontendId:会话链接的前端服务id,uid：用户id,cb:回调函数。根据用户id踢掉该会话。\nLocalSession\nbind(uid,cb)\tLocalSeesion.prototype.bind() uid:用户编号;cb:回调函数。callfunction(err)。绑定当前会话，用于前端服务的推送和全局会话的绑定。\nunbind(uid,cb)\t\nLocalSeesion.prototype.unbind() uid:用户编号;cb:回调函数。callfunction(err)。取消绑定。\n\nset(key,value)\tLocalSeesion.prototype.set() 将key&#x2F;value添加到本地会话中\nget(key)\t\nLocalSeesion.prototype.get() 根据key从本地会话中获取值。\n\npush(key,cb)\t\nLocalSeesion.prototype.push() 将本地会话中的key&#x2F;value添加到全局会话中\n\npushAll(cb)\tLocalSeesion.prototype.pushAll() 将本地会话中的所有key&#x2F;value添加到全会话中\nSessionService\nkick(uid,cb)\tSeesionService.prototype.kick() 踢掉该用户的所有离线会话\nkickBySession(sid,cb)\t\nSeesionService.prototype.kickBySession() sid:会话编号;cb:回调函数。根据会话id踢掉一个在线用户\n\nsendMessage(sid,msg)\tSeesionService.prototype.sendMessage()根据会话id向客户端发送消息\nsendMessageByUid(uid,msg)\t\nSeesionService.prototype.sendMessageByUid() 根据用户id向客户端发送消息\nPomelo\ncreateApp(opts)    Pomelo.create() 创建一个Pomelo 应用程序\n\n\n\n","slug":"pomelo学习笔记","date":"2018-10-23T11:34:45.000Z","categories_index":"IT笔记","tags_index":"node.js","author_index":"Fly"},{"id":"5d576bc5d97b72bd5c880644e758fd3d","title":"Node笔记","content":"第一章 node简介1.1 node的特点    1.1.1 异步I/O 绝大多数操作以异步方式进行调用    1.1.2 事件与回调函数    1.1.3 单线程，但是可以用WebWorkers的方式解决单线程的问题（子进程），用Master-Worker用master统一管理子进程    1.1.4 跨平台    1.1.5 c++速度大约是node的2.5倍\n1.2 模块机制    1.2.1 分为核心模块和文件模块，require没带路径的为核心模块，直接加载进内存，带路径的为文件模块,核心模块中有c++和javascript两部分，其中buffer、crypto、evals、fs、os、等都是c++部分的    1.2.2 npm安装的核心模块插件在package.json中定义\n1.3 异步I/O    1.3.1 操作系统内核对I/O只有：阻塞I/O和非阻塞I/O，node中的异步I/O模型由事件循环、观察者、请求对象、I/O线程池    整个系统可以理解为事件循环相当于厨子，不停的询问是否有新的订单，观察者相当于收银员，收到用户的订单将订单分给厨子，而订单相当于请求对象，参数、方法、回调函数斗封装在请求对象中,    以上是异步I/O的第一步，io线程池相当于放订单的桌子，  请求对象-&gt;I/O线程池-&gt;观察者-&gt;事件循环    1.3.2 非异步的I/O主要是setTimeout(),setInterval(),setImmediate(),process.nextTick()\n\n1.4 异步编程    1.4.1 异步编程的解决方案分为3个：        1）事件发布/订阅模式        2）Promise/Deferred模式        3）流程控制库    1.4.2 事件发布/订阅模式    &#x2F;&#x2F;订阅\nemitter.on(&quot;event1&quot;,function(message)&#123;\n\tconsole.log(message);\n&#125;);\n&#x2F;&#x2F;发布\nemitter.emit(&#39;event1&#39;,&quot;I Love you&quot;);    1）继承events模块    var events &#x3D; require(&#39;events&#39;);\n\nfunction Stream()&#123;\n\tevents.EventEmitter.call(this);\n&#125;\nutil.inherits(Stream,events.EventEmitter);    2)利用事件队列解决崩溃问题    事件发布/订阅模式中一般只有一个once()方法，用一个『状态锁』或者『事件队列』防止崩溃    状态锁    var status &#x3D; &quot;ready&quot;;\nvar select &#x3D; function(callback)&#123;\n\tif(status &#x3D;&#x3D; &quot;ready&quot; )&#123;\n\t\tstatus &#x3D; &quot;pending&quot;;\n\t\tdb.select(&quot;SQL&quot;, function(results)&#123;\n\t\t\tstatus &#x3D; &quot;ready&quot;;\n\t\t\tcallback(results);\n\t\t&#125;);\n\t&#125;\n&#125;;    事件队列    var proxy &#x3D; new events.EventEmitter();\nvar status &#x3D; function (callback) \n\tproxy.once(&quot;selected&quot;, callback);\n\tif(status &#x3D;&#x3D;&#x3D; &quot;ready&quot;)&#123;\n\t\tstatus &#x3D; &quot;pending&quot;;\n\t\tdb.select(&quot;SQL&quot;, function(result)&#123;\n\t\t\tproxy.emit(&quot;selected&quot;,result);\n\t\t\tstatus &#x3D; &quot;ready&quot;;\n\t\t&#125;);\n\t&#125;\n&#125;    3）多异步之间的协作方案    借组一个第三方函数和第三方变量来处理异步协作的结果    var after &#x3D; function (times,callback)&#123;\n\tvar count &#x3D; 0, results &#x3D; &#123;&#125;;\n\treturn function (key, value)&#123;\n\t\tresult[key] &#x3D; value;\n\t\tcount++;\n\t\tif(count &#x3D;&#x3D;&#x3D; times)&#123;\n\t\t\tcallback(results);\n\t\t&#125;\n\t&#125;\n&#125;\n\nvar done &#x3D; after(times, render);    1.4.3 Promise/Deferred模式    Promise是高级接口，事件是低级接口，Promise更像链表    Promise中有3种状态    pending - 进行中    fulfilled - 成功    rejected - 失败    状态一旦改变就不可更改，在回调还是同样结果，但是事件错过了监听是得不到结果的    1.4.4 async流程控制模块    1）async的series()方法实现串行（不传参）    async.series([\n\tfunction (callback)&#123;\n\t\tfs.readFile(&#39;file1.txt&#39;,&#39;utf-8&#39;,calback);\n\t&#125;,\n\tfunction (callback)&#123;\n\t\tfs.readFile(&#39;file2.txt&#39;,&#39;utf-8&#39;,calback);\n\t&#125;\n],function (err,result)&#123;\n\t&#x2F;&#x2F;result &#x3D; [file1.txt,file2.txt]等价于先处理file1.txt，在处理file2.txt，错误回调\n&#125;);    2）async的parallel()方法实现并行    async.parallel([\n\tfunction (callback)&#123;\n\t\tfs.readFile(&#39;file1.txt&#39;,&#39;utf-8&#39;,calback);\n\t&#125;,\n\tfunction (callback)&#123;\n\t\tfs.readFile(&#39;file2.txt&#39;,&#39;utf-8&#39;,calback);\n\t&#125;\n],function (err,result)&#123;\n\t&#x2F;&#x2F;result &#x3D; [file1.txt,file2.txt]等价于并行处理file1.txt，在处理file2.txt，错误回调\n&#125;);    3）async的waterfall()方法实现串行（传参）    略    4）async.auto()可以根据依赖关系自动分析，以最佳顺序执行    略    1.4.5 流程控制模块Step    1)Step接受任意数量任务，所有任务传行执行    Step(\n\tfunction (callback)&#123;\n\t\tfs.readFile(&#39;file1.txt&#39;,&#39;utf-8&#39;,this);\n\t&#125;,\n\tfunction (callback)&#123;\n\t\tfs.readFile(&#39;file2.txt&#39;,&#39;utf-8&#39;,this);\n\t&#125;,\n\tfunction done(err, content) &#123;\n\t\t console.log(content);\n\t&#125;\n);    2)Step实现异步任务并行执行要用this的parallel()    Step(\n\tfunction (callback)&#123;\n\t\tfs.readFile(&#39;file1.txt&#39;,&#39;utf-8&#39;,this.parallel());\n\t&#125;,\n\tfunction (callback)&#123;\n\t\tfs.readFile(&#39;file2.txt&#39;,&#39;utf-8&#39;,this.parallel());\n\t&#125;,\n\tfunction done(err, content) &#123;\n\t\t console.log(arguments);\n\t&#125;\n);    1.4.6流程控制模块wind    1)wind的$await()方法实现异步等待    2）wind的whenAll()处理并发\n1.5 异步并发控制    1.5.1 bagpipe解决办法（API添加过载保护，用队列控制并发）    var Bagpipe &#x3D; require(&#39;bagpipe&#39;);\n&#x2F;&#x2F;设定最大并发数为10\nvar bagpipe &#x3D; new Bagpipe(10);\nfor(var i &#x3D; 0; i&lt; 100;i++)&#123;\n\tbagpipe.push(async, function ()&#123;\n\n\t&#125;);\n&#125;\nbagpipe.on(&#39;full&#39;,function (length)&#123;\n\tconsole.warn(&#39;底层系统处理不及时&#39;);\n&#125;);    1.5.2 拒绝模式    var bagpipe &#x3D; new Bagpipe(10,&#123;\n\trefuse: true\n&#125;);    1.5.3 超时控制    var bagpipe &#x3D; new Bagpipe(10, &#123;\n\ttimeout: 3000\n&#125;);\n1.6 内存管理    1.6.1 v8内存分为新生代和老生代的    node –max-old-space-size 2048 xxx.js 调整内存大小执行某个脚本    v8堆内存64位系统是1.4G,32位系统是0.7G    新生代内存的回收机制是将堆内存一分为2，使用中的是From，空的是to，进行垃圾回收时，是将from中的存活对象复制到to中，然后释放非存活的，同时from和to对换，缺点是只能使用一半的内存空间    老生带内存的回收机制是将from中的使用的标记，回收未使用的    1.6.2 内部变量无法被外部方法访问 叫闭包    1.6.3 查看内存使用process.memoryUsage() os.totalmem os.freemem \n1.7 Buffer    1.7.1 Buffer与字符串转换    new Buffer(str, [encoding]);\nbuf.write(string, [offset], [length], [encodeing]);\nbuf.tostring([encoding], [start], [end]);1.8 网络    1.8.1 tcp协议中的osi模型（分为 物理层、数据链路层、网络层、传输层、会话层、表示层、应用层）    server    var net &#x3D; require(&#39;net&#39;);\nvar server &#x3D; net.createServer(function(socket)&#123;\n\tserver.on(&#39;data&#39;,function(data)&#123;\n\t&#125;);\n\tserver.on(&#39;end&#39;,function(data)&#123;\n\t&#125;);\n\tserver.on(&#39;error&#39;,function(data)&#123;\n\t&#125;);\n\tserver.write(&#39;data&#39;);\n&#125;);\n\nserver.listen(port,function()&#123;\n&#125;)    client    var net &#x3D; require(&#39;net&#39;);\nvar client &#x3D; net.connect(&#123;port: 8124&#125;,function(socket)&#123;\n\tclient.on(&#39;data&#39;,function(data)&#123;\n\t&#125;);\n\tclient.on(&#39;end&#39;,function(data)&#123;\n\t&#125;);\n\tclient.on(&#39;error&#39;,function(data)&#123;\n\t&#125;);\n\tclient.write(&#39;data&#39;);\n&#125;);    1.8.2 UDP是用户数据包协议，一个套接字可以与多个UDP通信    server    var dgrm &#x3D; require(&quot;dgrm&quot;);\nvar server &#x3D; dgrm.createSocket(&quot;udp4&quot;);\nserver.on(&quot;message&quot;, function (msg, rinfo)&#123;\n\tconsole.log(&quot;xxx&quot;);\n&#125;);\nserver.on(&quot;listening&quot;, function() &#123;\n\tvar address &#x3D; server.address();\n\tconsole.log(&quot;xxx&quot;);\n&#125;);\nserver.bind(41234);    client    var dgram &#x3D; require(&#39;dgram&#39;);\nvar messgae &#x3D; new Buffer(&quot;xxxx&quot;);\nvar client &#x3D; dgram.createSocket(&quot;udp4&quot;);\nclinet.send(message, 0, message.length, 41234, &quot;localhost&quot;, function(err,bytes)&#123;\n\tclient.close();\n&#125;);    1.8.3 HTTP是构建在TCP之上属于应用层协议    https_request : function(host, path, post_data, cb)&#123;\n    var reqdata &#x3D; JSON.stringify(post_data);\n\tvar options &#x3D; &#123;\n\t    hostname: host,\n\t    port: 443,\n\t    method: &#39;POST&#39;,\n\t    path: path,\n\t    headers: &#123;\n\t        &#39;Content-Type&#39;: &#39;application&#x2F;json&#39;\n\t    &#125;\n\t&#125;;\n\n\tvar req_time_out &#x3D; setTimeout(function() &#123;\n    \t\treq.abort();\n    \t\tcb(400, &#123;code:400,message:&#39;请求超时&#39;&#125;);\n    \t\tlogger.n.info(&#39;Got Request Timeout.&#39;);\n\t&#125;, 10000);\n\n\tvar req &#x3D; https.request(options, function (res) &#123;\n\t\tclearTimeout(req_time_out);\n\t\t&#x2F;&#x2F;等待响应60秒超时\n\t\tvar res_time_out &#x3D; setTimeout(function() &#123;\n\t\t\tres.destroy();\n\t\t\tcb(400, &#123;code:400,message:&#39;响应超时&#39;&#125;);\n\t\t\tlogger.n.info(&#39;Got Response Timeout.&#39;);\n\t\t&#125;, 60000);\n\t\tvar status_code &#x3D; res.statusCode;\n\t\tvar body &#x3D; null;\n\t\tlogger.n.info(&quot;Got status_code: &quot; + status_code);\n\t\tres.on(&#39;data&#39;,function(data)&#123;\n            body &#x3D; JSON.parse(data);\n        &#125;).on(&#39;end&#39;, function()&#123;\n        \tclearTimeout(res_time_out);\n        \tcb(status_code, body);\n        &#125;);\n\t&#125;).on(&#39;error&#39;, function(e) &#123;\n\t\tcb(400, &#123;code:400,message:e.message&#125;);\n\t\tlogger.n.info(&quot;Got error: &quot; + e.message);\n    &#125;);\n\treq.write(reqdata);\n\treq.end();\n   &#125;    1.8.4 WebSocket    client       var client&#x3D; new net.Socket();\nvar flag &#x3D; true;\nvar port &#x3D; 0;\n\nclient.on(&#39;connect&#39;,function ()&#123;\n    &#x2F;&#x2F;正常连接\n    flag &#x3D; true;\n    logger.boot.info(&#39;socket Connection succeed&#39;);\n&#125;);\nclient.on(&#39;end&#39;, function() &#123;\n    &#x2F;&#x2F;flag&#x3D;false;\n    logger.n.warn(&#39;!!!!!tcp_client disconnected&#39;);\n    setTimeout(Fight_Service.tcp_reconnect, 1000);\n&#125;);\nclient.on(&#39;data&#39;,function(data)&#123;\n    &#x2F;&#x2F;得到服务端返回来的数据\n    Fight_Service.processResp(data);\n&#125;);\nclient.on(&#39;error&#39;,function(error)&#123;\n    &#x2F;&#x2F;错误出现之后关闭连接\n    flag &#x3D; false;\n    logger.n.error(&#39;socket error:&#39; + error);\n    client.destroy();\n    setTimeout(Fight_Service.tcp_reconnect, 1000);\n&#125;);\nclient.on(&#39;close&#39;,function()&#123;\n    &#x2F;&#x2F;正常关闭连接\n    flag &#x3D; false;\n    logger.n.warn(&#39;socket Connection closed&#39;);\n    client.destroy();\n&#125;);\n\nFight_Service.tcp_reconnect &#x3D; function(worker_id)&#123;\n   &#x2F;&#x2F;创建socket客户端\n   client.setEncoding(&#39;binary&#39;);\n\n   if (port &#x3D;&#x3D; 0 )&#123;\n       &#x2F;&#x2F;连接到服务端115.159.186.60 8400\n       &#x2F;&#x2F; logger.boot.info(&quot;socket process_work_id:&quot; + worker_id);\n       worker_id &#x3D; worker_id % 8;\n       port &#x3D; 8400 + worker_id;\n   &#125;else&#123;\n       logger.boot.info(&quot;socket tcp_reconnect&quot;);\n   &#125;\n\n   logger.boot.info(&quot;socket_port_id:&quot; + port);\n\n   client.connect(port,&quot;10.96.71.91&quot;);\n&#125;\n1.9 多进程    1.9.1 child_process模块    1）spawn()启动一个子进程执行命令，无回调，无超时    2）exec()启动一个子进程执行命令，有回调，有超时    3）execFile()启动一个子进程执行可执行文件    4）fork()启动node子进程执行js文件模块    node.js在js执行中是单线程的，但是单线程的进程没办法用像多线程那样直接利用多核cpu，那么node.js就得用主从进程的方式fork出新的子进程，在用master主进程管理分配给子进程，通过多个node子进程的使用来利用多核cpu    var fork &#x3D; require(&#39;child_process&#39;).fork;\nvar cpus &#x3D; require(&#39;os&#39;).cpus();\nfor(var i &#x3D; 0; i &lt; cpus.length; i++)&#123;\n\tfork(&#39;.&#x2F;worker.js&#39;);\n&#125;    1.9.2 进程间通信IPC，主线程与工作线程之间通过onmessage()和postMessage()进行通信，子进程对象则由send()方法实现主进程向子进程发送数据    1.9.3 句柄是一种用来标识资源的引用，用来拓展有限的文件描述符    child.send(message,[sandHandle])如（child.send(&#39;server&#39;,server)）;\n子进程代码\nprocess.on(&#39;message&#39;,function(m, server)&#123;\n\tif(m &#x3D;&#x3D; &#39;server&#39;)&#123;\n\txxxxx\n&#125;\n&#125;)    1.9.4 父进程可以通过kill()方法给子进程发送一个SIGTERM信号杀进程    chid.kill([signal]);\nprocess.kill(pid, [signal]);    在退出中加入自动重启可能会有新用户进来请求丢失的情况，工作进程在得知退出时，向主进程发送一个自杀信号（达到先创建在退出进程）    &#x2F;**\n * cluster mode\n *&#x2F;\nif (   opts.get(&#39;cluster&#39;)\n    || config.APP_CLUSTER.ENABLE) &#123;\n    var cluster &#x3D; require(&#39;cluster&#39;);\n    if (cluster.isMaster) &#123;\n        console.log(&#39;[CLUSTER MODE] MASTER&#39;);\n        for (var i&#x3D;0; i&lt;config.APP_CLUSTER.NUM; i++) &#123;\n            cluster.fork();\n        &#125;\n        cluster.on(&#39;exit&#39;, function(worker, code, signal) &#123;\n            console.log(&#39;worker &#39; + worker.process.pid + &#39; died&#39;);\n            cluster.fork();\n        &#125;);\n        return;\n    &#125;\n    console.log(&#39;[CLUSTER MODE] WORKER&#39;);\n&#125;    每个新的子进程监听新对应的端口，同时主进程给子进程的分配中大部分是根据一个特点id,比如玩家的特定id%开的进程数平均分配给不同的进程，没有用户要求的情况可以根据子进程数量随机分配请求如下    export function repoRouteTmp(_session: any, msg: any, app: any, next: Function) &#123;\n    let servers &#x3D; app.getServersByType(&#39;repo&#39;);\n    if (!servers || servers.length &#x3D;&#x3D;&#x3D; 0) &#123;\n        next(new Error(&#39;can not find server info for type: &#39; + msg.serverType));\n        return;\n    &#125;\n    let str &#x3D; app.getServerId();\n    let id &#x3D; parseInt(str.replace(&#x2F;[^\\d]&#x2F;g, &#39;&#39;));\n    let server_list: any &#x3D; [];\n    if (id) &#123;\n        let len &#x3D; servers.length;\n        for (let i &#x3D; 0; i &lt; len; i++) &#123;\n            let repo_id &#x3D; parseInt(servers[i].id.replace(&#x2F;[^\\d]&#x2F;g, &#39;&#39;));\n            if (repo_id &gt; 20 &amp;&amp; id &gt; 20) &#123;\n                server_list.push(servers[i].id);\n            &#125; else if (repo_id &lt; 20 &amp;&amp; id &lt; 20) &#123;\n                server_list.push(servers[i].id);\n            &#125;\n        &#125;\n    &#125;\n    let serverId &#x3D; 0\n    if (server_list &amp;&amp; server_list.length) &#123;\n        let end &#x3D; server_list.length - 1;\n        let index &#x3D; randomRange(0, end);\n        serverId &#x3D; server_list[index]\n    &#125; else &#123;\n        let user_id &#x3D; (msg.data || msg).user_id || &#96;$&#123;randomNum()&#125;&#96;; &#x2F;&#x2F; 游客时使用随机\n        let count: number &#x3D; Array.isArray(servers) ? servers.length : 1;\n        let index &#x3D; Math.abs(crc.crc32(user_id)) % count;\n        serverId &#x3D; servers[index].id || 0;\n    &#125;\n    next(undefined, serverId);\n&#125;;    虽然利用了多进程调度的形式利用了多核的cpu来提升效率，但是进程间的通信开销还是不小的\n同时进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。\n\n在加上node本身底层的异步io与事件循环本身用的是Libuv的库，这是一个c/c++的跨平台的的基于事件驱动的异步io库，本身是可以利用多线程的属性处理密集io，但是不可否认js本身的优势地方和js的局限性，决定了node.js的性能会低于c++\n\n虽然线程和进程有本质的区别，但是在串行程序的基础上，线程和进程都是为了能提高程序的效率，线程执行开销小，但不利于资源的管理和保护；而进程正相反。同时，线程适合于在SMP机器上运行，而进程则可以跨机器迁移\n\n在进程内创建、终止线程比创建、终止进程要快；\n\n同一进程内的线程间切换比进程间的切换要快,尤其是用户级线程间的切换。1.10 插件    1.10.1 Sequelizejs  此插件在option索引的位置千万不能写错，写错有大几率导致db堵塞    Model.findAll(&#123;\n \t\tattributes: [&#39;foo&#39;, [&#39;bar&#39;, &#39;baz&#39;]]\n&#125;);\nSELECT foo, bar AS baz ...\nModel.findAll(&#123;\n  attributes: [[sequelize.fn(&#39;COUNT&#39;, sequelize.col(&#39;hats&#39;)), &#39;no_hats&#39;]]\n&#125;);\nSELECT COUNT(hats) AS no_hats ...\nPost.findAll(&#123;\n  where: &#123;\n    [Op.or]: [&#123;authorId: 12&#125;, &#123;authorId: 13&#125;]\n  &#125;\n&#125;);\nSELECT * FROM post WHERE authorId &#x3D; 12 OR authorId &#x3D; 13;\nOrder.findAll(&#123;attributes:[&#39;name&#39;, [sequelize.fn(&#39;SUM&#39;, sequelize.col(&#39;price&#39;)), &#39;sum&#39;]], group:&#39;name&#39;, having:[&#39;COUNT(?)&gt;?&#39;, &#39;name&#39;, 1], raw:true&#125;).then(function(result)&#123;\n console.log(result);\n&#125;)\nSELECT &#96;name&#96;, sum(&#96;price&#96;) AS &#96;sum&#96; FROM &#96;orders&#96; AS &#96;Orders&#96; GROUP BY name HAVING COUNT(&#39;name&#39;)&gt;1;\n1.10.2 Lodashjs\n[文档](https://www.lodashjs.com/docs/4.17.5.html)\n\n_.indexOf(array, value, [fromIndex=0])\nnumber): Returns the index of the matched value, else -1.\n_.indexOf([1, 2, 1, 2], 2);\n&#x2F;&#x2F; &#x3D;&gt; 1\n \n&#x2F;&#x2F; Search from the &#96;fromIndex&#96;.\n_.indexOf([1, 2, 1, 2], 2, 2);\n&#x2F;&#x2F; &#x3D;&gt; 3\n_.dropRight(array, [n=1])\n(Array): Returns the slice of array.\n_.dropRight([1, 2, 3]);\n&#x2F;&#x2F; &#x3D;&gt; [1, 2]\n \n_.dropRight([1, 2, 3], 2);\n&#x2F;&#x2F; &#x3D;&gt; [1]\n\n_.dropRight([1, 2, 3], 0);\n&#x2F;&#x2F; &#x3D;&gt; [1, 2, 3]\n_.filter(collection, [predicate=_.identity])\n(Array): Returns the new filtered array.\nvar users &#x3D; [\n  &#123; &#39;user&#39;: &#39;barney&#39;, &#39;age&#39;: 36, &#39;active&#39;: true &#125;,\n  &#123; &#39;user&#39;: &#39;fred&#39;,   &#39;age&#39;: 40, &#39;active&#39;: false &#125;\n];\n \n_.filter(users, function(o) &#123; return !o.active; &#125;);\n&#x2F;&#x2F; &#x3D;&gt; objects for [&#39;fred&#39;]\n_.find(collection, [predicate=_.identity], [fromIndex=0])\n(*): Returns the matched element, else undefined.\n\tvar users &#x3D; [\n  &#123; &#39;user&#39;: &#39;barney&#39;,  &#39;age&#39;: 36, &#39;active&#39;: true &#125;,\n  &#123; &#39;user&#39;: &#39;fred&#39;,    &#39;age&#39;: 40, &#39;active&#39;: false &#125;,\n  &#123; &#39;user&#39;: &#39;pebbles&#39;, &#39;age&#39;: 1,  &#39;active&#39;: true &#125;\n];\n \n_.find(users, function(o) &#123; return o.age &lt; 40; &#125;);\n&#x2F;&#x2F; &#x3D;&gt; object for &#39;barney&#39;\n_.forEach(collection, [iteratee=_.identity])\n_.forEach([1, 2], function(value) &#123;\n  console.log(value);\n&#125;);\n&#x2F;&#x2F; &#x3D;&gt; Logs &#96;1&#96; then &#96;2&#96;.\n \n_.forEach(&#123; &#39;a&#39;: 1, &#39;b&#39;: 2 &#125;, function(value, key) &#123;\n  console.log(key);\n&#125;);\n_.groupBy(collection, [iteratee=_.identity])\n(Object): Returns the composed aggregate object.\n_.groupBy([6.1, 4.2, 6.3], Math.floor);\n&#x2F;&#x2F; &#x3D;&gt; &#123; &#39;4&#39;: [4.2], &#39;6&#39;: [6.1, 6.3] &#125;\n \n&#x2F;&#x2F; The &#96;_.property&#96; iteratee shorthand.\n_.groupBy([&#39;one&#39;, &#39;two&#39;, &#39;three&#39;], &#39;length&#39;);\n&#x2F;&#x2F; &#x3D;&gt; &#123; &#39;3&#39;: [&#39;one&#39;, &#39;two&#39;], &#39;5&#39;: [&#39;three&#39;] &#125;\n#Promise.map Promise.all 相当于事务 \n_.map(collection, [iteratee=_.identity])\n(Array): Returns the new mapped array.\nfunction square(n) &#123;\n  return n * n;\n&#125;\n\n_.map([4, 8], square);\n&#x2F;&#x2F; &#x3D;&gt; [16, 64]\n \n_.map(&#123; &#39;a&#39;: 4, &#39;b&#39;: 8 &#125;, square);\n&#x2F;&#x2F; &#x3D;&gt; [16, 64] (iteration order is not guaranteed)\n#Promise.reduce是顺序执行\n_.reduce(collection, [iteratee=_.identity], [accumulator])  -\n(*): Returns the accumulated value.\nf_.reduce([1, 2], function(sum, n) &#123;\n  return sum + n;\n&#125;, 0);\n&#x2F;&#x2F; &#x3D;&gt; 3\n_.isEmpty(value)\n(boolean): Returns true if value is empty, else false.\n_.isEmpty(null);\n&#x2F;&#x2F; &#x3D;&gt; true\n \n_.isEmpty(true);\n&#x2F;&#x2F; &#x3D;&gt; true\n \n_.isEmpty(1);\n&#x2F;&#x2F; &#x3D;&gt; true\n \n_.isEmpty([1, 2, 3]);\n&#x2F;&#x2F; &#x3D;&gt; false\n \n_.isEmpty(&#123; &#39;a&#39;: 1 &#125;);\n&#x2F;&#x2F; &#x3D;&gt; false\n项目案例 略\n\n1.10.3 Moment.js\n[文档](http://momentjs.cn)\n案例使用\nmoment(event.start_time).startOf(&#39;day&#39;)&#x2F;1000;\nmoment.unix(moment().startOf(&#39;month&#39;)&#x2F;1000).utcOffset(config.TIME_ZONE_DIFF).format(&quot;YYYY-MM-DD HH:mm:ss&quot;);","slug":"node笔记","date":"2018-08-21T09:04:37.000Z","categories_index":"IT笔记","tags_index":"node.js","author_index":"Fly"},{"id":"1537605682febdfac8db68bbbd2d14a8","title":"翻译提取替换","content":"\n提取提取客户端资源文件之前先要用uc-utf8.php转utf-8 把unicode码转成utf-8的日文在提取将要提取文字的文件整合与getFromHtml.sh 放在同目录下#!&#x2F;bin&#x2F;bash\n#sh getFromHtml.sh under the template fold\n#Change filelist.csv to excel file, and give it to translator\n\nLANG&#x3D;C grep -r -n -v &#39;^[[:cntrl:][:print:]]*$&#39; . | grep -v &quot;using UnityEngine;&quot; | grep -v svn | grep -v &#x2F;&#x2F;  | grep -v \\* |  grep -v &quot;\\&#123;\\*&quot; |  grep -v &quot;\\&quot;Name\\&quot;&quot; &gt; ~&#x2F;lj_2_3_server.csv\n\nsed -i &#39;s@\\t@ @g&#39; ~&#x2F;lj_2_3_server.csv\nsed -i &#39;s@\\([^:]*\\):\\([0-9]*\\):@\\1\\t\\2\\t@&#39; ~&#x2F;lj_2_3_server.csv\n点击下载\n\n\n\n可以脚本文件内修改输出路径及文件名运行命令提取内容sh getFromHtml\n取出后的excel先在编辑软件里打开编码改成ansi, 否则直接excel打开会乱码在excel内，全选，点击数据-&gt;分列-&gt;分隔符号-&gt;Tab键-&gt;确定。。。。以Tab键分割内容完成后的数据格式如下：(A列为行数，B列为行号，C列为提取的原字符)如果有发现提取到不需要翻译的错误的，可直接整行删除。。。提交翻译\n\n替换翻译后的文件如果为xls，在最后另起一列，用公式=A1&amp;”^”&amp;B1&amp;”^”&amp;C1连接，拖到底，用连接的主要目的是让文件、行、数据之间有个特殊的符号分割^ 这个符号基本见不到所以用这个，将最后列的数据拷贝到sublime，替换”^ “ 为 “^”去掉多余的数据与行之间的一个空格，然后将\\替换为@@@或者奇怪不重复的符号，如果不替换转换会被转换掉，最后将sublime上的代码考到新建的一个txt中另存为utf-8，上传到服务器对应的目录下面，修改changeHtml.sh这个文件中判断中间的分割符号保存，整个文件权限777.\n\n#!&#x2F;bin&#x2F;bash\n#sh changeHtml.sh  result_file\n#result_file&#39; content\n#file&#39;s path    line_no old_content     new_content\n\nfile&#x3D;$1\n\nif [ -z $file ]\nthen\n        echo &quot;Input result_file&quot;\n        exit\nfi\n\nwhile read line\ndo\n        IFS&#x3D;&quot;^&quot;\n        arr&#x3D;($line)\n        filename&#x3D;$&#123;arr[0]&#125;\n        line_num&#x3D;$&#123;arr[1]&#125;\n        str_kr&#x3D;$&#123;arr[2]&#125;\n\n        if [ $str_kr ]\n        then\n        echo $filename\n        echo $line_num\n        echo $str_kr\n\n                sed -i &#39;&#39;$line_num&#39; c\\&#39;$str_kr&#39;&#39;  $filename\n        else\n                echo $line\n        fi\ndone &lt; $file\n运行命令替换内容sh changeHtml.sh text.txt \n运行完.asset的文件是没办法替换的，要手动自行替换\ntext.txt数据格式如下点击下载       \n","slug":"翻译提取替换","date":"2018-08-03T03:02:18.000Z","categories_index":"脚本工具","tags_index":"游戏","author_index":"Fly"},{"id":"bc2c9c727d9ddd92863bc97ef0485ad6","title":"项目各种配置文件","content":"\nsrpg.conf\nserver &#123;\n    listen 80;\n    listen 443 ssl;\n#    server_name alctwobt.ssl.91dena.cn;\n    server_name alccn2-release.ssl.91dena.cn;\n#    ssl on;\n    ssl_certificate &#x2F;root&#x2F;cert&#x2F;91dena_cn.pem;\n    ssl_certificate_key &#x2F;root&#x2F;cert&#x2F;91dena_cn.key;\n\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header Host $http_host;\n\n    ## APP  11\n    location &#x2F; &#123;\n        # proxy\n        proxy_pass http:&#x2F;&#x2F;127.0.0.1:5000&#x2F;;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        # connect to backend with keepalives\n\n        proxy_http_version 1.1;\n        proxy_set_header Connection &quot;&quot;;\n        proxy_send_timeout 30s;\n        proxy_read_timeout 60s;\n        proxy_connect_timeout 30s;\n    &#125;\n    access_log  &#x2F;home&#x2F;log&#x2F;nginxlog&#x2F;cnrelease&#x2F;alccn2.ssl.91dena.cn.access.log main;\n    error_log   &#x2F;home&#x2F;log&#x2F;nginxlog&#x2F;cnrelease&#x2F;alccn2.ssl.91dena.cn.error.log;\n&#125;\n点击下载\n\n\nnginx\nuser nginx;\n\nworker_processes  auto;\nworker_rlimit_nofile 150000;\n\nerror_log   &#x2F;tmp&#x2F;error.log;\n\nevents &#123;\n    worker_connections  65535;\n    multi_accept on ;\n\n&#125;\n\n\nhttp &#123;\n    include mime.types;\n    default_type  application&#x2F;octet-stream;\n    log_format  main  &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; $request_time&#39;\n                      &#39; $status $body_bytes_sent &quot;$http_referer&quot; &#39;\n                      &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;  $upstream_response_time&#39;;\n    access_log  &#x2F;tmp&#x2F;access.log;\n    sendfile        on;\n    tcp_nopush      on;\n    keepalive_timeout  120;\n\n    gzip  on;\n    \ninclude &#x2F;etcinx&#x2F;title&#x2F;*.conf;\n\n&#125;\n点击下载\n\nsrpg-app\n#!&#x2F;bin&#x2F;bash\n### BEGIN INIT INFO\n# Provides:             webapp\n# Required-Start:       $syslog $remote_fs\n# Required-Stop:        $syslog $remote_fs\n# Should-Start:         $local_fs\n# Should-Stop:          $local_fs\n# Default-Start:        2 3 4 5\n# Default-Stop:         0 1 6\n# Short-Description:    Alchemist Webapp\n# Description:          Alchemist Webapp\n### END INIT INFO\n#\n### BEGIN CHKCONFIG INFO\n# chkconfig: 2345 55 25\n# description: Alchemist Webapp\n### END CHKCONFIG INFO\n\nUSER&#x3D;&quot;webapp&quot;\nNAME&#x3D;&quot;webapp&quot;\nNODE_ENV&#x3D;&quot;production&quot;\nNODE_BIN_DIR&#x3D;&quot;&#x2F;usr&#x2F;localde&#x2F;bin&quot;\nNODE_PATH&#x3D;&quot;&#x2F;usr&#x2F;localdebde_modules&quot;\nAPPLICATION_PATH&#x3D;&quot;ar&#x2F;webapps&#x2F;alchemist&#x2F;currentde&#x2F;app&#x2F;app.js&quot;\nAPPLICATION_WORKDIR&#x3D;&quot;ar&#x2F;webapps&#x2F;alchemist&#x2F;currentde&#x2F;app&#x2F;&quot;\nAPPLICATION_OPTION&#x3D;&quot;&quot;\nLOGFILE&#x3D;&quot;ar&#x2F;webapps&#x2F;alchemist&#x2F;log&#x2F;forever&#x2F;app.log&quot;\nMIN_UPTIME&#x3D;&quot;5000&quot;\nSPIN_SLEEP_TIME&#x3D;&quot;10000&quot;\n\nPATH&#x3D;$NODE_BIN_DIR:$PATH\n\nexport NODE_PATH&#x3D;$NODE_PATH\n\nstart() &#123;\n    echo &#96;runuser -l &quot;$USER&quot; -c &quot;forever list&quot;&#96; | grep -q &quot;$APPLICATION_PATH&quot;\n    if [ &quot;$?&quot; -eq &quot;0&quot; ]; then\n        echo &quot;$NAME is already running.&quot;\n        RETVAL&#x3D;0\n    else\n        echo &quot;Starting $NAME&quot;\n        runuser -l &quot;$USER&quot; -c &quot;\\\n        export NODE_ENV&#x3D;$NODE_ENV &amp;&amp;\n        forever \\\n        -a \\\n        -l $LOGFILE \\\n        --minUptime $MIN_UPTIME \\\n        --spinSleepTime $SPIN_SLEEP_TIME \\\n        --workingDir $APPLICATION_WORKDIR \\\n        start $APPLICATION_PATH $APPLICATION_OPTION&quot; 2&gt;&amp;1 &gt; &#x2F;dev&#x2F;null &amp;\n        RETVAL&#x3D;$?\n    fi\n&#125;\n\nstop() &#123;\n    echo &#96;runuser -l &quot;$USER&quot; -c &quot;forever list&quot;&#96; | grep -q &quot;$APPLICATION_PATH&quot;\n    if [ &quot;$?&quot; -eq &quot;0&quot; ]; then\n        echo &quot;Shutting down $NAME&quot;\n        # Tell Forever to stop the process.\n        runuser -l &quot;$USER&quot; -c &quot;forever stop $APPLICATION_PATH&quot; 2&gt;&amp;1 &gt; &#x2F;dev&#x2F;null\n        RETVAL&#x3D;$?\n    else\n        echo &quot;$NAME is not running.&quot;\n        RETVAL&#x3D;0\n    fi\n&#125;\n\nrestart() &#123;\n    stop\n    start\n&#125;\n\nstatus() &#123;\n    echo &#96;runuser -l &quot;$USER&quot; -c &quot;forever list&quot;&#96; | grep -q &quot;$APPLICATION_PATH&quot;\n    if [ &quot;$?&quot; -eq &quot;0&quot; ]; then\n        echo &quot;$NAME is running.&quot;\n        RETVAL&#x3D;0\n    else\n        echo &quot;$NAME is not running.&quot;\n        RETVAL&#x3D;3\n    fi\n&#125;\n\ncase &quot;$1&quot; in\n    start)\n        start\n        ;;\n    stop)\n        stop\n        ;;\n    status)\n        status\n        ;;\n    restart)\n        restart\n        ;;\n    *)\n        echo &quot;Usage: &#123;start|stop|status|restart&#125;&quot;\n        exit 1\n        ;;\nesac\nexit $RETVAL\n点击下载\n\ntd-agent\n####\n## Output descriptions:\n##\n\n# Treasure Data (http:&#x2F;&#x2F;www.treasure-data.com&#x2F;) provides cloud based data\n# analytics platform, which easily stores and processes data from td-agent.\n# FREE plan is also provided.\n# @see http:&#x2F;&#x2F;docs.fluentd.org&#x2F;articles&#x2F;http-to-td\n#\n# This section matches events whose tag is td.DATABASE.TABLE\n&lt;match td.*.*&gt;\n  @type tdlog\n  apikey YOUR_API_KEY\n\n  auto_create_table\n  buffer_type file\n  buffer_path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;buffer&#x2F;td\n\n  &lt;secondary&gt;\n    @type file\n    path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;failed_records\n  &lt;&#x2F;secondary&gt;\n&lt;&#x2F;match&gt;\n\n## match tag&#x3D;debug.** and dump to console\n&lt;match debug.**&gt;\n  @type stdout\n&lt;&#x2F;match&gt;\n\n####\n## Source descriptions:\n##\n\n## built-in TCP input\n## @see http:&#x2F;&#x2F;docs.fluentd.org&#x2F;articles&#x2F;in_forward\n&lt;source&gt;\n  @type forward\n&lt;&#x2F;source&gt;\n\n## built-in UNIX socket input\n#&lt;source&gt;\n#  @type unix\n#&lt;&#x2F;source&gt;\n\n# HTTP input\n# POST http:&#x2F;&#x2F;localhost:8888&#x2F;&lt;tag&gt;?json&#x3D;&lt;json&gt;\n# POST http:&#x2F;&#x2F;localhost:8888&#x2F;td.myapp.login?json&#x3D;&#123;&quot;user&quot;%3A&quot;me&quot;&#125;\n# @see http:&#x2F;&#x2F;docs.fluentd.org&#x2F;articles&#x2F;in_http\n&lt;source&gt;\n  @type http\n  port 8888\n&lt;&#x2F;source&gt;\n\n## live debugging agent\n&lt;source&gt;\n  @type debug_agent\n  bind 127.0.0.1\n  port 24230\n&lt;&#x2F;source&gt;\n\n####\n## Examples:\n##\n\n## File input\n## read apache logs continuously and tags td.apache.access\n#&lt;source&gt;\n#  @type tail\n#  format apache\n#  path &#x2F;var&#x2F;log&#x2F;httpd-access.log\n#  tag td.apache.access\n#&lt;&#x2F;source&gt;\n\n## File output\n## match tag&#x3D;local.** and write to file\n#&lt;match local.**&gt;\n#  @type file\n#  path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;access\n#&lt;&#x2F;match&gt;\n\n## Forwarding\n## match tag&#x3D;system.** and forward to another td-agent server\n#&lt;match system.**&gt;\n#  @type forward\n#  host 192.168.0.11\n#  # secondary host is optional\n#  &lt;secondary&gt;\n#    host 192.168.0.12\n#  &lt;&#x2F;secondary&gt;\n#&lt;&#x2F;match&gt;\n\n## Multiple output\n## match tag&#x3D;td.*.* and output to Treasure Data AND file\n#&lt;match td.*.*&gt;\n#  @type copy\n#  &lt;store&gt;\n#    @type tdlog\n#    apikey API_KEY\n#  auto_create_table\n#    buffer_type file\n#    buffer_path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;buffer&#x2F;td\n#  &lt;&#x2F;store&gt;\n#  &lt;store&gt;\n#    @type file\n#    path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;td-%Y-%m-%d&#x2F;%H.log\n#  &lt;&#x2F;store&gt;\n#&lt;&#x2F;match&gt;\n#&lt;match *.**&gt;\n#  type file\n#   path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;error.log\n#&lt;&#x2F;match&gt;\n\n&lt;match alchemist.**&gt;\n  type forward\n  heartbeat_type tcp\n  buffer_type file\n  buffer_path &#x2F;var&#x2F;tmp&#x2F;td-agent&#x2F;forward.*.buffer\n  buffer_chunk_limit 8m     # チャンクサイズ\n  buffer_queue_limit 256    # 1queueに保存できるchunk数の上限\n  flush_interval 1s        # 10秒に1回送信\n  flush_at_shutdown true    # シャットダウン時にチャンクを処理するか?(ファイルバッファのみ有効)\n  retry_wait 5s            # 再送実施までの待ち時間\n  retry_limit 2             # 再送実施回数\n  require_ack_response true\n  expire_dns_cache 0\n  dns_round_robin true\n\n  &lt;server&gt;\n    host mongodb.alccn.91dena.cn\n    port 24224\n  &lt;&#x2F;server&gt;\n\n  # ログ送信失敗時のファイル\n  #  # &lt;secondary&gt;\n  #      #  type file\n  #         #   path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;failed&#x2F;forward-failed\n  #           #&lt;&#x2F;secondary&gt;\n &lt;&#x2F;match&gt;\n点击下载\n\n\n","slug":"项目各种配置文件","date":"2018-07-31T08:43:21.000Z","categories_index":"脚本工具","tags_index":"nginx,td-agent","author_index":"Fly"},{"id":"325a758ec467f97d0caf0311703869d6","title":"ALC_Sentry","content":"1) 安装环境执行命令创建名为sentry的数据库createdb -E utf-8 sentry为sentry项目初始化数据sentry –config=/.sentry/sentry.conf.py upgrade创建新用户sentry –config=/.sentry/sentry.conf.py createuser然后就可以启动服务了sentry –config=/.sentry/sentry.conf.py start另外，还需要启动Workersentry –config=/.sentry/sentry.conf.py celery worker -B假设web服务器端口是9000，那么访问localhost:9000就能开始使用sentry了！\nsource /usr/local/vir-sentry/bin/activatesentry –config=~/.sentry/sentry.conf.py start &gt;&gt; /usr/local/vir-sentry/logs/sentry.log 2&gt;&amp;1 &amp;\n\n\n2）相关命令2.1启动su - webappsource /usr/local/vir-sentry/bin/activatesupervisord -c /etc/supervisord.confsupervisorctl start all2.2关闭命令su - webappsource /usr/local/vir-sentry/bin/activatesupervisorctl stop allkillall supervisord\n*创建账号 sentry createuser3)基于node的测试demoraven-node-master.zip\n4.）界面显示\nweb 服务器相关配置\n","slug":"ALC-Sentry","date":"2018-07-24T08:06:55.000Z","categories_index":"开发环境安装","tags_index":"Sentry","author_index":"Fly"},{"id":"6e1762f4087a3c7b84bbdf912ec8c60e","title":"Alchemist_manage服务器部署","content":"\nmanage服务器代码上传copy srpg_too 目录到 /var/webapps/alchemist_mnt    (文件所有者必须为webapp)\nruby运行环境构建\n1 检查依赖\n\n-ruby(v2.2.2p95~)-gem bundle-Node.js-npm-bower-msyql-redis2.1 设置gem源为淘宝源Gemfile （描述gem之间依赖文件）需要如下修改source ‘https://gems.ruby-china.org/&#39;2.2  安装gem filesu  - webappbundle install2.2.1 安装bundle 命令不存在，。gem install bundle2.2.2 提示gem命令不存在，就执行rbenv global 2.2.2， 如果无法运行就重新安装ruby 2.2.2 版本，流程如下su - webappgit clone https://github.com/rbenv/rbenv.git ~/.rbenvcd ~/.rbenv &amp;&amp; src/configure &amp;&amp; make -C srcecho ‘export PATH=”$HOME/.rbenv/bin:$PATH”‘ &gt;&gt; ~/.bash_profile~/.rbenv/bin/rbenv initecho ‘eval “$(rbenv init -)”‘ &gt;&gt; ~/.bash_profilesource ~/.bash_profilegit clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-buildrbenv install 2.2.2rbenv global 2.2.2ruby -v\n\n\nCap环境部署\n1 配置SSH无密码登录配置config/deploy/produciton.rb ssh无密码登陆（id_rsa.pub和authorized_keys） 设置authorized_keys，记得chmod 600，否则无法生效）\n1.1 生成sshkey:cd ~/.sshssh-keygen输入公钥名：id_rsa\n1.2 配置authorized_keyscat  id_rsa.pub &gt;&gt; authorized_keyschmod -R 600 authorized_keyschmod 700 /.ssh备注：如果还是无法实现无密码登录，再清空下/.ssh/koown_hosts文件（echo “” &gt; ~/.sshown_hosts);\n1.3执行以下deploy命令：production环境为例cd currentbundle exec cap production mkdir:socketsbundle exec cap production bower:install\n前端bower模块安装\n1 Node.js 安装bowernpm install -g bower –registry=https://registry.npm.taobao.org   (-g不一定要)\n2install Bowerfilebundle exec rake bower:install\n3 manage server DB构建bundle exec rake maint:create maint:migrate\n\n4.4 添加管理账号  bundle exec rake maint:seed\n4.5  配置crontab    缺少crontab 会影响预约奖励发放    cd 根目录（current/）    gem install whenever ，检查config/schedule.rb是否存在    whenever -w（写入到crontab 中）    查看log/cron_log.log日志是否已生成。\n","slug":"alchemist-manage服务器部署","date":"2018-07-11T08:55:25.000Z","categories_index":"脚本工具","tags_index":"Ruby on Rails,Capistrano 自动部署工具","author_index":"Fly"},{"id":"153b75a4e068c203d6174137f4f2a310","title":"Hexo 常用笔记","content":"建站的过程网上一大把就不记录了，主要写下遇到的几个问题\n\ngithub上的项目名称一定要和自己在github上的用户名一致，否则会生成静态文件后点开会白屏\n多看看官方手册上面有详细记录https://hexo.io/zh-cn/docs\n\nhexo g -dhexo cleanhexo shexo目录下执行这样一句话npm install hexo-asset-image –save，这是下载安装一个可以上传本地图片的插件,再运行hexo n “xxxx”来生成md博文hexo new post xxxxx 生成带图片的博文\nnpm install hexo-generator-json-content –savenpm install hexo-deployer-git –savepost_asset_folder: true  config.yml\nindex_generator:  per_page: 9 ##首页默认9篇文章标题 如果值为0不分页archive_generator:    per_page: 100 ##归档页面默认100篇文章标题    yearly: true  ##生成年视图    monthly: true ##生成月视图tag_generator:    per_page: 100 ##标签分类页面默认100篇文章category_generator:    per_page: 100 ###分类页面默认100篇文章\n","slug":"hexo-安装遇到的问题","date":"2018-07-03T09:39:12.000Z","categories_index":"开发环境安装","tags_index":"node.js,hexo","author_index":"Fly"}]