{"meta":{"title":"Fly的博客","subtitle":"Fly-blog","description":"一个在夏天会被芒果砸到的城市靠写代码为生的前职业电竞选手","author":"zx","url":"http://zxtotti17.github.io","root":"/"},"pages":[{"title":"About-Me","date":"2018-10-03T02:48:33.000Z","updated":"2021-11-30T08:17:03.293Z","comments":true,"path":"about/index.html","permalink":"http://zxtotti17.github.io/about/index.html","excerpt":"","text":"一句话 Just do it ! (翻译：我只是个搞 IT的！哭笑脸) 关于我 一个莫名其妙的，喜欢敲代码，喜欢研究技术的，表面上高冷、不苟言笑的， 偶尔又嬉皮笑脸，偶尔又特立独行的，双重性格的技术爱好者！ 兴趣方向 做饭，运动，游戏，摄影。 联系我 Email: 574215066@qq.com"},{"title":"About-Me","date":"2018-10-03T02:48:33.000Z","updated":"2021-07-01T06:49:56.793Z","comments":true,"path":"about-me/index.html","permalink":"http://zxtotti17.github.io/about-me/index.html","excerpt":"","text":"一句话 Just do it ! (翻译：我只是个搞 IT的！哭笑脸) 关于我 一个莫名其妙的，喜欢敲代码，喜欢研究技术的，表面上高冷、不苟言笑的， 偶尔又嬉皮笑脸，偶尔又特立独行的，双重性格的技术爱好者！ 兴趣方向 做饭，运动，游戏，摄影。 联系我 Email: 574215066@qq.com"},{"title":"Archives","date":"2017-09-20T12:49:56.000Z","updated":"2019-11-27T15:26:48.000Z","comments":false,"path":"archives/index.html","permalink":"http://zxtotti17.github.io/archives/index.html","excerpt":"","text":""},{"title":"Categories","date":"2018-09-20T12:49:56.000Z","updated":"2019-11-27T15:26:48.000Z","comments":false,"path":"categories/index.html","permalink":"http://zxtotti17.github.io/categories/index.html","excerpt":"","text":""},{"title":"Message-Board","date":"2021-11-30T09:23:07.000Z","updated":"2021-11-30T09:23:07.018Z","comments":true,"path":"message-board/index.html","permalink":"http://zxtotti17.github.io/message-board/index.html","excerpt":"","text":""},{"title":"Tags","date":"2018-07-03T09:44:08.000Z","updated":"2019-11-27T15:26:48.000Z","comments":true,"path":"tags/index.html","permalink":"http://zxtotti17.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"分布式算法","slug":"分布式算法","date":"2023-04-10T01:58:53.000Z","updated":"2023-04-10T02:21:31.493Z","comments":true,"path":"/post/分布式算法.html","link":"","permalink":"http://zxtotti17.github.io/post/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95.html","excerpt":"","text":"强一致性说明：保证系统改变提交以后立即改变集群的状态。模型：PaxosRaft（muti-paxos）ZAB（muti-paxos）弱一致性说明：也叫最终一致性，系统不保证改变提交以后立即改变集群的状态，但是随着时间的推移最终状态是一致的。模型：DNS系统Gossip协议 一致性算法实现举例Google的Chubby分布式锁服务，采用了Paxos算法etcd分布式键值数据库，采用了Raft算法ZooKeeper分布式应用协调服务，Chubby的开源实现，采用ZAB算法 Raft算法Leader总统节点，负责发出提案Follower追随者节点，负责同意Leader发出的提案Candidate候选人，负责争夺Leader Raft算法将一致性问题分解为两个的子问题，Leader选举和状态复制Leader选举 每个Follower都持有一个定时器 当定时器时间到了而集群中仍然没有Leader，Follower将声明自己是Candidate并参与Leader选举，同时将消息发给其他节点来争取他们的投票，若其他节点长时间没有响应Candidate将重新发送选举信息 集群中其他节点将给Candidate投票 获得多数派支持的Candidate将成为第M任Leader（M任是最新的任期） 在任期内的Leader会不断发送心跳给其他节点证明自己还活着，其他节点受到心跳以后就清空自己的计时器并回复Leader的心跳。这个机制保证其他节点不会在Leader任期内参加Leader选举。 当Leader节点出现故障而导致Leader失联，没有接收到心跳的Follower节点将准备成为Candidate进入下一轮Leader选举 若出现两个Candidate同时选举并获得了相同的票数，那么这两个Candidate将随机推迟一段时间后再向其他节点发出投票请求，这保证了再次发送投票请求以后不冲突","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://zxtotti17.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"不同语言区别","slug":"不同语言的处理方式","date":"2023-04-06T08:06:35.000Z","updated":"2023-04-08T09:12:32.671Z","comments":true,"path":"/post/不同语言的处理方式.html","link":"","permalink":"http://zxtotti17.github.io/post/%E4%B8%8D%E5%90%8C%E8%AF%AD%E8%A8%80%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F.html","excerpt":"","text":"错误处理nodejs 中常用的错误处理会用try catch catch throw errorlua 中的错误处理 error直接抛出错误信息 assert断言 pcall以 保护模式 调用函数 f, true,结果，相似于node中的promisexpcall也是以保护的模式，相似与node中的promise().catch()python 下的错误处理 用try except ，python中的字典不存在的key会直接报错,c++也是一样，不会像其他语言一样返回空erlang try catch erlang是强类型匹配，从编译的角度来说就不容易出错 lua的协程类似于promise的异步","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://zxtotti17.github.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"PP-活动中心","slug":"PP-活动中心","date":"2023-03-23T09:01:19.000Z","updated":"2023-04-07T02:45:48.174Z","comments":true,"path":"/post/PP-活动中心.html","link":"","permalink":"http://zxtotti17.github.io/post/PP-%E6%B4%BB%E5%8A%A8%E4%B8%AD%E5%BF%83.html","excerpt":"","text":"PP的活动可以分为公共活动中心和玩家活动中心两大块，公共活动中心负责全体玩家活动，其中包含日程管理和活动管理，玩家活动中心负责玩家个人活动管理及接收管理公共中心的状态变化及相关活动在个人中的逻辑 日程管理中包含, 配置 db 管理模块 定时器 初始化， 其中主要做的就是将任务日程数据加载进内存 scheduleCfgMgr.init() scheduleDB.init() scheduleMgr.init() timeTrigger.start() local function registerSchedule(id, scheduleConfig, parameter) handles[id] = handles[id] or {} -- 当前已开启未结束的活动 local curTime = timeUtil.time() local timestamp = activityScheduleParser.getNearestValidTimestamp(scheduleConfig) if timestamp &lt; curTime then scheduleCallback(id, parameter)(timestamp) end local handle = schedule.register(curTime, scheduleConfig, scheduleCallback(id, parameter)) table.insert(handles[id], handle) return true end local function scheduleCallback(id, parameter) return function(timestamp) log.info(&quot;registerSchedule callback activity[%s] timestamp[%s]&quot;, id, timestamp) if not hasActvityOpened(id, timestamp) then -- 未开启 local ok = activityMgr.openActivity(id, timestamp, parameter) if not ok then log.error(&quot;start schedule(%s) activity failed!&quot;, id) end end end end 活动管理中包含对活动基类的管理，不同活动通过基类派生逻辑，在活动管理中管理开启关闭通知等 function Activity:newRound(config) if self.data.round == 0 then self.data.firstRoundTimpstamp = config.stageTimestamp[1] end self.data.round = self.data.round + 1 local param = config.parameter or activityCfgMgr.getParameter(self.id) self.data.stageTimestamp = config.stageTimestamp self.data.stageCurrent = 0 self.data.activityType = activityCfgMgr.getType(self.id) self.data.parameter = tableUtil.deepCopy(param) self.data.isOpen = true local unlock = config.unlock or activityCfgMgr.getUnlock(self.id) self.data.unlock = unlock activityCenterDB.setActivity(self.id, self.data) end 个人活动与公共活动中心结构类似，也是活动管理管理其他活动逻辑","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"http://zxtotti17.github.io/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"PP-邮箱邮件系统","slug":"PP-邮箱邮件系统","date":"2023-02-28T03:43:43.000Z","updated":"2023-03-04T02:30:47.062Z","comments":true,"path":"/post/PP-邮箱邮件系统.html","link":"","permalink":"http://zxtotti17.github.io/post/PP-%E9%82%AE%E7%AE%B1%E9%82%AE%E4%BB%B6%E7%B3%BB%E7%BB%9F.html","excerpt":"","text":"PP中的邮件邮箱和传统的基本类似，邮件属于玩家自己的，邮箱负责接收全局或者后台或者分组的特定邮件，邮箱新开一个进程，邮件同玩家相关在同一个进程邮箱接收到的邮件通过判断玩家在线与否来推送邮件，玩家在线通过玩家上线及下线通知邮箱系统，玩家上线会同步未过期未领取在邮箱中的邮件邮箱节点除了分组邮箱备份和主服务外，主要包含邮件创建、邮件管理、玩家邮箱相关服务玩家节点中包含玩家邮件缓存、玩家邮件接口直接对接玩家部分 邮箱服务接口部分# 产生邮件id唯一用于所有玩家 function mailDB.newMailID() local ok, mailID = storagedProxy.req.execute(&quot;mail_data_auto_incr_id&quot;, &quot;unique&quot;, &quot;INCR&quot;) if ok then return math_tointeger(mailID) else return nil end end 删除一封全局邮件local function callAllGameDelMailData(mailID) local nodes = registry.getValidNodesByType(NodeTypeEnum.GAME) for _, nName in ipairs(nodes) do log.info(“cluster.send nName:%s”, nName) local ok = exceptionUtil.xpcall(cluster.send, nName, “.mailDataCached”, “delMailData”, mailID) if not ok then log.error(“callGameNodeDelMailData error, nName:%s, mailID:%s”, nName, mailID) end endend – 系统创建玩家邮件function CMD.auto.sendPlayerMailByCfg(mailType, reward, params, receiverList, source) – GM创建玩家邮件function CMD.auto.sendPlayerMail(mailType, reward, expiryTimestamp, params, receiverList, source) – GM创建群体邮件function CMD.auto.sendGroupMail(mailType, reward, expiryTimestamp, data, conditions, source) 注意发送玩家邮件用额外的模块内存记录发送进度， 发送到玩家邮箱模块后删除，删除操作类似local recordID = mailReqRecordMgr.addRecord(“player”, recordData)local sendResult, retData = sendToPlayerMailbox(mailID, receiverList, rewardFlag, expiryTimestamp)mailReqRecordMgr.delRecord(“player”, recordID) #全体邮件分组，同时全体邮件的通知需要用到组播功能，在初始化中初始，初始化中还要考虑过期问题channel = mc.new() #组播组件dc.set(“GROUP_MAILBOX_CHANNEL”, channel.channel) #数据中心记录组播号#分别记录邮件组id对应的邮件信息和邮件ID对应的组信息列表function M.receiveMail(mailID, condition, rewardFlag, expireTimestamp)dbMailList[mailID] = groupIDgroupMailboxMasterDB.updateGroupMailboxData(groupID, mailInfo)groupMailboxMasterDB.updateGroupMailList(dbMailList)– 通知玩家个人邮箱有新群体邮件 local msg = { publishType = “new”, data = {} } channel:publish(msg) #组播通知有订阅都能通知到 2. 玩家邮箱 玩家邮箱负责接收玩家邮件数据，模块主要通过邮箱基类引申出不同对应方法 ``` bash #初始化中获取全局邮箱主播号，订阅并判断命令方式 function M.init() local channelID = dc.get(&quot;GROUP_MAILBOX_CHANNEL&quot;) grouoChannel = mc.new({ channel = channelID, dispatch = function (_, _, msg) log.dump(msg, &quot;playerMailboxd receive msg&quot;) local publishType = msg.publishType if &quot;new&quot; == publishType then callReciveGroupMail() elseif &quot;del&quot; == publishType then callDelGroupMail(msg.data.mailID) end end }) grouoChannel:subscribe() end function M:ctor(uid, recycleCallback) self.uid = uid self.state = MailboxState.OFFLINE self.data = mailboxDB.getMailboxData(self.uid) if checkUtil.notTableOrEmpty(self.data) then self.data = createDefaultData() mailboxDB.updateMailboxData(self.uid, self.data) end self.data.mails = transMailsKeyType(self.data.mails) self.mailCnt = countMailNum(self.data.mails) self.recycleCallback = recycleCallback local recycleTimestamp = timeUtil.time() + RECTCLE_WAIT_TIME self.recycleTimestamp = recycleTimestamp self.timerHandle = timeTrigger.register(recycleTimestamp, function() recycleCallback(uid) end) end # 由于层级结构，外部进程无法从玩家进程取回调数据，只能通过通知的形式，让玩家进程接收通知后去外部进程取数据 function M:receiveAndNotifyPlayerMail(mailID, rewardFlag, expireTimestamp, channel) local result = self:receivePlayerMail(mailID, rewardFlag, expireTimestamp, channel, MailTypeEnum.PLAYER) if self.state == MailboxState.ONLINE then -- 通知玩家有新邮件，过来拿走 self:notifyAgent(&quot;newPlayerMail&quot;, mailID) end return result end function M:notifyAgent(msgName, ...) forwardNotifydProxy.post.forwardMsgToAgent(self.uid, &quot;mailMsgHandle&quot;, msgName, ...) end # 玩家进程接收到通知去邮箱进程取数据 function M.newGroupMail() log.info(&quot;mailNodeMsgHandler newGroupMail&quot;) local request = { type = MailTypeEnum.GROUP, playerInfo = getPlayerInfo(), syncMailIndex = mailDBData.syncMailIndex, } M.remoteReqNewMails(request) end # 领取邮箱中的邮件，邮箱定时10分钟后清空 function M:reqReceiveNewMails(uid, loginID, request) -- 在线处理 if not self:isOperateValid(uid, loginID) then log.info(&quot;reqReceiveNewMails isOperateValid invalid&quot;) return end local syncMailIndex = tonumber(request.syncMailIndex) if request.type == MailTypeEnum.GROUP then -- 新群体邮件先验证是否符合条件，符合投入玩家邮件列表 local playerInfo = request.playerInfo if not playerInfo then log.info(&quot;reqReceiveNewMails playerInfo nil&quot;) return end self:syncGroupMails(playerInfo) #将未领取的全局邮件推送到邮箱 end local retMail = {} for mailIndex, mailInfo in pairs(self.data.mails) do if mailIndex &gt; syncMailIndex then retMail[mailIndex] = mailInfo end end return retMail end #玩家actor中还加了一个邮件数据缓存，链式5000容量的存储缓存 function M.getMailData(mailID) local cliMailData = mailDataCache:get(mailID) ...","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"http://zxtotti17.github.io/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"PP_Battle","slug":"PP-Battle","date":"2023-01-03T09:44:47.000Z","updated":"2023-04-07T03:19:40.871Z","comments":true,"path":"/post/PP-Battle.html","link":"","permalink":"http://zxtotti17.github.io/post/PP-Battle.html","excerpt":"PP的战斗是由客户端做完，服务端校验，与传统服务端做略有差别 战斗认证传参, 其中认证数据中包含操作指令列表，战斗数据（攻方，守方，cd, 消除权重，随机数， 战斗类型），战斗结果， 服务端跑完完整的指令对比战斗结果 function battleVerifyMgr.startVerify(verifyData) local start = skynet.time() local gameConfig = verifyData.gameConfig local ID = battleModule.newGame(gameConfig) local game = battleModule.getGame(ID) local resultData = verifyData.resultData game:start() local opCostMap = {} local fail_list = {} local commandList = verifyData.commandList for idx, opData in pairs(commandList) do opData.gameID = ID local opStart = skynet.time() local ok = pcall(battleMsgTrigger.receive, opData) local opEnd = skynet.time() local curr = opCostMap[opData.opType] or 0 opCostMap[opData.opType] = curr + opEnd - opStart if not ok then fail_list[fail_list + 1] = { opData = opData, opIndex = idx, } end end -- log.dump(opCostMap, &quot;battleVerify command time cost info&quot;) local finish = skynet.time() local errCode = ErrorEnum.SUCCESS local battleRecord = game:getBattleRecord() local serWin = battleRecord:isAttackerWin() local cliWin = resultData.bWin if serWin ~= cliWin and not serWin then -- 客户端有可能断线重连后发送战斗结果，战斗实际胜利了但是类型不对 -- 这里做一个容错，如果回合和伤害都一致，并且服务器流程是胜利，验证就会通过 errCode = ErrorEnum.VERIFY_FAIL_WIN_TEAM_NOT_EQUAL end local serRound = battleRecord:getTotalRound() local cliRound = resultData.totalRound or 0 if serRound &gt; cliRound then errCode = ErrorEnum.VERIFY_FAIL_ROUND_NOT_EQUAL end local serDmg = battleRecord:getTotalDamage() local cliDmg = resultData.totalDamage or 0 if serDmg &lt; cliDmg then errCode = ErrorEnum.VERIFY_FAIL_DAMAGE_NOT_EQUAL end local serRebirthTimes = battleRecord:getRebirthTimes() local agentRebirthTimes = resultData.rebirthTimes or 0 if serRebirthTimes &gt; agentRebirthTimes then errCode = ErrorEnum.VERIFY_FAIL_REBIRTH_TIMES end local errMsg, errorRecord, randomTimes if errCode ~= ErrorEnum.SUCCESS then errMsg = string_format( &quot;battle verify fail win(s:%s, c:%s), round(s:%s, c:%s), damage(s:%s, c:%s), rebirthTimes(s:%s, a:%s)&quot; , serWin, cliWin, serRound, cliRound, serDmg, cliDmg, serRebirthTimes, agentRebirthTimes) errorRecord = battleRecord:getErrorRecord() randomTimes = game:getNRand():getTimes() end if fail_list &gt; 0 then errCode = ErrorEnum.VERIFY_FAIL_COMMAND_LIST_ERROR errMsg = &quot;receive command fail&quot; errorRecord = fail_list end if game and not game:bRelease() then log.info(&quot;game not release in battle&quot;) game:release() end local verifyCost = { diff = finish - start, opCostMap = opCostMap, verifySucc = (errCode == ErrorEnum.SUCCESS or resultData.bAbnormalExit), errCode = errCode, } battleVerifyCostProxy.post.record(verifyCost) return errCode, errMsg, errorRecord, randomTimes end battleModule.newGame(gameConfig)将战斗配置数据封装基类， 基类中包含（原配置，轮次，战场，计算器，攻方，守方，基础配置（技能效果，目标，技能，操作命令），BUFF管理器，控制流，战斗记录） function Game:ctor(ID, gameOverCallback, config) self.config = config self.nRand = NRand.new() self.nRand:SetSeed(config.randSeed) local fieldIDs = config.fieldIDs or {} self.battlefield = Battlefield.new(self, fieldIDs) -- 场地技能初始化 calculator.init(self, config.formulaBattleType) -- 计算器初始化 local attackerConfig = config.attacker local attacker = initCharacter(attackerConfig, BattleSideEnum.ATTACKER, self) -- 对应成员实例 attacker:init(attackerConfig) local defenderConfig = config.defender local defender = initCharacter(defenderConfig, BattleSideEnum.DEFENDER, self) self.parserMap = {} for k, v in pairs(parser_cfg) do self.parserMap[k] = v.new(self) end self.buffMgr = BuffMgr.new(self) self.flow = Flow.new(attacker, defender, self.battlefield) self.gameID = ID self.battleRecord = BattleRecord.new(self, ID) self.useGmCom = false self.isRelease = false self.gameOverCallback = gameOverCallback end 轮次类中记录（随机数，轮次，游戏基类） function NRand:ctor() self.seed = 65536 self.times = 0 self.game = nil end 产地技能类 其子类为产地技能管理类，team为队伍配置存放队伍实例，队伍实例创建之后初始化 function Battlefield:ctor(game, fieldIDs) self.teams = { [BattleSideEnum.ATTACKER] = false, [BattleSideEnum.DEFENDER] = false, } self.game = game self.fieldIDs = fieldIDs self.fieldSkillMgr = FieldSkillMgr.new(self.game) end function Team:ctor(game, battleSide, battleCount, nRand) self.battleSide = battleSide self.battleCount = battleCount self.nRand = nRand self.game = game end function FieldSkillMgr:ctor(game) self.game = game self.fieldSkillTable = {} -- type=5 的场地技能生效次数 self.roundEffectTriggerTimes = {} -- 最多5人了 self.aliveHeroNum = 5 end","text":"PP的战斗是由客户端做完，服务端校验，与传统服务端做略有差别 战斗认证传参, 其中认证数据中包含操作指令列表，战斗数据（攻方，守方，cd, 消除权重，随机数， 战斗类型），战斗结果， 服务端跑完完整的指令对比战斗结果 function battleVerifyMgr.startVerify(verifyData) local start = skynet.time() local gameConfig = verifyData.gameConfig local ID = battleModule.newGame(gameConfig) local game = battleModule.getGame(ID) local resultData = verifyData.resultData game:start() local opCostMap = {} local fail_list = {} local commandList = verifyData.commandList for idx, opData in pairs(commandList) do opData.gameID = ID local opStart = skynet.time() local ok = pcall(battleMsgTrigger.receive, opData) local opEnd = skynet.time() local curr = opCostMap[opData.opType] or 0 opCostMap[opData.opType] = curr + opEnd - opStart if not ok then fail_list[fail_list + 1] = { opData = opData, opIndex = idx, } end end -- log.dump(opCostMap, &quot;battleVerify command time cost info&quot;) local finish = skynet.time() local errCode = ErrorEnum.SUCCESS local battleRecord = game:getBattleRecord() local serWin = battleRecord:isAttackerWin() local cliWin = resultData.bWin if serWin ~= cliWin and not serWin then -- 客户端有可能断线重连后发送战斗结果，战斗实际胜利了但是类型不对 -- 这里做一个容错，如果回合和伤害都一致，并且服务器流程是胜利，验证就会通过 errCode = ErrorEnum.VERIFY_FAIL_WIN_TEAM_NOT_EQUAL end local serRound = battleRecord:getTotalRound() local cliRound = resultData.totalRound or 0 if serRound &gt; cliRound then errCode = ErrorEnum.VERIFY_FAIL_ROUND_NOT_EQUAL end local serDmg = battleRecord:getTotalDamage() local cliDmg = resultData.totalDamage or 0 if serDmg &lt; cliDmg then errCode = ErrorEnum.VERIFY_FAIL_DAMAGE_NOT_EQUAL end local serRebirthTimes = battleRecord:getRebirthTimes() local agentRebirthTimes = resultData.rebirthTimes or 0 if serRebirthTimes &gt; agentRebirthTimes then errCode = ErrorEnum.VERIFY_FAIL_REBIRTH_TIMES end local errMsg, errorRecord, randomTimes if errCode ~= ErrorEnum.SUCCESS then errMsg = string_format( &quot;battle verify fail win(s:%s, c:%s), round(s:%s, c:%s), damage(s:%s, c:%s), rebirthTimes(s:%s, a:%s)&quot; , serWin, cliWin, serRound, cliRound, serDmg, cliDmg, serRebirthTimes, agentRebirthTimes) errorRecord = battleRecord:getErrorRecord() randomTimes = game:getNRand():getTimes() end if fail_list &gt; 0 then errCode = ErrorEnum.VERIFY_FAIL_COMMAND_LIST_ERROR errMsg = &quot;receive command fail&quot; errorRecord = fail_list end if game and not game:bRelease() then log.info(&quot;game not release in battle&quot;) game:release() end local verifyCost = { diff = finish - start, opCostMap = opCostMap, verifySucc = (errCode == ErrorEnum.SUCCESS or resultData.bAbnormalExit), errCode = errCode, } battleVerifyCostProxy.post.record(verifyCost) return errCode, errMsg, errorRecord, randomTimes end battleModule.newGame(gameConfig)将战斗配置数据封装基类， 基类中包含（原配置，轮次，战场，计算器，攻方，守方，基础配置（技能效果，目标，技能，操作命令），BUFF管理器，控制流，战斗记录） function Game:ctor(ID, gameOverCallback, config) self.config = config self.nRand = NRand.new() self.nRand:SetSeed(config.randSeed) local fieldIDs = config.fieldIDs or {} self.battlefield = Battlefield.new(self, fieldIDs) -- 场地技能初始化 calculator.init(self, config.formulaBattleType) -- 计算器初始化 local attackerConfig = config.attacker local attacker = initCharacter(attackerConfig, BattleSideEnum.ATTACKER, self) -- 对应成员实例 attacker:init(attackerConfig) local defenderConfig = config.defender local defender = initCharacter(defenderConfig, BattleSideEnum.DEFENDER, self) self.parserMap = {} for k, v in pairs(parser_cfg) do self.parserMap[k] = v.new(self) end self.buffMgr = BuffMgr.new(self) self.flow = Flow.new(attacker, defender, self.battlefield) self.gameID = ID self.battleRecord = BattleRecord.new(self, ID) self.useGmCom = false self.isRelease = false self.gameOverCallback = gameOverCallback end 轮次类中记录（随机数，轮次，游戏基类） function NRand:ctor() self.seed = 65536 self.times = 0 self.game = nil end 产地技能类 其子类为产地技能管理类，team为队伍配置存放队伍实例，队伍实例创建之后初始化 function Battlefield:ctor(game, fieldIDs) self.teams = { [BattleSideEnum.ATTACKER] = false, [BattleSideEnum.DEFENDER] = false, } self.game = game self.fieldIDs = fieldIDs self.fieldSkillMgr = FieldSkillMgr.new(self.game) end function Team:ctor(game, battleSide, battleCount, nRand) self.battleSide = battleSide self.battleCount = battleCount self.nRand = nRand self.game = game end function FieldSkillMgr:ctor(game) self.game = game self.fieldSkillTable = {} -- type=5 的场地技能生效次数 self.roundEffectTriggerTimes = {} -- 最多5人了 self.aliveHeroNum = 5 end 队伍初始化中添加英雄，站位，消除盘，英雄类中包含英雄相关的属性和技能类，技能类有cd长度及其他，消除盘绑定队伍上，消除盘中带有阵营和珠盘 function Team:init(teamConfig, cdCounterInit, nearLogic, swapableCfg) local cdInitList = self:_initCdCounter(cdCounterInit, #teamConfig) -- 英雄 for i, heroConfig in ipairs(teamConfig) do local cdInit = cdInitList and cdInitList[i] local heroInfo = heroConfig.hero local xMin, xMax, y = heroConfig.xMin, heroConfig.xMax, heroConfig.y local hero = Hero.new(i, heroInfo, self.battleSide, xMin, xMax, y, cdInit) heroConfig.hero = hero end -- 布局站位 self.heroLayout = HeroLayout.new(teamConfig, nearLogic) self.coordinateLayout = CoordinateLayout.new(teamConfig) -- 三消盘 self.eliminateBoard = EliminateBoard.new(self.game, teamConfig) -- 换位锁定 self.swapableCfg = swapableCfg or {1,1,1,1,1} local heros = self.heroLayout:getAllHeros() for _, hero in ipairs(heros) do hero:setTeamObj(self) end end function SkillGroup:ctor(skillInfo, battleSide, cdInit) self.id = skillInfo.ID if BattleSideEnum.ATTACKER == battleSide then self.cd = 0 self.cdCounter = 0 else self.cd = skillInfo.cd self.cdCounter = cdInit and cdInit or skillInfo.cdCounterInit end self.needMana = skillInfo.manaCost self.skillType = skillInfo.skillType self.skillsList = skillInfo.skillsList self.skillWeight = skillInfo.skillWeight end function EliminateBoard:ctor(game, teamConfig) local heros = {} for _, heroConfig in ipairs(teamConfig) do local hero = heroConfig.hero local faction = hero:getFaction() heros[faction] = heros[faction] or {} table.insert(heros[faction], hero) end self.heros = heros self.gemBoard = nil self.game = game end 计算器类包含了公式类实例，公式类中有game指针中的轮次，轮次实例及战斗类型保存在公式类中 function calculator.init(game, formulaBattleType) thisGame = game formula.init(game.nRand, formulaBattleType) end function formula.init(gameNRand, formulaBattleType) nRand = gameNRand _battleType = formulaBattleType end 初始化成员initCharacter, 包含三种成员方式，三种方式同时继承于成员基类， 每一种成员都有物品和指令， 成员物品由物品类产生对应的技能 local characterConfig = { [CharacterEnum.PLAYER] = Player, [CharacterEnum.AI] = AI, [CharacterEnum.PLAYER_AI] = PlayerAI, } local Player = class(Character) function Character:ctor(config, battleSide, game) self.battleSide = battleSide self.teams = config.teamConfig self.battlefield = game.battlefield self.game = game end function Player:ctor(config) -- 道具栏 local itemInfos = config.itemInfos log.dump(itemInfos, &quot;itemInfos&quot;) self.itemBar = ItemBar.new(itemInfos) -- 指令列表 self.commandList = {} end function ItemBar:ctor(itemInfo) self.soltItem = itemInfo self.itemList = {} for _, item in pairs(itemInfo) do local skillID = item.skillID local skills = skillConfigMgr.getItemSkillGroup(skillID) assert(skills, string.format(&quot;item(%s) skill(%s) config error&quot;, tostring(item.itemID), tostring(skillID))) item.skills = skills self.itemList[item.itemID] = item end end buff管理器和配置管理器就是依次初始化，流程管理器初始化带三个实例 Flow.new(attacker, defender, self.battlefield) function Flow:ctor(attacker, defender, battlefield) self.battlefield = battlefield self.isOver = false self.roundData = {} self.battleCount = 0 self.characters = { [BattleSideEnum.ATTACKER] = attacker, [BattleSideEnum.DEFENDER] = defender, } end 单场战斗的实例保存于内存中 games[ID] = game 战斗开始，轮次开始赋予gamethis指针，战斗流开始， 构建行为树，debug模式可看日志， 成员实例进入战斗 function Game:start() self.nRand:gameStart(self) self.flow:start(self) end function Flow:start(game) self.game = game -------------Game Start------------- local actionNode = actionTree.newNode(ActionEnum.GAME_BEGIN) msgTrigger.send(actionNode) local battleCountInit = 1 -- 双方入场 characterEnterBattlefield(self.characters[BattleSideEnum.ATTACKER], battleCountInit) characterEnterBattlefield(self.characters[BattleSideEnum.DEFENDER], battleCountInit) self:battle(battleCountInit) end local function characterEnterBattlefield(character, battleCount) local ok, teamConfig = character:enterBattlefield(battleCount) if ok then local battleSide = character:getBattleSide() local actionNode = actionTree.newNode(ActionEnum.TEAM_ENTER, battleCount, battleSide, teamConfig) msgTrigger.send(actionNode) end end 进入战斗依据战斗次数 function Character:enterBattlefield(battleCount) local teamConfig = getNextTeam(self) if teamConfig then local nRand = self.game:getNRand() local cdCounterInit, nearLogic, swapableCfg if BattleSideEnum.DEFENDER == self.battleSide then cdCounterInit = self.game:getCdCounterInit(battleCount) nearLogic = self.game:getNearLogic(battleCount) swapableCfg = self.game:getSwapableCfg(battleCount) end self.battlefield:setTeam(self.battleSide, teamConfig, battleCount, nRand, cdCounterInit, nearLogic, swapableCfg) -- 初始化珠盘 if 1 == battleCount and BattleSideEnum.ATTACKER == self.battleSide then local config = self.game:getConfig() local eliminateWeightCfg = config.eliminateWeightCfg local gemSpawnList = config.gemSpawnList or {} local gemSpawnListCurrWave = gemSpawnList[battleCount] or {} local boardData = config.boardData or {} local gemParamCfg = config.gemParamCfg or {} local team = self.battlefield:getOwnTeam(self.battleSide) local eliminateBoard = team:initGemBoard(eliminateWeightCfg, gemSpawnListCurrWave, boardData, gemParamCfg) self.battlefield:setUniqueEliminateBoard(eliminateBoard) if #gemSpawnList &gt; 0 or #boardData &gt; 0 then self.game:useGmCommand() end end return true, teamConfig else return false end end 角色珠盘都生成完，开始战斗加载攻守双方队伍及英雄，初始化天赋，场地技能，开场天赋,然后开始战斗 function Flow:battle(battleCount) self.battleCount = battleCount handler.startBattle(self, battleCount) -- 攻击方先手 local initRound = 1 self.roundData[self.battleCount] = initRound self:fight(BattleSideEnum.ATTACKER, initRound) end function handler.startBattle(self, battleCount) local actionNode = actionTree.newNode(ActionEnum.BATTLE_BEGIN, battleCount) local attackerTeam = self.battlefield:getOwnTeam(BattleSideEnum.ATTACKER) local gemBoard = attackerTeam:getEliminateBoard():getGemBoard() local allGemList = gemBoard:packAllGemList() local _, gem, gem2 = gemBoard:needShuffle() actionTree.addAction(actionNode, ActionEnum.GEM_BOARD, allGemList, gem, gem2) self.battlefield:startBattle(actionNode, battleCount) msgTrigger.send(actionNode) end 攻方先手 战斗开始流程启动轮次-场地轮次-队伍轮次-英雄轮次-技能有持续cd时间的缩减1， 角色行动为命令解析 function Flow:fight(battleSide, round) assert(round &lt;= ROUND_LIMIT) handler.beginRound(self, battleSide, round) -- 战斗结束了就不要行动了 if self.isOver or self.battlefield:isOver() then return end local character = self.characters[battleSide] character:move(round) end function Hero:roundBegin(rootActionNode, round) log.info(&quot;Hero:roundBegin, round:%s&quot;, round) -- 需要在恢复cd前处理的buff self.buffEventTrigger:dispatch(BuffEventEnum.ROUND_BEGIN, rootActionNode) if self.unSkillCd == 0 then local readyToSkillTag if not self.useSkillTag then local activeSkill = self:getActiveSkillGroup() if activeSkill then readyToSkillTag = (not activeSkill:isNormalAttack() ) and self:canUseSkill() end end for _, skillGroup in ipairs(self.skillGroups) do if not readyToSkillTag then skillGroup:subCDCounter() end end end actionTree.addAction(rootActionNode, ActionEnum.ROUND_BEGIN_SKILL_GROUP_CD, self, self.skillGroups) end 命令解析有两个重要模块，消息模块和命令模块，命令模块包含所有对命名的解析，消息模块包含消息的发送，接收，订阅，注册 local function initMsg() local msgTrigger = require(&quot;battle.msgTrigger&quot;) local command = require(&quot;battle.command&quot;) for msg, callback in pairs(command) do msgTrigger.register(msg, callback) end end function msgTrigger.dispatch(msg, ...) local callback = dispatch[msg] --记录命令和回调的映射 if callback then callback(...) end end 回调的命令进入流程模块执行输入命令 function Flow:inputCommand(...) assert(not self.isOver) local attacker = self.characters[BattleSideEnum.ATTACKER] attacker:input(...) if self.battlefield and self.battlefield:isOver() then if not self:isDefenderHasTeam() then attacker:roundEnd() end end end 当玩家回合结束调用轮次类回合结束回调 function Player:roundEnd() if self.roundEndTag then return end self.roundEndTag = true self:getGame():getFlow():roundEndCallback(self.battleSide) end 轮次类结束回调,判断是否游戏结束，没有的话进入下一轮次，否则判断单场战斗结束还是全部结束调用不同的回调 function Flow:roundEndCallback(battleSide) local round = self:getRound() if battleSide ~= BattleSideEnum.ATTACKER or not self.battlefield:isFinalOver() then handler.endRound(self, battleSide, round) end local isOver, winnerSide = self.battlefield:isOver() if isOver then -- 另一方也结束一下 local otherSide = getOtherSide(battleSide) if otherSide ~= BattleSideEnum.ATTACKER or not self.battlefield:isFinalOver() then handler.endRound(self, otherSide, round) end self:flowOverCallback(winnerSide) else -- 获取对方 local otherSide = getOtherSide(battleSide) round = (battleSide == BattleSideEnum.DEFENDER) and (round + 1) or round self.roundData[self.battleCount] = round self:fight(otherSide, round) end end function Flow:flowOverCallback(winnerSide) local battleCount = self.battleCount if BattleSideEnum.ATTACKER == winnerSide or BattleSideEnum.DEFENDER == winnerSide then local loserSide = getOtherSide(winnerSide) local loser = self.characters[loserSide] if loser:hasRemainTeam() then handler.finishBattle(self, battleCount, winnerSide) local nextBattleCount = battleCount + 1 characterEnterBattlefield(loser, nextBattleCount) self:battle(nextBattleCount) else -------------Game Over------------- self:over(winnerSide) end else -- 平局 local attacker = self.characters[BattleSideEnum.ATTACKER] local attackerHasRemainTeam = attacker:hasRemainTeam() local defender = self.characters[BattleSideEnum.DEFENDER] local defenderHasRemainTeam = defender:hasRemainTeam() if attackerHasRemainTeam and attackerHasRemainTeam then handler.finishBattle(self, battleCount, BattleSideEnum.DEFENDER) local nextBattleCount = battleCount + 1 characterEnterBattlefield(attacker, nextBattleCount) characterEnterBattlefield(defender, nextBattleCount) self:battle(nextBattleCount) elseif attackerHasRemainTeam then -- &gt;&gt;&gt; game over! attacker win! -------------Game Over------------- self:over(BattleSideEnum.ATTACKER) elseif defenderHasRemainTeam then -- &gt;&gt;&gt; game over! defender win! -------------Game Over------------- self:over(BattleSideEnum.DEFENDER) else -- &gt;&gt;&gt; game over! draw! defender win! -------------Game Over------------- self:over(BattleSideEnum.DEFENDER) end end end function Player:input(command, params, opType) tracy.ZoneBeginN(&quot;Server_Player:input&quot;) local commandFunc = commandFunctionCfg[command] assert(commandFunc) local conditionBase = not env.skynet and not gmCommand[command] local isGemCommand = gemCommand[command] local commandList = self.commandList if conditionBase and not isGemCommand then commandList[commandList + 1] = { opType = opType, opParam = params, } conditionBase = false end local bSucc = commandFunc(self, command, params) if conditionBase and (not isGemCommand or bSucc) then commandList[commandList + 1] = { opType = opType, opParam = params, } end if not env.skynet and self.game and packRecordCommand[command] then self.game:getFlow():packUpRecordData() end if env.skynet and isGemCommand and not bSucc then local errorKey = &quot;gem_operate_fail&quot; local errorData = { command = command, params = params, } self.game:getBattleRecord():setErrorRecord(errorKey, errorData) log.warning(errorKey) end -- 成功操作宝石，回合结束 if bSucc and isGemCommand then self:roundEnd() end tracy.ZoneEnd() end 其中英雄技能攻击等是通过解析器实现其中的逻辑相关，解析器中包含命令、效果、技能、目标, 命令解析器负责获取目标列表，解析技能命令 function commandParser:getTargetsList(skill, ownTeam, enemyTeam, caster, targetParams, tauntEffect, transferTarget) local targetParser = self.game:getParser(&quot;Target&quot;) local targetType = skill.targetType local targetParameter = skill.targetParameter local targetIgnore = (skill.targetIgnore == 1) -- 同技能多效果目标传递 if TargetTypeEnum.HERO == targetType and transferTarget.lastTargetRelation and transferTarget.lastTargetRelation == targetParameter[1] and not (targetParams and targetParams.uniqueID) and transferTarget.lastTargetUniqueID then targetParams = { uniqueID = transferTarget.lastTargetUniqueID, } end local targets, isTaunt, extarParam, originTargets = targetParser:analyze(targetType, targetParameter, targetIgnore , ownTeam, enemyTeam, caster, targetParams, tauntEffect) if TargetTypeEnum.HERO == targetType then transferTarget.lastTargetRelation = targetParameter[1] transferTarget.lastTargetUniqueID = targets[1] and targets[1]:getUniqueID() end -- return { targets = targets, isTaunt = isTaunt, extarParam = extarParam, originTargets = originTargets, } end function commandParser:parseSkillCommand(rootActionNode, battleSide, skillGroup, caster, targetParams, extraParam) -- 使用技能统计 local eventData = { caster = caster, } local battleRecord = self.game:getBattleRecord() battleRecord:useSkillEvent(eventData) local battlefield = self.game:getBattleField() local skillParser = self.game:getParser(&quot;Skill&quot;) skillGroup:resetCDCounter() local useSkillNode = actionTree.addAction(rootActionNode, ActionEnum.USE_SKILL_GROUP, caster, skillGroup) local needMana = skillGroup:getNeedMana() if caster and extraParam and extraParam.costManaPer then needMana = calculator.getHeroMaxManaWithPer(caster, extraParam.costManaPer) end caster:costMana(useSkillNode, needMana, CostManaTypeEnum.USE_SKILL) local skillNode = actionTree.addAction(useSkillNode, ActionEnum.SKILL_GROUP, caster, skillGroup) -- 放技能 local ownTeam = battlefield:getOwnTeam(battleSide) local enemyTeam = battlefield:getEnemyTeam(battleSide) local effectParam = { effectSource = skillGroup:isNormalAttack() and SkillEffectSourceEnum.NORMAL or SkillEffectSourceEnum.ACTIVE, } local skills = skillGroup:getSkills() local tauntEffect = effectParam.effectSource == SkillEffectSourceEnum.ACTIVE -- 技能效果之间的参数传递 local passParam = {} local transferTarget = {} for skillIndex, skill in ipairs(skills) do local skillTargets = self:getTargetsList(skill, ownTeam, enemyTeam, caster, targetParams, tauntEffect , transferTarget) local count = skill.count for i = 1, count do local skillParam = { skillIndex = skillIndex, skillCount = count, currCount = i, } exceptionUtils.xpcall(skillParser.analyze, self.game, skillNode , ownTeam, caster, skill, effectParam, skillParam, skillTargets, passParam) end end end 技能解析器中包含效果解析器, 效果解析器会解析伤害、回血、耗蓝及buff情况, effectConfig配置了对应效果实现方法树，方法中关联buff function effectParser:analyze(rootActionNode, effect, caster, target, effectParam, passParam) log.dump(effect, &quot;effect&quot;) local actionNode = rootActionNode if not noHeroEffect[effect.effectType] then actionNode = actionTree.addAction(rootActionNode, ActionEnum.EFFECT_HIT, target, effect) end effectParam = effectParam or {} passParam = passParam or {} -- 宝石参数转换 local gemParamConver = gemParamConverCfg[effect.effectType] if gemParamConver and effectParam.gemParam then gemParamConver(effectParam, effectParam.gemParam) effectParam.gemParam = nil end effectConfig[effect.effectType](target, self, actionNode, effect, caster, target, effectParam, passParam) end","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"http://zxtotti17.github.io/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"PP-任务统计属性筛选解锁模块","slug":"PP-任务统计属性筛选解锁","date":"2022-12-30T03:12:59.000Z","updated":"2023-02-28T03:44:34.719Z","comments":true,"path":"/post/PP-任务统计属性筛选解锁.html","link":"","permalink":"http://zxtotti17.github.io/post/PP-%E4%BB%BB%E5%8A%A1%E7%BB%9F%E8%AE%A1%E5%B1%9E%E6%80%A7%E7%AD%9B%E9%80%89%E8%A7%A3%E9%94%81.html","excerpt":"PP中的任务部分分为统计和发布任务两块， 其中发布任务分为（基础任务，多目标任务，链式任务，通用任务管理），统计部分分为…层级上由外到内是 任务管理 - 任务 - 统计， 同时统计类上层包含了一个筛选系统 任务管理模块该模块负责将发布任务，同时将任务构建成目录树 local taskSystem = {} --外联 local taskMap = {} -- 内部任务树 #接受普通任务 function taskSystem.publishTask(taskCfgID, initProgress, callback) local taskCfg = taskConfigMgr.getTaskCfg(taskCfgID) if not taskCfg then return end local uniqueID = newTaskID() local callbackHandler = { progressUpdateCallback = callback, taskFinishCallback = taskFinish } local cfg = statisticalCfg.getStatisticalTaskCfg(taskCfg.statsRuleID) assert(cfg, string_format(&quot;addStatisticalTask cfg nil, taskRuleID:%s&quot;, taskCfg.statsRuleID)) local statsRuleType = cfg.stateType local statsFilters = cfg.filter local taskObj = Task.new(uniqueID, taskCfg.aimParam, statsRuleType, statsFilters, initProgress, callbackHandler) taskObj:init() taskMap[uniqueID] = taskObj if taskObj:isFinish() then taskObj:completeTask() end return uniqueID end 任务模块类基础任务模块，其中有基本的更新进度设置进度等 local PENDING = 1 -- 待接取的 local STATISTICAL = 2 -- 统计中 local FINISH = 3 -- 完成的 function M:ctor(uniqueID, aim, statsRuleType, statsFilters, initProgress, handler) self.uniqueID = uniqueID –任务唯一id自动生成 self.aim = aim –任务目标 self.statsRuleType = statsRuleType self.statsFilters = statsFilters self.status = PENDING self.progress = initProgress self.handler = handler –回调函数 self.statisticalHandler = nilend function M:createStatistical() self.statisticalHandler = statistics.addCustomizeStatisticalTask(self.statsRuleType, self.statsFilters, {}, self.progress, function(val) self:setProgress(val) end)end function M:setProgress(value) if STATISTICAL == self.status then self.progress = value self:updateStatus() local isFinish = self:isFinish() skynet.fork(self.handler.progressUpdateCallback, isFinish, self.uniqueID, self.progress) if isFinish then self:finishCallback() end return true else return false endend 链式任务模块，通过判断目标值确定链式任务的完成下标 ``` bash function M:ctor(config, handler, refresh) assert(checkUtil.isTableAndNotEmpty(config)) self.config = config self.handler = handler -- 回调函数 self.data = nil self.taskIDMap = {} self.refresh = refresh self.config.link = packLinkFunc(self.config.link) -- 记录链数组啥的都行 end多目标模块，及是需要多个目标才能完成任务, aimData目标值为一个map管理即可，其他和普通基本一样 self.aimData = {} for k, aim in pairs(aimMap) do self.aimData[k] = { status = PENDING, aim = aim, } end","text":"PP中的任务部分分为统计和发布任务两块， 其中发布任务分为（基础任务，多目标任务，链式任务，通用任务管理），统计部分分为…层级上由外到内是 任务管理 - 任务 - 统计， 同时统计类上层包含了一个筛选系统 任务管理模块该模块负责将发布任务，同时将任务构建成目录树 local taskSystem = {} --外联 local taskMap = {} -- 内部任务树 #接受普通任务 function taskSystem.publishTask(taskCfgID, initProgress, callback) local taskCfg = taskConfigMgr.getTaskCfg(taskCfgID) if not taskCfg then return end local uniqueID = newTaskID() local callbackHandler = { progressUpdateCallback = callback, taskFinishCallback = taskFinish } local cfg = statisticalCfg.getStatisticalTaskCfg(taskCfg.statsRuleID) assert(cfg, string_format(&quot;addStatisticalTask cfg nil, taskRuleID:%s&quot;, taskCfg.statsRuleID)) local statsRuleType = cfg.stateType local statsFilters = cfg.filter local taskObj = Task.new(uniqueID, taskCfg.aimParam, statsRuleType, statsFilters, initProgress, callbackHandler) taskObj:init() taskMap[uniqueID] = taskObj if taskObj:isFinish() then taskObj:completeTask() end return uniqueID end 任务模块类基础任务模块，其中有基本的更新进度设置进度等 local PENDING = 1 -- 待接取的 local STATISTICAL = 2 -- 统计中 local FINISH = 3 -- 完成的 function M:ctor(uniqueID, aim, statsRuleType, statsFilters, initProgress, handler) self.uniqueID = uniqueID –任务唯一id自动生成 self.aim = aim –任务目标 self.statsRuleType = statsRuleType self.statsFilters = statsFilters self.status = PENDING self.progress = initProgress self.handler = handler –回调函数 self.statisticalHandler = nilend function M:createStatistical() self.statisticalHandler = statistics.addCustomizeStatisticalTask(self.statsRuleType, self.statsFilters, {}, self.progress, function(val) self:setProgress(val) end)end function M:setProgress(value) if STATISTICAL == self.status then self.progress = value self:updateStatus() local isFinish = self:isFinish() skynet.fork(self.handler.progressUpdateCallback, isFinish, self.uniqueID, self.progress) if isFinish then self:finishCallback() end return true else return false endend 链式任务模块，通过判断目标值确定链式任务的完成下标 ``` bash function M:ctor(config, handler, refresh) assert(checkUtil.isTableAndNotEmpty(config)) self.config = config self.handler = handler -- 回调函数 self.data = nil self.taskIDMap = {} self.refresh = refresh self.config.link = packLinkFunc(self.config.link) -- 记录链数组啥的都行 end多目标模块，及是需要多个目标才能完成任务, aimData目标值为一个map管理即可，其他和普通基本一样 self.aimData = {} for k, aim in pairs(aimMap) do self.aimData[k] = { status = PENDING, aim = aim, } end 统计模块再任务模块内，一个任务对应一个或者多个规则，一个规则对应一种统计PP统计分为统计基类，监听，管理，接口，规则，获取初始， 基类如下，主要功能是添加数量及回调 function M:ctor(statisitcalType, filters, calcRule, callback, initValue) self.statisitcalType = statisitcalType self.filters = filters -- 筛选条件 self.calcRule = calcRule -- 占时无用 self.callback = callback self.value = initValue or 0 self.initialize = false end local function calculate(self, ...) local filterData = statisticalAdapter[self.statisitcalType].transToFilterData(...) if checkUtil.notTableOrEmpty(self.filters) or filterSystem.isPassFilters(self.filters, filterData) then #判断赛选条件及打包筛选数据 self.value = statisticalAdapter[self.statisitcalType].calculate(self.value, self.filters, ...) -- log.info(&quot;ssssssssss statisitcalType:%d, val:%d&quot;, self.statisitcalType, self.value) return true end return false end function M:count(...) if statisticalAdapter[self.statisitcalType].traversing(calculate, self, ...) then self.callback(self.value) end end 任务管理模块主要是任务的添加 删除， 加值 local taskTypeMap = {} local taskIDMap = {} local function saveTask(uniqueID, task) local taskType = task:getType() taskIDMap[uniqueID] = task taskTypeMap[taskType] = taskTypeMap[taskType] or {} taskTypeMap[taskType][task] = uniqueID end function Mgr.addTask(taskType, taskFilters, countRule, callback, initValue) local uniqueID = newTaskID() local filters = filterCfgMgr.getFilterListCfg(taskFilters) local task = statistical.new(taskType, filters, countRule, callback, initValue) if Mgr.isStartCount() then task:init() end saveTask(uniqueID, task) return uniqueID end function Mgr.addUp(taskType, ...) #log.dump(taskTypeMap, &quot;statisticalMgr addUp 666666666666&quot;) if not taskTypeMap[taskType] or not next(taskTypeMap[taskType]) then # log.info(&quot;statisticalMgr addUp return %d&quot;, taskType) return end for task, _ in pairs(taskTypeMap[taskType]) do local ok, err = exceptionUtil.xpcall(task.count, task, ...) if not ok then log.error(&quot;statisticalMgr addUp %s error: %s&quot;, taskType, err) end end end 监听模块做的是将类型及方法对应，将方法设置进统计模块 eventListener.register(AgentEventEnum.COLLECTION, eventListener.playerCollect) 筛选模块通过继承对应不同的类型，第一个是条件，第二个增加方法,类型映射 local metaHandler = { transToFilterData = function() #赛选条件 return end, calculate = function(value, _, count) #增加逻辑 return value + count end } local adapter = { [StatisticalEnum.TAX] = addHandler, ... } 初始化模块做对应的校验和值的获取 function M:init() if self.initialize then return else self.initialize = true end if not self.value or self.value == 0 then #没有传入初始值的情况用从别的模块获取统计初始值 local initValue = statisticalInitValHandler.getInitValue(self.statisitcalType, self.filters) if self.value ~= initValue then self.value = initValue skynet.fork(function() if &quot;function&quot; == type(self.callback) then self.callback(self.value) end end) end end end function M.getInitValue(statisitcalType, ...) local f = initValFunc[statisitcalType] if f then return f(...) else return 0 end end 筛选、属性、公式3者是公共模块，筛选模块包含5种类型和2种方法，一种通过筛选id获取筛选条件筛选，一种通过筛选条件筛选local filterHandler = { [filterHandlerTypeEnum.CONTAINS] = containHandler, #包含 [filterHandlerTypeEnum.RANGE] = rangeHandler, #范围 [filterHandlerTypeEnum.MATCH_STRING] = matchStringHandler, #字符串包含 [filterHandlerTypeEnum.BE_CONTAINED] = beContainHandler, #全包含 [filterHandlerTypeEnum.NO_CONTAINS] = noContainHandler, #不包含 } function filterLogic.isPassMultiFilter(filters, filterData) if notTableOrEmpty(filters) then – log.info(“filters is empty”) return true end if notTableOrEmpty(filterData) then – log.info(“filterData is empty”) return false end – log.dump(filters, “=========filters”) – log.dump(filterData, “=========filterData”) for _, filterCfg in pairs(filters) do if not isPassFilter(filterCfg, filterData) then return false end end return trueend local function isPassFilter(filterCfg, filterData) if not filterCfg then – log.info(string_format(“filter cfg not found”)) return false end local filterType = filterCfg.filterType local data = filterData[filterType] if not data then return false end local filterValType = filterCfg.filterValueType return filterHandler[filterValType](filterCfg.filterValue, data)end 4. 属性系统类似，属性分为属性和筛选条件2部分， 基本都是配置，管理，接口，事件，整体构造hash 属性中事件主要关联（ 属性类型和回调函数） ``` bash 基类中就一个map data = {} -- 存属性数据 同时基类中包含增删改查属性的方法，其中给外部使用的改变值方法嵌套筛选模块，通过筛选才能改变 外部管理的接口方法中包含3个对象 local totalContainer = attrContainer.new() --总属性对象 local sourceContainerMap = {} --属性源对象 local floatContainerMap = {} --浮点型源对象 事件类包含2个对象 local eventData = {} -- 类型id对应回调函数对象 local events = {} -- 回调函数地址对应的类型id 普通属性设置设置源属性和总属性，移除也是一样，管理部分也包含增删改查 self.data[attrType] = {} function M:set(attrType, attrID, attrVal, source) local attrMap = self:getAttrKeyMap(attrType) if not attrMap[attrID] then attrMap[attrID] = {total = 0} end local attrData = attrMap[attrID] if not attrData[source] then attrData[source] = attrVal attrData.total = attrData.total + attrVal return true end local curVal = attrData[source] if attrVal == curVal then return false end attrData[source] = attrVal attrData.total = attrData.total + attrVal - curVal return true end 事件对象中设置id和回调的对应关系 local function setCallback(attrType, callback, handle) local data = eventData[attrType] if not data then data = { callbacks = {}, handles = {}, } eventData[attrType] = data end data.callbacks[handle] = callback data.handles[callback] = handle end 外部通过注册和执行来实现回调 function attributeEvent.register(attrType, callback) if isCallbackExist(attrType, callback) then error(&quot;Repeat register&quot;) else local handle = newHandle() setCallback(attrType, callback, handle) events[handle] = attrType return handle end end function attributeEvent.forkDispatch(attrType) assert(fork, &quot;forkFunc not init&quot;) local data = eventData[attrType] if data then for _, callback in pairs(data.callbacks) do fork(callback) end end end 接口部分添加属性配置及事件注册回调初始化 function attrSys.init(cfg, forkFunc) attrCfgMgr.init(cfg) attrEvent.init(forkFunc) initFlag = true queryFlag = true end function attrSys.register(attrType, callback) return attrEvent.register(attrType, callback) end ... 解锁模块，本质上也是任务的一种，通过完成任务回调解锁，任务有固定目标aim及是解锁的目标 local function registerUnlock(cfg, callback, together) local unlockID = newUnlockID() if not checkUtil.isTableAndNotEmpty(cfg) then return unlockID end local handle = { questCompleted = function() questMap[unlockID] = nil callback(unlockID) end, } local Quest = MultiAimQuest.new(cfg, handle, together) Quest:init() questMap[unlockID] = Quest return unlockID end 上面注册解锁的配置是通过下面函数产生痛苦规则和条件、目标， unlockConvertConf 每一个类型对应一个配置统计返回function M.convertUnlock(unlockCon) if not next(unlockCon) then return {} end local conditionType = unlockCon[1] if conditionType == ConditionTypeEnum.NONE then return {} end local f = unlockConvertConf[conditionType] if not f then log.error(&quot;condition type error, type:%s&quot;, conditionType) return end local statsRuleType, statsFilters, aim = f(unlockCon[2], unlockCon[3]) return { statsRuleType = statsRuleType, statsFilters = statsFilters, aim = aim }end还有一个判断模块或者系统解锁，unlockLogicConf 每一个配置对应一个解锁逻辑判断– 与 的关系function L.unlockByTogetherCon(unlockCon) if not unlockCon then return false end -- {}，默认解锁 if type(unlockCon) == &quot;table&quot; and not next(unlockCon) then return true end for _,v in pairs(unlockCon) do local unlockType, unlockConx, unlockExpand = v[1], v[2], v[3] if unlockType == ConditionTypeEnum.LOCK then return false elseif unlockType ~= ConditionTypeEnum.NONE then local f = unlockLogicConf[unlockType] if f then local ok = f(unlockConx, unlockExpand) if not ok then return false end else log.error(&quot;not found unlock type %s&quot;, unlockType) return false end end end return trueend```","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"http://zxtotti17.github.io/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"魔域资料库目录结构生成","slug":"myzlk_menu","date":"2022-09-13T06:34:26.000Z","updated":"2022-09-13T07:36:52.245Z","comments":true,"path":"/post/myzlk_menu.html","link":"","permalink":"http://zxtotti17.github.io/post/myzlk_menu.html","excerpt":"","text":"魔域资料库类似于魔域的成就达成系统成就的目录及内容通过后台配置表结构设计上，保证一个主菜单id 和关联父菜单iD，同样作品下也是，支持拖拽排序，将完整的菜单构建成菜单树的结构，用父关联替代一个层级一个字段方便以后的拓展性不用加层级字段 CREATE TABLE &#96;moyu_lists&#96; ( &#96;id&#96; char(24) NOT NULL COMMENT &#39;编号&#39;, &#96;menu_root_id&#96; varchar(50) DEFAULT &#39;&#39; COMMENT &#39;主菜单Id&#39;, &#96;menu_prent_id&#96; varchar(50) DEFAULT &#39;&#39; COMMENT &#39;关联父Id&#39;, &#96;title&#96; varchar(1000) DEFAULT &#39;&#39; COMMENT &#39;标题&#39;, &#96;icon&#96; varchar(500) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT &#39;&#39; COMMENT &#39;图标地址&#39;, &#96;menu_level&#96; int(11) DEFAULT 1 COMMENT &#39;目录层级&#39;, &#96;sort_index&#96; int(11) NULL DEFAULT 0 COMMENT &#39;排序号&#39;, &#96;show_all&#96; int(11) NULL DEFAULT 0 COMMENT &#39;是否显示全部&#39;, &#96;is_delete&#96; int(11) DEFAULT 0 COMMENT &#39;是否删除&#39;, &#96;create_time&#96; datetime DEFAULT NULL COMMENT &#39;创建时间&#39;, PRIMARY KEY (&#96;id&#96;), KEY &#96;menu_prent&#96; (&#96;menu_root_id&#96;,&#96;menu_prent_id&#96;) USING BTREE, KEY &#96;level_sort&#96; (&#96;menu_level&#96;,&#96;sort_index&#96;) USING BTREE ) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8mb4 ROW_FORMAT&#x3D;DYNAMIC; CREATE TABLE &#96;moyu_works&#96; ( &#96;id&#96; char(24) NOT NULL COMMENT &#39;编号&#39;, &#96;menu_root_id&#96; varchar(50) DEFAULT &#39;&#39; COMMENT &#39;主菜单Id&#39;, &#96;menu_id&#96; varchar(50) DEFAULT &#39;&#39; COMMENT &#39;关联菜单Id&#39;, &#96;works_id&#96; varchar(50) DEFAULT &#39;&#39; COMMENT &#39;作品ID&#39;, &#96;game_condition&#96; int(11) DEFAULT 0 COMMENT &#39;游戏解锁条件&#39;, &#96;game_condition_desc&#96; varchar(1000) DEFAULT &#39;&#39; COMMENT &#39;游戏解锁条件描述&#39;, &#96;works_title&#96; varchar(1000) DEFAULT 0 COMMENT &#39;作品标题&#39;, &#96;item_id&#96; int(11) DEFAULT 0 COMMENT &#39;游戏物品id&#39;, &#96;menu_level&#96; int(11) DEFAULT 1 COMMENT &#39;目录层级&#39;, &#96;sort_index&#96; int(11) NULL DEFAULT 0 COMMENT &#39;排序号&#39;, &#96;is_delete&#96; int(11) DEFAULT 0 COMMENT &#39;是否删除&#39;, &#96;create_time&#96; datetime DEFAULT NULL COMMENT &#39;创建时间&#39;, PRIMARY KEY (&#96;id&#96;), KEY &#96;menu_prent&#96; (&#96;menu_root_id&#96;,&#96;menu_id&#96;) USING BTREE, KEY &#96;sort_index&#96; (&#96;sort_index&#96;) USING BTREE ) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8mb4 ROW_FORMAT&#x3D;DYNAMIC; 通过查询出的menu_level 和 sort_index的排序规则构建层级 private async getMenuLists(doingList:MoyuLists[], isUse?:boolean): Promise&lt;any[]&gt;&#123; let result:any &#x3D; []; let indexMap:any &#x3D; &#123;&#125;; for(let i &#x3D; 0, l &#x3D; doingList.length; i &lt; l; i++)&#123; let tmp:MoyuLists &#x3D; doingList[i]; if(tmp.menu_level &#x3D;&#x3D; 1)&#123; let oneMap:any &#x3D; &#123;&#125;; if(isUse)&#123; oneMap &#x3D; MoyuListsBody.buildOne(tmp); &#125;else&#123; oneMap &#x3D; new MoyuLists(tmp); oneMap.childs &#x3D; []; &#125; result.push(oneMap); indexMap[tmp.id] &#x3D; result.length - 1; &#125;else if(tmp.menu_level &#x3D;&#x3D; 2 &amp;&amp; indexMap[tmp.menu_root_id] &gt;&#x3D; 0)&#123; let oneIndex &#x3D; indexMap[tmp.menu_root_id] || 0; let oneMap:any &#x3D; &#123;&#125;; if(isUse)&#123; oneMap &#x3D; MoyuListsBody.buildOne(tmp); &#125;else&#123; oneMap &#x3D; new MoyuLists(tmp); oneMap.childs &#x3D; []; &#125; result[oneIndex].childs.push(oneMap); let twoL &#x3D; result[oneIndex].childs.length - 1; indexMap[tmp.id] &#x3D; [oneIndex, twoL]; &#125;else if(tmp.menu_level &#x3D;&#x3D; 3 &amp;&amp; indexMap[tmp.menu_prent_id])&#123; let twoIndex &#x3D; indexMap[tmp.menu_prent_id]; let oneMap:any &#x3D; &#123;&#125;; if(isUse)&#123; oneMap &#x3D; MoyuListsBody.buildOne(tmp); &#125;else&#123; oneMap &#x3D; new MoyuLists(tmp); oneMap.childs &#x3D; []; &#125; result[twoIndex[0]].childs[twoIndex[1]].childs.push(oneMap); let threeL &#x3D; result[twoIndex[0]].childs[twoIndex[1]].childs.length - 1; indexMap[tmp.id] &#x3D; [twoIndex[0], twoIndex[1], threeL]; &#125;else if(tmp.menu_level &#x3D;&#x3D; 4 &amp;&amp; indexMap[tmp.menu_prent_id])&#123; let threeIndex &#x3D; indexMap[tmp.menu_prent_id]; let oneMap:any &#x3D; &#123;&#125;; if(isUse)&#123; oneMap &#x3D; MoyuListsBody.buildOne(tmp); &#125;else&#123; oneMap &#x3D; new MoyuLists(tmp); oneMap.childs &#x3D; []; &#125; result[threeIndex[0]].childs[threeIndex[1]].childs[threeIndex[2]].childs.push(oneMap); let fourL &#x3D; result[threeIndex[0]].childs[threeIndex[1]].childs[threeIndex[2]].childs.length - 1; indexMap[tmp.id] &#x3D; [threeIndex[0], threeIndex[1], threeIndex[2], fourL]; &#125; &#125; return result; &#125; 以上是构建4级目录的树的方式，下标索引用一个map对象维护，一般4~5级的层级即可， 如果需要在拓展就继续加对应代码后台更新和添加的时候都mq发布出来刷新指令，不去维护树中的改变，重新刷新缓存中的使用的菜单树，达到热更新的效果 public async refreshUseLists(): Promise&lt;any&gt; &#123; EventManager.getInstance().execSync(&#39;moyuListsSync.refresh&#39;, &quot;&quot;) return true; &#125;","categories":[],"tags":[{"name":"游戏","slug":"游戏","permalink":"http://zxtotti17.github.io/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"Gin-Vue-Admin","slug":"gin-vue-admin","date":"2022-09-09T08:26:26.000Z","updated":"2022-09-09T08:27:42.386Z","comments":true,"path":"/post/gin-vue-admin.html","link":"","permalink":"http://zxtotti17.github.io/post/gin-vue-admin.html","excerpt":"","text":"服务端用go的gin框架下的开源后台系统，后台部分使用的是vue3.0开发从github上down下服务器代码 https://github.com/flipped-aurora/gin-vue-adminset GOPROXY=https://goproxy.cn,direct1.先进入server目录 安装对应的资源包 go generate -x安装完依赖之后 go build main.go生成服务端启动文件main.exe启动2.安装客户端后台， 安装node16.0以上版本， cd web目录 npm install 安装依赖，安装完成后用npm run serve启动前端浏览器进入http://127.0.0.1:8080/这个地址，后选择初始化，填写相关配置会自动生成db及数据进入后台页面后即可开始vue和后台学习记录下几个重要的插件使用1.swag自动生成restFul文档go install github.com/swaggo/swag/cmd/swag@latest 安装swag包 在到服务器目录下执行 swag init命令初始化，swag只能用在几个特定的服务端框架上自动生成文档，这里就说下gin在gin的路由文件的地方引入包“github.com/swaggo/gin-swagger”“github.com/swaggo/gin-swagger/swaggerFiles”Router := gin.Default()//获取一个引擎中间件的实例Router.GET(“/swagger/*any”, ginSwagger.WrapHandler(swaggerFiles.Handler))//关联自动生成文档在服务端目录swagger/index.html即可查看相关文档信息2.gorm 谷歌的一个库方便对数据库的使用，简化了开发及安全，不方便用于复杂sql的使用在db初始化的地方引入包“gorm.io/driver/mysql”“gorm.io/gorm”从设定的配置文件中加载配置信息，用gorm.open建立连接 func GormMysqlByConfig(m config.Mysql) *gorm.DB &#123; if m.Dbname &#x3D;&#x3D; &quot;&quot; &#123; return nil &#125; mysqlConfig :&#x3D; mysql.Config&#123; DSN: m.Dsn(), &#x2F;&#x2F; DSN data source name DefaultStringSize: 191, &#x2F;&#x2F; string 类型字段的默认长度 SkipInitializeWithVersion: false, &#x2F;&#x2F; 根据版本自动配置 &#125; if db, err :&#x3D; gorm.Open(mysql.New(mysqlConfig), internal.Gorm.Config()); err !&#x3D; nil &#123; panic(err) &#125; else &#123; sqlDB, _ :&#x3D; db.DB() sqlDB.SetMaxIdleConns(m.MaxIdleConns) sqlDB.SetMaxOpenConns(m.MaxOpenConns) return db &#125; &#125; 返回的db存放在全局global.GVA_DB，使用上依据gorm的语法规则global.GVA_DB.Where(“id = ?”, info.Uint()).Delete(&amp;system.SysAutoCodeHistory{}).Error","categories":[],"tags":[{"name":"go","slug":"go","permalink":"http://zxtotti17.github.io/tags/go/"}]},{"title":"Go的调度","slug":"go的调度","date":"2022-09-09T08:05:03.000Z","updated":"2022-09-09T08:21:14.350Z","comments":true,"path":"/post/go的调度.html","link":"","permalink":"http://zxtotti17.github.io/post/go%E7%9A%84%E8%B0%83%E5%BA%A6.html","excerpt":"","text":"go语言中的调度是个G-P-M的模型G: G代表的是一个goroutine对象，常说的协程，真正携带代码执行逻辑的部分。M：M代表的是一个内核级线程，所有的G任务，最终还是在M上执行。P：P代表的是一个处理器，P是用一个全局数组（255）来保存的，并且维护着一个全局的P空闲链表，一个P可以对应多个M,但同一时刻只能与一个M绑定关系，goroutine对应的结构如下，Go语言中，每一个goroutine是一个独立的执行单元，相较于每个OS线程固定分配2M内存的模式，goroutine的栈采取了动态扩容方式， 初始时仅为2KB，随着任务执行按需增长，最大可达1GB，且完全由golang自己的调度器 Go Scheduler 来调度 type g struct &#123; stack stack &#x2F;&#x2F; 描述了当前 Goroutine 的栈内存范围 [stack.lo, stack.hi) stackguard0 uintptr &#x2F;&#x2F; 是对比 Go 栈增长的 prologue 的栈指针, 可以用于调度器抢占式调度 stackguard1 uintptr &#x2F;&#x2F; 是对比 C 栈增长的 prologue 的栈指针 ... _panic *_panic &#x2F;&#x2F; 最内侧的 panic 结构体 _defer *_defer &#x2F;&#x2F; 最内侧的延迟函数结构体 m *m &#x2F;&#x2F; 当前的m sched gobuf &#x2F;&#x2F; goroutine切换时，用于保存g的上下文 ... param unsafe.Pointer &#x2F;&#x2F; 用于传递参数，睡眠时其他goroutine可以设置param，唤醒时该goroutine可以获取 atomicstatus uint32 &#x2F;&#x2F; Goroutine 的状态 stackLock uint32 goid int64 &#x2F;&#x2F; goroutine的ID ... waitsince int64 &#x2F;&#x2F; g被阻塞的大体时间 preempt bool &#x2F;&#x2F; 抢占信号 preemptStop bool &#x2F;&#x2F; 抢占时将状态修改成 &#96;_Gpreempted&#96; preemptShrink bool &#x2F;&#x2F; 在同步安全点收缩栈 ... lockedm *m &#x2F;&#x2F; G被锁定只在这个m上运行 ... &#125; 协作的抢占式调度每当有 goroutine 要创建时，会被添加到 P 上的 goroutine 本地队列上，如果 P 的本地队列已满，则会维护到全局队列里。在进行调度时，会优先从本地队列获取 goroutine 来执行。如果本地队列没有，会从其他的 P 上偷取 goroutine。如果其他 P 上也没有，则会从全局队列上获取 goroutine。这样通过上面的策略，就能尽最大努力保证有 goroutine 可运行。P的结构 type p struct &#123; id int32 status uint32 &#x2F;&#x2F; 状态，可以为pidle&#x2F;prunning&#x2F;... link puintptr schedtick uint32 &#x2F;&#x2F; 每调度一次加1 syscalltick uint32 &#x2F;&#x2F; 每一次系统调用加1 sysmontick sysmontick m muintptr &#x2F;&#x2F; 回链到关联的m mcache *mcache &#x2F;&#x2F;当前m的内存缓存，意味着不必为每一个M都配备一块内存，避免了过多的内存消耗。 pcache pageCache raceprocctx uintptr ...... &#x2F;&#x2F; goroutine ids的缓存，摊销对runtime-sched.goidgen的访问。 goidcache uint64 goidcacheend uint64 &#x2F;&#x2F; 可运行的goroutine的队列. 不需要锁即可访问 runqhead uint32 runqtail uint32 runq [256]guintptr runnext guintptr &#x2F;&#x2F; 下一个运行的g，以高优先级执行 unblock G，提高了一些包的性能。 &#x2F;&#x2F; 可用的G (status &#x3D;&#x3D; Gdead， Gdead 表示这个goroutine目前未被使用) gFree struct &#123; gList n int32 &#125; &#x2F;&#x2F; sudog 代表等待列表中的一个G，例如在向通道执行发送&#x2F;接收的G。 sudogcache []*sudog sudogbuf [128]*sudog &#x2F;&#x2F; 堆中mspan对象的缓存 mspancache struct &#123; &#x2F;&#x2F; len 被用于不允许写障碍的调用代码路径中 len int buf [128]*mspan &#125; ...... palloc persistentAlloc &#x2F;&#x2F; per-P to avoid mutex ...... &#125; M对应的线程的栈，当指定了线程栈，则M.stack→G.stack，M的PC寄存器指向G提供的函数，然后去执行 type m struct &#123; &#x2F;&#x2F; g0是带有调度栈的goroutine。 &#x2F;&#x2F; 普通的Goroutine栈是在Heap分配的可增长的stack,而g0的stack是M对应的线程栈。 &#x2F;&#x2F; 所有调度相关代码,会先切换到该Goroutine的栈再执行。 g0 *g ...... gsignal *g &#x2F;&#x2F; 处理信号的goroutine ...... tls [6]uintptr &#x2F;&#x2F; thread-local storage mstartfn func() &#x2F;&#x2F;m入口函数 curg *g &#x2F;&#x2F; 当前运行的goroutine caughtsig guintptr p puintptr &#x2F;&#x2F; 关联p和执行的go代码 nextp puintptr oldp puintptr &#x2F;&#x2F; 在执行系统调用之前所附加的p id int32 mallocing int32 &#x2F;&#x2F; 状态 ...... locks int32 &#x2F;&#x2F;m的锁 ...... spinning bool &#x2F;&#x2F; m不在执行g，但在积极寻找可执行的g blocked bool &#x2F;&#x2F; m是否被阻塞 newSigstack bool printlock int8 incgo bool &#x2F;&#x2F; m是否在执行cgo freeWait uint32 &#x2F;&#x2F; 如果为0，将安全释放g0并删除m（原子性）。 fastrand uint32 ...... ncgocall uint64 &#x2F;&#x2F; cgo调用的总数 ncgo int32 &#x2F;&#x2F; 当前cgo调用的数目 ...... park note alllink *m &#x2F;&#x2F; 用于链接allm schedlink muintptr lockedg *g &#x2F;&#x2F; 锁定g在当前m上执行，而不会切换到其他m createstack [32]uintptr &#x2F;&#x2F; thread创建的栈 ...... nextwaitm muintptr &#x2F;&#x2F; 下一个等待的m ...... &#125; M 优先从 P 的本地队列获取 goroutine，减少并发竞争。并且保证了最多跟 CPU 核心数一样的 goroutine 数量在并行运行，充分利用了多核优势","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"go","slug":"go","permalink":"http://zxtotti17.github.io/tags/go/"}]},{"title":"node.js对接protobuff及protobuff3","slug":"node-js对接protobuff及protobuff3","date":"2022-09-07T11:07:06.000Z","updated":"2022-09-13T07:05:37.300Z","comments":true,"path":"/post/node-js对接protobuff及protobuff3.html","link":"","permalink":"http://zxtotti17.github.io/post/node-js%E5%AF%B9%E6%8E%A5protobuff%E5%8F%8Aprotobuff3.html","excerpt":"protobuf作为现在最流行的序列化数据结构的协议格式之一，被广泛运用在跨平台的数据交互中，它提升了数据传输过程的时间效率和空间效率，空间效率是JSON的2-5倍，时间效率要高，对于数据大小敏感，传输效率高的模块可以采用protobuf库，同时比明文传输也更加安全，缺点就是消息结构的可读性不高对接首先先在环境中 用npm install protocol-buffers安装上proto对应插件，当然也可以选择别的proto的相关插件功能是一样的，在参数返回客户端的地方加上序列化转换成buffer数据 public after(err: any, msg: any, session: any, resp: any, next: any) &#123; if (afterLogRoute[msg.__route__]) &#123; if (resp.data &amp;&amp; resp.data.user &amp;&amp; resp.data.user.id) &#123; let actor_id &#x3D; resp.data &amp;&amp; resp.data.user.id; this.logRouter(session, msg, actor_id); &#125; &#125; &#x2F;&#x2F; nodejs 使用protocol-buffers 这个库进行编解码的操作 &#x2F;&#x2F; 加载协议文件中的模型 const schema:any &#x3D; protobuf(fs.readFileSync(__dirname + &#39;&#x2F;test.proto&#39;, &#39;utf-8&#39;));&#x2F;&#x2F;测试使用 &#x2F;&#x2F; schema里面有两个函数，一个是编码的函数，一个是解码的函数 &#x2F;&#x2F; encode: [Function: encode] &#123; bytes: 0 &#125;, &#x2F;&#x2F; decode: [Function: decode] &#123; bytes: 0 &#125;, &#x2F;&#x2F; console.log(schema); &#x2F;&#x2F; 输出结果 &#x2F;* Messages &#x3D; &#123; Column: &#123; type: 2, message: true, name: &#39;Column&#39;, buffer: true, encode: [Function: encode] &#123; bytes: 0 &#125;, decode: [Function: decode] &#123; bytes: 0 &#125;, encodingLength: [Function: encodingLength], dependencies: [ [Object], [Object], [Object] ] &#125; &#125; *&#x2F; &#x2F;&#x2F; Using function about package protobuf &#x2F;&#x2F; 将数据根据模型，也就是.proto协议中定义的Column，传入并使用encode函数生成buffer const buffer &#x3D; schema.Column.encode(&#123; id: 1, name: &quot;Node.js&quot;, price: 80.4 &#125;) console.log(buffer); next(err, msg, session, resp); &#125; 其中要新建一个测试用的test.proto的配置文件，内容对应返回的数据格式 message Column &#123; required int32 id &#x3D; 1; required string name &#x3D; 2; required float price &#x3D; 3; &#125; 这里测试用的是fs异步读取的形式，真正使用最好在程序启动时 app.use()调用上插件，在插件中用map记录路由，遍历路由读取配置文件放进内存静态变量在与客户端交互返回的时候直接调用即可客户端读取的时候同样需要用proto进行decode的解码，所以配置文件服务端客户端各一份 protobuf是谷歌的一套消息协议，具体介绍不说了，记录下使用及基本数据结构protobuf的协议一般不会被node直接编译，所以使用中需要将协议文件放入指定文件夹通过命令自动化拷贝到编译好的项目文件下 &quot;scripts&quot;: &#123; &quot;clear&quot;: &quot;rimraf -rf dist types lib coverage .nyc_output&quot;, &quot;make_dir&quot;: &quot;md dist\\\\logs\\\\&quot;, &quot;copy&quot;: &quot;xcopy src\\\\config\\\\*.* dist\\\\config\\\\ &#x2F;e&#x2F;y &amp;&amp; xcopy src\\\\public\\\\*.* dist\\\\public\\\\ &#x2F;e&#x2F;y &amp;&amp; xcopy src\\\\scripts\\\\*.* dist\\\\scripts\\\\ &#x2F;e&#x2F;y &quot;, &quot;start&quot;: &quot;cross-env NODE_ENV&#x3D;development node .&#x2F;dist&#x2F;app.js&quot;, &quot;pomelo_start&quot;: &quot;pomelo start&quot;, &quot;build&quot;: &quot;npm run clear &amp;&amp; npm run make_dir &amp;&amp; npm run copy &amp;&amp; tsc&quot;, &quot;build:ts&quot;: &quot;npm run clear &amp;&amp; npm run make_dir &amp;&amp; npm run copy &amp;&amp; tsc --sourceMap true --removeComments false --outDir dist --declaration --declarationDir dist&#x2F;types&quot;, &quot;test&quot;: &quot;cross-env NODE_ENV&#x3D;development cross-env TEST_MODE&#x3D;true nyc mocha --require ts-node&#x2F;register --exit --reporter spec .&#x2F;**&#x2F;*.spec.ts&quot;, &quot;test:coverage&quot;: &quot;cross-env NODE_ENV&#x3D;development cross-env TEST_MODE&#x3D;true nyc mocha --exit --reporter spec&quot;, &quot;check&quot;: &quot;echo \\&quot;Checking...\\&quot; &amp;&amp; tsc &amp;&amp; npm run tslint&quot;, &quot;tslint&quot;: &quot;tslint -c tslint.json -p tsconfig.json&quot;, &quot;start:ts&quot;: &quot;npm run build:ts &amp;&amp; npm run start&quot; &#125;, 主要用到copy的脚本去拷贝对应目录下的文件夹到编译后的文件中.proto Type Notes C++ Type Java Type Python Type[2] Go Type Ruby Type C# Type PHP Typedouble double double float float64 Float double floatfloat float float float float32 Float float floatint32 使用变长编码，对于负值的效率很低，如果你的域有可能有负值，请使用sint64替代 int32 int int int32 Fixnum 或者 Bignum（根据需要） int integeruint32 使用变长编码 uint32 int int/long uint32 Fixnum 或者 Bignum（根据需要） uint integeruint64 使用变长编码 uint64 long int/long uint64 Bignum ulong integer/stringsint32 使用变长编码，这些编码在负值时比int32高效的多 int32 int int int32 Fixnum 或者 Bignum（根据需要） int integersint64 使用变长编码，有符号的整型值。编码时比通常的int64高效。 int64 long int/long int64 Bignum long integer/stringfixed32 总是4个字节，如果数值总是比总是比228大的话，这个类型会比uint32高效。 uint32 int int uint32 Fixnum 或者 Bignum（根据需要） uint integerfixed64 总是8个字节，如果数值总是比总是比256大的话，这个类型会比uint64高效。 uint64 long int/long uint64 Bignum ulong integer/stringsfixed32 总是4个字节 int32 int int int32 Fixnum 或者 Bignum（根据需要） int integersfixed64 总是8个字节 int64 long int/long int64 Bignum long integer/stringbool bool boolean bool bool TrueClass/FalseClass bool booleanstring 一个字符串必须是UTF-8编码或者7-bit ASCII编码的文本。 string String str/unicode string String (UTF-8) string stringbytes 可能包含任意顺序的字节数据。 string ByteString str []byte String (ASCII-8BIT) ByteString string以上是所有proto3的数据类型，具体的使用根据我们项目中的返回数据结构定义比如简单的{“merge_id”:”xxx”, “page”:1, “size”:500} message getMergeListRequest &#123; string merge_id &#x3D; 1; int32 page &#x3D; 2; int32 size &#x3D; 3; &#125; repeated string works_ids = 5;repeated修饰符是用来修饰数组结构[“1”,”2”,”3”]复杂类型需要嵌套构建如","text":"protobuf作为现在最流行的序列化数据结构的协议格式之一，被广泛运用在跨平台的数据交互中，它提升了数据传输过程的时间效率和空间效率，空间效率是JSON的2-5倍，时间效率要高，对于数据大小敏感，传输效率高的模块可以采用protobuf库，同时比明文传输也更加安全，缺点就是消息结构的可读性不高对接首先先在环境中 用npm install protocol-buffers安装上proto对应插件，当然也可以选择别的proto的相关插件功能是一样的，在参数返回客户端的地方加上序列化转换成buffer数据 public after(err: any, msg: any, session: any, resp: any, next: any) &#123; if (afterLogRoute[msg.__route__]) &#123; if (resp.data &amp;&amp; resp.data.user &amp;&amp; resp.data.user.id) &#123; let actor_id &#x3D; resp.data &amp;&amp; resp.data.user.id; this.logRouter(session, msg, actor_id); &#125; &#125; &#x2F;&#x2F; nodejs 使用protocol-buffers 这个库进行编解码的操作 &#x2F;&#x2F; 加载协议文件中的模型 const schema:any &#x3D; protobuf(fs.readFileSync(__dirname + &#39;&#x2F;test.proto&#39;, &#39;utf-8&#39;));&#x2F;&#x2F;测试使用 &#x2F;&#x2F; schema里面有两个函数，一个是编码的函数，一个是解码的函数 &#x2F;&#x2F; encode: [Function: encode] &#123; bytes: 0 &#125;, &#x2F;&#x2F; decode: [Function: decode] &#123; bytes: 0 &#125;, &#x2F;&#x2F; console.log(schema); &#x2F;&#x2F; 输出结果 &#x2F;* Messages &#x3D; &#123; Column: &#123; type: 2, message: true, name: &#39;Column&#39;, buffer: true, encode: [Function: encode] &#123; bytes: 0 &#125;, decode: [Function: decode] &#123; bytes: 0 &#125;, encodingLength: [Function: encodingLength], dependencies: [ [Object], [Object], [Object] ] &#125; &#125; *&#x2F; &#x2F;&#x2F; Using function about package protobuf &#x2F;&#x2F; 将数据根据模型，也就是.proto协议中定义的Column，传入并使用encode函数生成buffer const buffer &#x3D; schema.Column.encode(&#123; id: 1, name: &quot;Node.js&quot;, price: 80.4 &#125;) console.log(buffer); next(err, msg, session, resp); &#125; 其中要新建一个测试用的test.proto的配置文件，内容对应返回的数据格式 message Column &#123; required int32 id &#x3D; 1; required string name &#x3D; 2; required float price &#x3D; 3; &#125; 这里测试用的是fs异步读取的形式，真正使用最好在程序启动时 app.use()调用上插件，在插件中用map记录路由，遍历路由读取配置文件放进内存静态变量在与客户端交互返回的时候直接调用即可客户端读取的时候同样需要用proto进行decode的解码，所以配置文件服务端客户端各一份 protobuf是谷歌的一套消息协议，具体介绍不说了，记录下使用及基本数据结构protobuf的协议一般不会被node直接编译，所以使用中需要将协议文件放入指定文件夹通过命令自动化拷贝到编译好的项目文件下 &quot;scripts&quot;: &#123; &quot;clear&quot;: &quot;rimraf -rf dist types lib coverage .nyc_output&quot;, &quot;make_dir&quot;: &quot;md dist\\\\logs\\\\&quot;, &quot;copy&quot;: &quot;xcopy src\\\\config\\\\*.* dist\\\\config\\\\ &#x2F;e&#x2F;y &amp;&amp; xcopy src\\\\public\\\\*.* dist\\\\public\\\\ &#x2F;e&#x2F;y &amp;&amp; xcopy src\\\\scripts\\\\*.* dist\\\\scripts\\\\ &#x2F;e&#x2F;y &quot;, &quot;start&quot;: &quot;cross-env NODE_ENV&#x3D;development node .&#x2F;dist&#x2F;app.js&quot;, &quot;pomelo_start&quot;: &quot;pomelo start&quot;, &quot;build&quot;: &quot;npm run clear &amp;&amp; npm run make_dir &amp;&amp; npm run copy &amp;&amp; tsc&quot;, &quot;build:ts&quot;: &quot;npm run clear &amp;&amp; npm run make_dir &amp;&amp; npm run copy &amp;&amp; tsc --sourceMap true --removeComments false --outDir dist --declaration --declarationDir dist&#x2F;types&quot;, &quot;test&quot;: &quot;cross-env NODE_ENV&#x3D;development cross-env TEST_MODE&#x3D;true nyc mocha --require ts-node&#x2F;register --exit --reporter spec .&#x2F;**&#x2F;*.spec.ts&quot;, &quot;test:coverage&quot;: &quot;cross-env NODE_ENV&#x3D;development cross-env TEST_MODE&#x3D;true nyc mocha --exit --reporter spec&quot;, &quot;check&quot;: &quot;echo \\&quot;Checking...\\&quot; &amp;&amp; tsc &amp;&amp; npm run tslint&quot;, &quot;tslint&quot;: &quot;tslint -c tslint.json -p tsconfig.json&quot;, &quot;start:ts&quot;: &quot;npm run build:ts &amp;&amp; npm run start&quot; &#125;, 主要用到copy的脚本去拷贝对应目录下的文件夹到编译后的文件中.proto Type Notes C++ Type Java Type Python Type[2] Go Type Ruby Type C# Type PHP Typedouble double double float float64 Float double floatfloat float float float float32 Float float floatint32 使用变长编码，对于负值的效率很低，如果你的域有可能有负值，请使用sint64替代 int32 int int int32 Fixnum 或者 Bignum（根据需要） int integeruint32 使用变长编码 uint32 int int/long uint32 Fixnum 或者 Bignum（根据需要） uint integeruint64 使用变长编码 uint64 long int/long uint64 Bignum ulong integer/stringsint32 使用变长编码，这些编码在负值时比int32高效的多 int32 int int int32 Fixnum 或者 Bignum（根据需要） int integersint64 使用变长编码，有符号的整型值。编码时比通常的int64高效。 int64 long int/long int64 Bignum long integer/stringfixed32 总是4个字节，如果数值总是比总是比228大的话，这个类型会比uint32高效。 uint32 int int uint32 Fixnum 或者 Bignum（根据需要） uint integerfixed64 总是8个字节，如果数值总是比总是比256大的话，这个类型会比uint64高效。 uint64 long int/long uint64 Bignum ulong integer/stringsfixed32 总是4个字节 int32 int int int32 Fixnum 或者 Bignum（根据需要） int integersfixed64 总是8个字节 int64 long int/long int64 Bignum long integer/stringbool bool boolean bool bool TrueClass/FalseClass bool booleanstring 一个字符串必须是UTF-8编码或者7-bit ASCII编码的文本。 string String str/unicode string String (UTF-8) string stringbytes 可能包含任意顺序的字节数据。 string ByteString str []byte String (ASCII-8BIT) ByteString string以上是所有proto3的数据类型，具体的使用根据我们项目中的返回数据结构定义比如简单的{“merge_id”:”xxx”, “page”:1, “size”:500} message getMergeListRequest &#123; string merge_id &#x3D; 1; int32 page &#x3D; 2; int32 size &#x3D; 3; &#125; repeated string works_ids = 5;repeated修饰符是用来修饰数组结构[“1”,”2”,”3”]复杂类型需要嵌套构建如 message getDoingMergeReply &#123; repeated MergeInfo merge_info &#x3D; 1; &#125; message MergeInfo &#123; string id &#x3D; 1; string merge_title &#x3D; 2; string icon &#x3D; 3; string icon_colour &#x3D; 4; map&lt;string, list&gt; relevance_topic &#x3D; 5; &#125; message list &#123; repeated string ids &#x3D; 1; &#125; 这是一个map嵌套数组的多层结构 &#123; merge_info: [ &#123; relevance_topic: &#123;&quot;1&quot;:[&quot;asdd&quot;,&quot;ddddd&quot;,&quot;xxxx&quot;]&#125;, id: &#39;61df9b30ec9fea39c8fe7f97&#39;, merge_title: &#39;合辑-6&#39;, icon: &#39;&#39;, icon_colour: &#39;#96c23b&#39; &#125;, &#123; relevance_topic:&#123;&quot;1&quot;:[&quot;asdd&quot;,&quot;ddddd&quot;,&quot;xxxx&quot;]&#125;, id: &#39;61df9b22ec9fea39c8fe7f96&#39;, merge_title: &#39;合辑-5&#39;, icon: &#39;&#39;, icon_colour: &#39;#96c23b&#39; &#125;] &#125; #还有枚举类型比较常用在错误码上 enum Corpus &#123; UNIVERSAL &#x3D; 0; WEB &#x3D; 1; IMAGES &#x3D; 2; LOCAL &#x3D; 3; NEWS &#x3D; 4; PRODUCTS &#x3D; 5; VIDEO &#x3D; 6; &#125; #同时如果想要在proto中让远程grpc调用，可以定义为 service Route &#123; &#x2F;&#x2F; Sends a greeting rpc getDoingMerge (getDoingMergeRequest) returns (getDoingMergeReply) &#123;&#125; &#x2F;&#x2F; Sends another greeting rpc getGrpcMergeList (getMergeListRequest) returns (getMergeListReply) &#123;&#125; &#125;","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://zxtotti17.github.io/tags/node-js/"}]},{"title":"服务端的安全预警","slug":"服务端的安全预警","date":"2022-09-07T11:02:15.000Z","updated":"2022-09-09T08:23:45.049Z","comments":true,"path":"/post/服务端的安全预警.html","link":"","permalink":"http://zxtotti17.github.io/post/%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%9A%84%E5%AE%89%E5%85%A8%E9%A2%84%E8%AD%A6.html","excerpt":"","text":"通常在服务端会为了防止攻击会设置安全限制，及有人攻击的时候及时预警通知自己，能在最短时间内封了不法分子的账号或者ip达人秀中采用的预警是预警登录及获取魔域区服的接口解决方案：1、每日登录时切换区服查【主角色接口】达2次以上出现验证码，切换区服达6次发出预警；2、每日登录时切换区服查【主角色接口】，当IP查询50次以上发出预警；注：不切换区服查主角色接口（查已选择的区服）不限制，因为我们有4小时的主角色信息缓存；3、同个账号每日访【区服列表】接口50次限制，发出预警；4、同IP每日访问【区服列表】接口200次限制，发出预警；5、以上4个事件预警发出后，5分钟内不在发送，避免消息轰炸； 预警模板内容： 渠道ID, 账号id、大区ID，子服ID， IP, 触发事件类型（上面3种） private async addNumLimitLog(game_id:number, area_id:number, ip:string, real_ip:string)&#123; logger.warn(&quot;get_sub_server ip:%s&quot;, ip); if(!ip || !real_ip) return false; let areaUrlConfig &#x3D; pomelo.app.get(&#39;areaUrlConfig&#39;); let conf &#x3D; Array.isArray(areaUrlConfig) ? areaUrlConfig[0] : areaUrlConfig; let playerLimit &#x3D; conf.commonLimit || 50; let ipLimit &#x3D; conf.ipLimit || 200; let ipWhiteList &#x3D; conf.ipWhiteList || []; if(ipWhiteList.indexOf(ip) &gt;&#x3D; 0 ) &#123; return false; &#125; if(real_ip &amp;&amp; real_ip.length &gt; 200)&#123; real_ip &#x3D; real_ip.slice(0,200); &#125; let playerNum &#x3D; await AreaServerInfoRepository.getInstance().addNumLimit(game_id, area_id, this.player_id || &#39;&#39;); let notice &#x3D; pomelo.app.get(&#39;noticeService&#39;); let confNotice &#x3D; pomelo.app.get(&#39;watchdogMqConfig&#39;); let content: string &#x3D; confNotice.noticeLoginStr + this.platform_id + &quot; player_id: &quot; + this.player_id + &quot; area_id: &quot; + area_id + &quot; ip: &quot; + ip; let userIds &#x3D; conf.noticeMqUserIds; const areaIp200 &#x3D; &quot;areaIp200&quot;; const areaAccount50 &#x3D; &quot;areaAccount50&quot;; if(playerNum &gt; playerLimit)&#123; logger.error(&quot;player limit game_id:%s area_id:%s playerId:%s&quot;, game_id, area_id, this.player_id); content +&#x3D; &quot; event: &quot; + areaAccount50; for (let i &#x3D; 0; i &lt; userIds.length; i++) &#123; let id &#x3D; userIds[i]; await notice.sendUserLimitTime(id, content, areaAccount50); &#125; await AreaServerInfoRepository.getInstance().addClickLimitLog(1, game_id, area_id, this.player_id, ip, real_ip); return Msg.OVER_AREA_LIMIT; &#125; let ipNum &#x3D; await AreaServerInfoRepository.getInstance().addIpNumLimit(ip); if(ipNum &gt; ipLimit)&#123; logger.error(&quot;ip limit game_id:%s area_id:%s playerId:%s ip:%s&quot;, game_id, area_id, this.player_id, ip); content +&#x3D; &quot; event: &quot; + areaAccount50; for (let i &#x3D; 0; i &lt; userIds.length; i++) &#123; let id &#x3D; userIds[i]; await notice.sendUserLimitTime(id, content, areaIp200); &#125; await AreaServerInfoRepository.getInstance().addClickLimitLog(2, game_id, area_id, this.player_id, ip, real_ip); return Msg.OVER_AREA_LIMIT; &#125; return true; &#125; 在登录的部分加上ip及验证码使用过多的预警 else if (rows &amp;&amp; rows.length) &#123; let ipNum &#x3D; await this.addIpLimit(info.ip); let notice &#x3D; this.app.get(&#39;noticeService&#39;); let confNotice &#x3D; this.app.get(&#39;watchdogMqConfig&#39;); let content: string &#x3D; confNotice.noticeLoginStr + platformId + &quot; player_id: &quot; + info.player_id + &quot; area_id: &quot; + info.area_id + &quot; server_id: &quot; + info.server_id + &quot; ip: &quot; + info.ip; let userIds &#x3D; conf.noticeMqUserIds; const code6 &#x3D; &quot;code6&quot;; const loginIp50 &#x3D; &quot;loginIp50&quot;; if(ipNum &gt;&#x3D; 50)&#123; content +&#x3D; &quot; event: &quot; + loginIp50; for (let i &#x3D; 0; i &lt; userIds.length; i++) &#123; let id &#x3D; userIds[i]; await notice.sendUserLimitTime(id, content, loginIp50); &#125; &#125; if(rows[0].num &gt; max)&#123; await this.addUserLimit(route, userCode, platformId, rows[0].num); return 2; &#125;else if(rows[0].num &lt; begin || rows[0].code &#x3D;&#x3D; text.toLowerCase())&#123; rows[0].num++; if(await this.addCache(rows[0], storage))&#123; return 1; &#125; &#125; else if(rows[0].num &gt;&#x3D; 6)&#123; content +&#x3D; &quot; event: &quot; + code6; for (let i &#x3D; 0; i &lt; userIds.length; i++) &#123; let id &#x3D; userIds[i]; await notice.sendUserLimitTime(id, content, code6); &#125; &#125; 预警的通知限制时间，通过api网络接口发给99u及时通知 public async sendUserLimitTime(userId: string, content: string, event:string): Promise&lt;any&gt; &#123; let conf &#x3D; this.app.get(&#39;noticeConfig&#39;); let url &#x3D; conf.api_chat; let time &#x3D; Math.floor(new Date().getTime() &#x2F; 1000); if(!time || time &lt; this.limitTime[event] + 300)&#123;&#x2F;&#x2F;5分钟 return &#125; this.limitTime[event] &#x3D; time; &#x2F;&#x2F; 群发格式 let postArgs &#x3D; &#123; login_name : userId, type : &quot;text&quot;, content : content &#125;; let options: RequestInit &#x3D; &#123; method: &quot;POST&quot;, headers: &#123; &quot;Content-Type&quot;: &quot;application&#x2F;json&quot;, &quot;Authorization&quot;: &#96;APP appid&#x3D;4f7933e627ccbbd3,token&#x3D;757c8c2552374cfa42862435da00384e&#96; &#125; &#125;; options.body &#x3D; JSON.stringify(postArgs) let response &#x3D; await fetch(url, options); let data &#x3D; await response.json(); return data; &#125;","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"安全","slug":"安全","permalink":"http://zxtotti17.github.io/tags/%E5%AE%89%E5%85%A8/"}]},{"title":"Redis原子性应用","slug":"redis原子性应用","date":"2022-09-07T10:56:32.000Z","updated":"2022-09-09T08:22:57.984Z","comments":true,"path":"/post/redis原子性应用.html","link":"","permalink":"http://zxtotti17.github.io/post/redis%E5%8E%9F%E5%AD%90%E6%80%A7%E5%BA%94%E7%94%A8.html","excerpt":"","text":"服务端中有时候总是会因为一些业务逻辑的不够严谨及并发条件下判断不足导致数据中出现脏数据或者累加的情况下出现数值不一致的情况（不是必现，是偶尔会产生）为了避免以上情况的发生我们通常会采用的方法1.数据库加事务处理，最大程度上保证数据的一致性，但是并发的情况下还是有可能出现脏数据2.通过数据库本身的约束条件，主键约束 ， 唯一索引等约束数据的一致性，能保证脏数据不产生，但是累加的更新在业务层上的锁定无法保证3.通过业务层加锁来保证并发情况下更新累加数据的一致性，如redis分布式锁，或者不做累加只用赋值，通过再次查询一遍数据库值做加法后赋值，这样并发的情况下只会重复更新不会累加多值前2种不说，着重说第3种，redis是单进程的，redis分布式锁就是用到某些语句的原子性特点，保证当前执行锁住只会执行一次如incr命令阅读数场景原先使用get key命令获取缓存参数在set 更新，但是这个命令是非原子性，累加并发的情况就会出现多次累加原先的做法只是load，加分布式锁后在load前后用incr加上key ,在取会数值时候释放incr锁住的key值，这是比较好的做法最好好是用lua脚本实现redis锁 public async getOrAdd(databaseId: string, table: string, rowKey: string, rows: any, opts?: any): Promise&lt;any&gt; &#123; let lockKey &#x3D; &#96;$&#123;rowKey&#125;:__lock__&#96;; let flag &#x3D; opts.queryFlag; let redisDb: Database &#x3D; this.service.connect(databaseId); let lockState &#x3D; await this.incrby(databaseId, lockKey, 1); &#x2F;&#x2F;锁定原子并发 if (lockState !&#x3D;&#x3D; 1) &#123; return &#123; error: &#96;table:$&#123;table&#125; key:$&#123;rowKey&#125; has be locked($&#123;lockState&#125;) of get or add options.&#96; &#125;; &#125; &#x2F;&#x2F;最多锁定1分钟,自动解除锁定 await redisDb.removeAsync(this.getRowKey(lockKey), &#123; mode: CommandMode.Key, expired: utils.nowSecond() + 60 &#125;, flag); let loadRows &#x3D; await this.load(databaseId, table, rowKey, opts); if (!loadRows || (Array.isArray(loadRows) &amp;&amp; loadRows.length &#x3D;&#x3D;&#x3D; 0)) &#123; &#x2F;&#x2F;数据不存在时增加 await this.update(databaseId, table, rowKey, rows, opts); await redisDb.removeAsync(this.getRowKey(lockKey), &#123; mode: CommandMode.Key, expired: 0 &#125;, flag); return &#123; created: true, data: (Array.isArray(rows) ? rows : [rows]) &#125;; &#125; await redisDb.removeAsync(this.getRowKey(lockKey), &#123; mode: CommandMode.Key, expired: 0 &#125;, flag); return &#123; created: false, data: loadRows &#125;; &#125; 这时候后面在clickData[‘click_num’] += click_num;累加的时候就不会因为并发出现累加多次的情况 let ret: any &#x3D; await this.getOrAddDailyClick(works_id, create_time, clickData, storage); if (ret.error) &#123; logger.error(&quot;addDailyClicks error:%s works_id:%s create_time:%s&quot;, ret.error, works_id, create_time); return false; &#125; else if (ret.created) &#123; msg +&#x3D; &#96; created.&#96;; this.execSync(&#39;clickSync.add&#39;, clickData); &#125; else &#123; clickData &#x3D; ret.data[0]; msg +&#x3D; &#96; before_num:$&#123;clickData.click_num&#125;&#96;; if (clickData &amp;&amp; clickData[&#39;owner_actor&#39;] !&#x3D; owner_actor) &#123; clickData[&#39;owner_actor&#39;] &#x3D; owner_actor; &#125; clickData[&#39;all_click_num&#39;] &#x3D; all_click_num; clickData[&#39;click_num&#39;] +&#x3D; click_num; clickData[&#39;update_time&#39;] &#x3D; Math.floor(Date.now() &#x2F; 1000); msg +&#x3D; &#96; after_num:$&#123;clickData.click_num&#125;&#96;; if (await this.addDailyClick(clickData, create_time, storage)) &#123; this.execSync(&#39;clickSync.update&#39;, clickData); &#125; else return false; &#125; 还有一种方法就是牺牲性能做校验，用赋值的方式不做累加，checkRedNum校验真实的数据后替换在累加 let redCache &#x3D; await redDotsRepository.getInstance().getCharacter(actor_id, &#39;&#39;); if(redCache &amp;&amp; redCache[type] &gt;&#x3D; 0)&#123; redCache[type] &#x3D; await redDotsRepository.getInstance().checkRedNum(actor_id); redCache[type] &#x3D; redCache[type] + num &gt;&#x3D; 0 ? redCache[type] + num : 0; return await redDotsRepository.getInstance().update(actor_id, redCache, type, redWorks); &#125;","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://zxtotti17.github.io/tags/redis/"}]},{"title":"Mysql的一些不常用的规则","slug":"mysql的一些不常用的规则","date":"2021-11-24T08:59:23.000Z","updated":"2023-04-10T01:47:07.540Z","comments":true,"path":"/post/mysql的一些不常用的规则.html","link":"","permalink":"http://zxtotti17.github.io/post/mysql%E7%9A%84%E4%B8%80%E4%BA%9B%E4%B8%8D%E5%B8%B8%E7%94%A8%E7%9A%84%E8%A7%84%E5%88%99.html","excerpt":"","text":"mysql的全文索引主要用在用户搜索查询，达人秀中应用是用来匹配作品内容及标题全文搜索 传统的匹配方式是like “%xxx%”但这样效率是很低的，在mysql 5.7版本之后提供了inodb的全文索引方式，用的是分词的形式 达人秀中用户主要用的是中文查找内容，但是在标题和内容中存在网页html css等标签及无关的标点符号会影响搜索的速度，同时mysql全文索引只支持 char varchar text三种数据类型 那么当出现较多文字的同时就需要缩减文字精炼存储，在用专门的字段存储查询 ALTER TABLE `works` ADD COLUMN `search_content` text CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT &#39;&#39; COMMENT &#39;搜索文本&#39; AFTER `rich_content`; ALTER TABLE `works` add fulltext index `title_search_content` (`title`, `search_content`) WITH PARSER ngram; 先给对应的表结构加上字段及全文索引，包含标题及内容，采用分词的形式 在作品添加及更新的时候用正则表达式匹配字符串中文精炼字符串长度保证text的长度能放下，同时过滤只存在中文去掉其他 public getSearchContent(content:string, rich_content:string) { let str = matchChinses(content) + matchChinses(rich_content); if(str.length &gt; 16382){//中文按4个字节来算 return str.slice(0,16382); } return str; } /** * 正则匹配中文 */ export function matchChinses(content: string): any { if (content !== null &amp;&amp; content !== &#39;&#39;) { const reg = /[\\u4e00-\\u9fa5]/g; return content.match(reg).join(&#39;&#39;); } return &#39;&#39;; } 这样就能保证存储数据准确性又不太影响搜索的准确性及时效性 对于之前发布的作品采用脚本的形式一次性做匹配更新操作，定到凌晨3点跑一次做同步，避免死循环加上超时机制 public async syncUpdateSearchContent(): Promise&lt;any&gt; { setTimeout(async () =&gt;{ let page = 1; while(1){ if(await this.worksService.updateSearchContent(page)){ page++; }else{ break; } } return }, 60*5); } public async updateSearchContent(page:number) { let repo = WorksRepository.getInstance(); let ids = await repo.getNeedSearchContent(page);//取数据 if(!ids || !ids.length) return false; let data = await repo.getIdsWorksData(ids); for(let i = 0; i &lt; data.length; i++){ let worksData:Works = data[i]; worksData.search_content = this.getSearchContent(worksData.content,worksData.rich_content); let editor = this.getEditor(worksData); await this.setCharacter(worksData, editor); } return true; } 如果是mysql 8.0以上版本可以用REGEXP_REPLACE的方法直接在sql中匹配替换更新 有些不常被使用的mysql语法 1.union 和 union all、 Intersect 这些sql语法主要用在当我们需要查询多表数据同时需要使用多表不同字段数据的时候用这个语句避免多次连接数据库查询如：SELECT ANY_VALUE(t.works_id) AS works_id, ANY_VALUE(SUM(t.score)) AS score FROM (SELECT ANY_VALUE(works_id) AS works_id, ANY_VALUE(SUM(click_num)) AS score FROM view_click WHERE works_id = ? AND create_time &lt;= ? GROUP BY works_id UNION ALL SELECT ANY_VALUE(works_id) AS works_id, ANY_VALUE(COUNT(id) * 30) AS score FROM log_first_like WHERE works_id = ? AND create_time &lt;= ? GROUP BY works_id 同时union 与 union all的区别在与 当连接查询的表有同样字段的时候union all中对两个结果集进行并集操作，包括重复行，不进行排序， union则会对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序， Intersect：对两个结果集进行交集操作，不包括重复行，同时进行默认规则的排序 2.2.视图View 视图就是SELECT语句执行后返回的结果集，比如当我们需要用新表的替换旧表，但需要重旧表中获取数据，可以用视图 view，将两个结果集合并视图，在查询视图，但是视图肯定不会那么高效的，所以尽量少用如： CREATE VIEW view_click AS SELECT * FROM click UNION ALL SELECT * FROM log_click 后续当我要按时间查找新旧表数据的时候就可以直接select * from view_click where … 查找视图来查找新旧数据 2.3.ON DUPLICATE KEY UPDATE 这个是专门使用在插入语句中，在并发的情况的下有可能会导致业务数据判断错误，引起插入语句违反数据库限制，如主键唯一 或者 唯一索引限制引起报错，但实际上索要做的是更新对应业务数据的值就可以使用ON DUPLICATE KEY UPDATE在插入语句中去替换因为限制条件下的数据，需要注意的限制条件在插入语句中要去掉，如id做主键就需要在更新后面去掉id，唯一索引也是同理如： INSERT INTO table (a,b,c) VALUES (1,2,3) ON DUPLICATE KEY UPDATE c=c+1; a为主键，b为唯一索引那么update语句中就不要带这两个字段 但是这个语法容易导致死锁所以使用上要格外小心 ``` bashselect * from user where id = 1 lock in share mode #加S锁，也称读锁，共享锁，可以事务重复添加S锁，但不能添加X锁，必须释放后才可以update user set username=’javaboy’ where id=1; #会先读取X锁，也称写锁 排他锁，写锁会阻塞直到完成","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://zxtotti17.github.io/tags/mysql/"}]},{"title":"作品合集-多对多对多关系表","slug":"moyu_worksMerge","date":"2021-07-27T07:38:58.000Z","updated":"2022-09-13T07:07:38.086Z","comments":true,"path":"/post/moyu_worksMerge.html","link":"","permalink":"http://zxtotti17.github.io/post/moyu_worksMerge.html","excerpt":"作品合集的背景是在原有话题上加入标签，让话题和标签有多对多的关系即 A-&gt;B，新的合集表C是由标签B合并成合集也是多对多关系即 B-&gt;C, 同时对于用户来说，用户只关心对应的话题，对应话题条件加入合集即 A-&gt;C,传统的多对多关系一般是建立中间关联表用作中转的关联（传统的关系表中A-B关系就分出一个A-B的各主键关联关系表，B-C和C-A也是一样，但是这时候如果改动一个A上的B属性，就需要改动复杂的关联关系这是必然的，所要改动的表数据可能就是5个，复杂。在表含量较小的情况下时，我们将关系存储于原始表字段，用数组或者map的形式做关系的关联能大大降低关系表的复杂性及查询次数。数据量大的情况下用mangodb的map存储会有更好的效果），但是这样的一般是在多对多一种关系中，在多种关系下就会显得臃肿复杂，所以分析情景细节后，将标签表做B-&gt;A的关联，将合集表做C-&gt;A， C-&gt;B的关联同时对用户发布需要判断话题对应合集的情况，将使用中的合集重要信息缓存一张新的缓存表，以下是标签表 !bq 可以看到标签对应的话题已经做了关联，以下是合集表!hj 合集表中关联了标签及对应标签所有相关不重复的话题，重点就是将对应关系一一梳理对应存储，更改合集中的标签的时候，通过对标签与原数据不同的拆解分出添加和删除的标签，从中获取对应涉及的话题，去重合并更新缓存及数据库和用于给用户的使用的缓存表中的关系字段 &#x2F;&#x2F;管理更改的标签 public async manageTagMerge(mergeData:WorksMerge, tag_map:any): Promise&lt;string&gt;&#123; let result &#x3D; mergeData.relevance_topic; if(mergeData.topic_tag !&#x3D; JSON.stringify(tag_map))&#123; let mergeTopicList &#x3D; await this.getMergeTagTopic(tag_map); result &#x3D; JSON.stringify(mergeTopicList); &#125; return result; &#125;","text":"作品合集的背景是在原有话题上加入标签，让话题和标签有多对多的关系即 A-&gt;B，新的合集表C是由标签B合并成合集也是多对多关系即 B-&gt;C, 同时对于用户来说，用户只关心对应的话题，对应话题条件加入合集即 A-&gt;C,传统的多对多关系一般是建立中间关联表用作中转的关联（传统的关系表中A-B关系就分出一个A-B的各主键关联关系表，B-C和C-A也是一样，但是这时候如果改动一个A上的B属性，就需要改动复杂的关联关系这是必然的，所要改动的表数据可能就是5个，复杂。在表含量较小的情况下时，我们将关系存储于原始表字段，用数组或者map的形式做关系的关联能大大降低关系表的复杂性及查询次数。数据量大的情况下用mangodb的map存储会有更好的效果），但是这样的一般是在多对多一种关系中，在多种关系下就会显得臃肿复杂，所以分析情景细节后，将标签表做B-&gt;A的关联，将合集表做C-&gt;A， C-&gt;B的关联同时对用户发布需要判断话题对应合集的情况，将使用中的合集重要信息缓存一张新的缓存表，以下是标签表 !bq 可以看到标签对应的话题已经做了关联，以下是合集表!hj 合集表中关联了标签及对应标签所有相关不重复的话题，重点就是将对应关系一一梳理对应存储，更改合集中的标签的时候，通过对标签与原数据不同的拆解分出添加和删除的标签，从中获取对应涉及的话题，去重合并更新缓存及数据库和用于给用户的使用的缓存表中的关系字段 &#x2F;&#x2F;管理更改的标签 public async manageTagMerge(mergeData:WorksMerge, tag_map:any): Promise&lt;string&gt;&#123; let result &#x3D; mergeData.relevance_topic; if(mergeData.topic_tag !&#x3D; JSON.stringify(tag_map))&#123; let mergeTopicList &#x3D; await this.getMergeTagTopic(tag_map); result &#x3D; JSON.stringify(mergeTopicList); &#125; return result; &#125; 当更改或者添加话题标签时，同样也是分出添加和删除的标签，从标签中获取对应的联系的合集，取出合集管理的话题，在对关联话题进行修改达到去掉标签后的关联效果，同时修改标签表中关联的话题属性，将改完去重后完整数据更新缓存及数据库，同时更新用于用户部分的缓存数据 public async manageTagTopic(old_tag:string, tag_map:any, topic_id:string): Promise&lt;any&gt; &#123; if(old_tag &#x3D;&#x3D; JSON.stringify(tag_map)) return true; let oldTagMap &#x3D; JSON.parse(old_tag); let newMap &#x3D; tag_map[&#39;0&#39;] || []; let newAddMap &#x3D; await this.addNewTopicTag(topic_id, newMap); if(!newAddMap)&#123; logger.error(&#39;manageTagTopic new error, topic_id:%s &#39;,topic_id); return false; &#125; let addMap &#x3D; this.getAddMap(oldTagMap, tag_map); if(!await this.addTagTopic(addMap, topic_id))&#123; logger.error(&#39;manageTagTopic add error, topic_id:%s &#39;,topic_id); return false; &#125; let deleteMap &#x3D; this.getDeleteMap(oldTagMap, tag_map); if(!await this.deleteTagTopic(deleteMap, topic_id))&#123; logger.error(&#39;manageTagTopic delete error, topic_id:%s &#39;,topic_id); return false; &#125; let result &#x3D; tag_map; if(typeof newAddMap &#x3D;&#x3D; &quot;object&quot;)&#123; delete result[0]; for(let k in newAddMap)&#123; result[k] &#x3D; newAddMap[k]; &#125; &#125; return result; &#125; &#x2F;** * 删除已有话题标签 *&#x2F; public async deleteTagTopic (tag_map:any, topic_id:string): Promise&lt;any&gt; &#123; if(JSON.stringify(tag_map) &#x3D;&#x3D; &quot;&#123;&#125;&quot;) return true; for(let k in tag_map)&#123; let tagList &#x3D; await TopicTagRepository.getInstance().getCharacter(k); let tagData &#x3D; tagList[0]; if(!tagData)&#123; continue; &#125; let topicArr &#x3D; JSON.parse(tagData.relevance_topic); if(topicArr &amp;&amp; topicArr.length &amp;&amp; topicArr.indexOf(topic_id) &gt;&#x3D; 0)&#123; let index &#x3D; topicArr.indexOf(topic_id); topicArr.splice(index, 1); tagData.relevance_topic &#x3D; JSON.stringify(topicArr); if(await TopicTagRepository.getInstance().setCharacter(tagData))&#123;&#x2F;&#x2F;更新合集作品关联 let rows &#x3D; await WorksMergeRepository.getInstance().getMergeTagIds(k); for(let j &#x3D; 0; j &lt; rows.length; j++)&#123; let mergeOne &#x3D; rows[j]; let rt &#x3D; JSON.parse(mergeOne.relevance_topic); if(rt &amp;&amp; rt.length &amp;&amp; rt.indexOf(topic_id) &gt;&#x3D; 0)&#123; rt.splice(index, 1); mergeOne.relevance_topic &#x3D; JSON.stringify(rt); await WorksMergeRepository.getInstance().setMergeTopic(mergeOne); &#125; &#125; &#125; &#125; &#125; return true; &#125; &#x2F;** * 添加已有标签 *&#x2F; public async addTagTopic (tag_map:any, topic_id:string): Promise&lt;boolean&gt; &#123; if(JSON.stringify(tag_map) &#x3D;&#x3D; &quot;&#123;&#125;&quot;) return true; for(let k in tag_map)&#123; let tagList &#x3D; await TopicTagRepository.getInstance().getCharacter(k); let tagData &#x3D; tagList[0]; if(!tagData)&#123; tagData &#x3D; await this.addNewTopicOneTag(topic_id, tag_map[k]); &#125; let topicArr &#x3D; JSON.parse(tagData.relevance_topic); if(topicArr &amp;&amp; topicArr.indexOf(topic_id) &lt; 0)&#123; topicArr.push(topic_id); tagData.relevance_topic &#x3D; JSON.stringify(topicArr); if(await TopicTagRepository.getInstance().setCharacter(tagData))&#123;&#x2F;&#x2F;更新合集作品关联 let rows &#x3D; await WorksMergeRepository.getInstance().getMergeTagIds(k); for(let j &#x3D; 0; j &lt; rows.length; j++)&#123; let mergeOne &#x3D; rows[j]; let rt &#x3D; JSON.parse(mergeOne.relevance_topic); if(rt &amp;&amp; rt.length &amp;&amp; rt.indexOf(topic_id) &lt; 0)&#123; rt.push(topic_id); mergeOne.relevance_topic &#x3D; JSON.stringify(rt); await WorksMergeRepository.getInstance().setMergeTopic(mergeOne); &#125; &#125; &#125; &#125; &#125; return true; &#125; 这样就将所有的关系都拆解串联了起来，达到统一。 用户提交作品的时候获取缓存中正在使用中的话题，遍历判断下条件分配对应话题下即可 public static async addWorksMerge(works_id:string, owner_id:string, identity_id:string, file_type:number, topic_list:string):Promise&lt;any&gt;&#123; let fileType &#x3D; &quot;&quot; + file_type; let userMap &#x3D; await WorksMergeRepository.getInstance().getMergeMap(); let mergeList &#x3D; await WorksMergePoolRepository.getInstance().getWorkIdMerge(works_id); for(let k in userMap)&#123; if(userMap[k].identity_id &#x3D;&#x3D; identity_id &amp;&amp; userMap[k].file_type.indexOf(fileType) &gt;&#x3D;0 &amp;&amp; topic_list &#x3D;&#x3D; userMap[k].relevance_topic &amp;&amp; mergeList.indexOf(k) &lt; 0)&#123; let opts &#x3D; &#123; merge_id:k, works_id:works_id, owner_id:owner_id, file_type:fileType, identity:identity_id, topic_tag:userMap.topic_tag, relevance_topic:userMap.relevance_topic &#125; WorksMergePoolRepository.getInstance().addCharacter(opts); &#125; &#125; &#125; 合集部分通过对话题标签取交集来获取当前合集下话题的关联 &#x2F;&#x2F;取交集 public getMergeWorksTopic(mergeData:WorksMerge)&#123; let rtMap &#x3D; typeof mergeData.relevance_topic &#x3D;&#x3D; &quot;string&quot; ? JSON.parse(mergeData.relevance_topic) : mergeData.relevance_topic; let fileStr &#x3D; typeof mergeData.file_type &#x3D;&#x3D; &quot;string&quot; ? mergeData.file_type.split(&#39;,&#39;) : []; let fileNum &#x3D; []; for(let l &#x3D; 0; l &lt; fileStr.length; l++)&#123; let str &#x3D; fileStr[l]; if(isNaN(Number(str)))continue; fileNum.push(Number(str)); &#125; let result:any &#x3D; &#123;&quot;merge_id&quot;:mergeData.id, &quot;topic_list&quot;:[], &quot;file_type&quot;:fileNum, &quot;identity_id&quot;:mergeData.identity, &quot;limit&quot;:1, &quot;is_good&quot;:mergeData.is_good&#125;; let topic_list:any[] &#x3D; []; let temp_list:any[] &#x3D; []; for(let k in rtMap)&#123; if(Array.isArray(rtMap[k])) topic_list.push(rtMap[k]); &#125; if(!topic_list.length)result.limit &#x3D; 0;&#x2F;&#x2F;无限制 temp_list &#x3D; topic_list.shift(); for(let i &#x3D; topic_list.length; i-- ;)&#123; let p:any &#x3D; &#123;&#125;, obj:any &#x3D; []; temp_list &#x3D; temp_list.concat(topic_list[i]).filter(function (x: string) &#123; return !((x in p) ? !p[x] &amp;&amp; (p[x] &#x3D; 1) : obj.indexOf(x) &lt; 0 &amp;&amp; obj.push(x)); &#125;); if(!temp_list.length) &#123; result.topic_list &#x3D; []; return result; &#125; &#125; result.topic_list &#x3D; temp_list; &#x2F;&#x2F; logger.error(&#39;topic_list:&#39;, result.topic_list); return result; &#125;","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://zxtotti17.github.io/tags/mysql/"}]},{"title":"node.js中常用的函数","slug":"node-js中常用的函数","date":"2021-07-07T06:33:31.000Z","updated":"2022-09-09T08:00:09.271Z","comments":true,"path":"/post/node-js中常用的函数.html","link":"","permalink":"http://zxtotti17.github.io/post/node-js%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E5%87%BD%E6%95%B0.html","excerpt":"http部分 import fetch from &quot;node-fetch&quot;; import &#123; RequestInit &#125; from &quot;node-fetch&quot;; import &#123; URLSearchParams &#125; from &#39;url&#39;; export enum ContentType &#123; JSON &#x3D; &quot;application&#x2F;json&quot;, FORM &#x3D; &quot;application&#x2F;x-www-form-urlencoded&quot; &#125;; export enum ResponseType &#123; JSON, XML, BUFFER_OR_JSON, TEXT &#125;; export async function doGet(url: string, headers?: &#123; [index: string]: string &#125;, reqFail?: (err: any) &#x3D;&gt; void, responseType: ResponseType &#x3D; ResponseType.JSON) &#123; let options: RequestInit &#x3D; &#123; method: &quot;GET&quot;, headers: &#123; &#39;Content-Type&#39;: ContentType.JSON &#125;, &#125;; if (headers) &#123; Object.assign(options.headers, headers); &#125; return await doRequest(url, options, reqFail, responseType); &#125; export async function doPost(url: string, body: (URLSearchParams | any), headers?: &#123; [index: string]: string &#125;, reqFail?: (err: any) &#x3D;&gt; void, responseType: ResponseType &#x3D; ResponseType.JSON) &#123; let options: RequestInit &#x3D; &#123; method: &quot;POST&quot; &#125;; if (body &amp;&amp; body.constructor &amp;&amp; body.constructor.name &#x3D;&#x3D;&#x3D; &quot;URLSearchParams&quot;) &#123; &#x2F;&#x2F; 表单类型直接赋值body options.body &#x3D; body; options.headers &#x3D; &#123; &#39;Content-Type&#39;: ContentType.FORM &#125; &#125; else &#123; options.body &#x3D; JSON.stringify(body); options.headers &#x3D; &#123; &#39;Content-Type&#39;: ContentType.JSON &#125; &#125; if (headers) &#123; Object.assign(options.headers, headers); &#125; return await doRequest(url, options, reqFail, responseType); &#125; async function doRequest(url: string, options: RequestInit, reqFail?: (err: any) &#x3D;&gt; void, responseType: ResponseType &#x3D; ResponseType.JSON) &#123; let fetchRes &#x3D; await fetch(url, options); if (fetchRes.status !&#x3D; 200 &amp;&amp; fetchRes.status !&#x3D; 201) &#123; try &#123; if (reqFail) &#123; let err &#x3D; await getError(fetchRes, responseType); await reqFail(err); &#125; &#125; catch &#123; if (reqFail) &#123; await reqFail(&#123; http_status_code: fetchRes.status, error: &#96;to json fail&#96; &#125;); &#125; &#125; return undefined; &#125; let res &#x3D; undefined; switch (responseType) &#123; case ResponseType.JSON: res &#x3D; await fetchRes.json(); break; case ResponseType.XML: case ResponseType.TEXT: res &#x3D; await fetchRes.text() break; case ResponseType.BUFFER_OR_JSON: if ((fetchRes.headers.get(&quot;content-type&quot;) || &quot;&quot;).includes(&quot;json&quot;)) &#123; res &#x3D; await fetchRes.json(); &#125; else &#123; res &#x3D; await fetchRes.buffer(); &#125; break; default: if (reqFail) &#123; await reqFail(&#123; error: &#96;responseType error&#96; &#125;); &#125; break; &#125; return res; &#125; async function getError(fetchRes: any, responseType: ResponseType) &#123; let err: any &#x3D; &#123;&#125;; switch (responseType) &#123; case ResponseType.JSON: err &#x3D; await fetchRes.json(); err.http_status_code &#x3D; fetchRes.status break; case ResponseType.XML: let text &#x3D; await fetchRes.text(); err &#x3D; &#123; http_status_code: fetchRes.status, error: text &#125;; break; default: err &#x3D; &#123; http_status_code: fetchRes.status, error: &#96;responseType error&#96; &#125; break; &#125; return err; &#125;","text":"http部分 import fetch from &quot;node-fetch&quot;; import &#123; RequestInit &#125; from &quot;node-fetch&quot;; import &#123; URLSearchParams &#125; from &#39;url&#39;; export enum ContentType &#123; JSON &#x3D; &quot;application&#x2F;json&quot;, FORM &#x3D; &quot;application&#x2F;x-www-form-urlencoded&quot; &#125;; export enum ResponseType &#123; JSON, XML, BUFFER_OR_JSON, TEXT &#125;; export async function doGet(url: string, headers?: &#123; [index: string]: string &#125;, reqFail?: (err: any) &#x3D;&gt; void, responseType: ResponseType &#x3D; ResponseType.JSON) &#123; let options: RequestInit &#x3D; &#123; method: &quot;GET&quot;, headers: &#123; &#39;Content-Type&#39;: ContentType.JSON &#125;, &#125;; if (headers) &#123; Object.assign(options.headers, headers); &#125; return await doRequest(url, options, reqFail, responseType); &#125; export async function doPost(url: string, body: (URLSearchParams | any), headers?: &#123; [index: string]: string &#125;, reqFail?: (err: any) &#x3D;&gt; void, responseType: ResponseType &#x3D; ResponseType.JSON) &#123; let options: RequestInit &#x3D; &#123; method: &quot;POST&quot; &#125;; if (body &amp;&amp; body.constructor &amp;&amp; body.constructor.name &#x3D;&#x3D;&#x3D; &quot;URLSearchParams&quot;) &#123; &#x2F;&#x2F; 表单类型直接赋值body options.body &#x3D; body; options.headers &#x3D; &#123; &#39;Content-Type&#39;: ContentType.FORM &#125; &#125; else &#123; options.body &#x3D; JSON.stringify(body); options.headers &#x3D; &#123; &#39;Content-Type&#39;: ContentType.JSON &#125; &#125; if (headers) &#123; Object.assign(options.headers, headers); &#125; return await doRequest(url, options, reqFail, responseType); &#125; async function doRequest(url: string, options: RequestInit, reqFail?: (err: any) &#x3D;&gt; void, responseType: ResponseType &#x3D; ResponseType.JSON) &#123; let fetchRes &#x3D; await fetch(url, options); if (fetchRes.status !&#x3D; 200 &amp;&amp; fetchRes.status !&#x3D; 201) &#123; try &#123; if (reqFail) &#123; let err &#x3D; await getError(fetchRes, responseType); await reqFail(err); &#125; &#125; catch &#123; if (reqFail) &#123; await reqFail(&#123; http_status_code: fetchRes.status, error: &#96;to json fail&#96; &#125;); &#125; &#125; return undefined; &#125; let res &#x3D; undefined; switch (responseType) &#123; case ResponseType.JSON: res &#x3D; await fetchRes.json(); break; case ResponseType.XML: case ResponseType.TEXT: res &#x3D; await fetchRes.text() break; case ResponseType.BUFFER_OR_JSON: if ((fetchRes.headers.get(&quot;content-type&quot;) || &quot;&quot;).includes(&quot;json&quot;)) &#123; res &#x3D; await fetchRes.json(); &#125; else &#123; res &#x3D; await fetchRes.buffer(); &#125; break; default: if (reqFail) &#123; await reqFail(&#123; error: &#96;responseType error&#96; &#125;); &#125; break; &#125; return res; &#125; async function getError(fetchRes: any, responseType: ResponseType) &#123; let err: any &#x3D; &#123;&#125;; switch (responseType) &#123; case ResponseType.JSON: err &#x3D; await fetchRes.json(); err.http_status_code &#x3D; fetchRes.status break; case ResponseType.XML: let text &#x3D; await fetchRes.text(); err &#x3D; &#123; http_status_code: fetchRes.status, error: text &#125;; break; default: err &#x3D; &#123; http_status_code: fetchRes.status, error: &#96;responseType error&#96; &#125; break; &#125; return err; &#125; import fetch from &quot;node-fetch&quot;; import &#123; URL &#125; from &#39;url&#39;; import &#123; RequestInit &#125; from &quot;node-fetch&quot;; import logger &#x3D; require(&quot;.&#x2F;logger&quot;); const FormData &#x3D; require(&#39;form-data&#39;); &#x2F;&#x2F; import &#123; URLSearchParams &#125; from &#39;url&#39;; export function requestParam(url: string, method?: string, params?: any, headers?: any): Promise&lt;any&gt; &#123; let form &#x3D; new FormData(); headers &#x3D; headers || form.getHeaders(); for (let key in params) &#123; form.append(key, params[key]); &#125; return request(url, method, form, headers); &#125; export function checkUrl(url: string) &#123; try &#123; let parsedURL &#x3D; new URL(url); logger.info(&#39;url protocol:[%s] host:%s port:%s hostname:%s, path:%s&#39;, parsedURL.protocol, parsedURL.host, parsedURL.port, parsedURL.hostname, parsedURL.pathname); &#125; catch (err) &#123; logger.error(&#39;url:%s invoid, err:%j&#39;, url, err.message); &#125; &#125; export function request(url: string, method?: string, data?: any, headers?: any): Promise&lt;any&gt; &#123; let options: RequestInit &#x3D; &#123; method: method || &#39;GET&#39;, headers: headers || &#123; &#39;Content-Type&#39;: &quot;application&#x2F;json&quot; &#125; &#125;; if (data) &#123; options.body &#x3D; data; &#125; &#x2F;&#x2F;check url &#x2F;&#x2F; checkUrl(url); return new Promise((resolve, reject) &#x3D;&gt; &#123; fetch(url, options).then(resp &#x3D;&gt; &#123; if (resp.status !&#x3D; 200) &#123; return reject(&#39;request status:&#39; + resp.status); &#125; &#x2F;&#x2F;尝试以json结果返回 resp.json().then(data &#x3D;&gt; &#123; resolve(data); &#125;).catch(_ &#x3D;&gt; &#123; &#x2F;&#x2F;尝试以text结果返回 resp.text().then(data &#x3D;&gt; &#123; resolve(data); &#125;).catch(error &#x3D;&gt; &#123; return reject(error); &#125;); &#125;) &#125;).catch(err &#x3D;&gt; &#123; return reject(err); &#125;); &#125;); &#125; 加密部分 md5(data: string) &#123; &#x2F;&#x2F; 以md5的格式创建一个哈希值 let hash &#x3D; crypto.createHash(&#39;md5&#39;); return hash.update(data).digest(&#39;hex&#39;); &#125;, sha1(data: string) &#123; &#x2F;&#x2F; 以md5的格式创建一个哈希值 let hash &#x3D; crypto.createHash(&#39;sha1&#39;); return hash.update(data).digest(&#39;hex&#39;); &#125;, hmac(data: string, key: string, upperCase: boolean &#x3D; false) &#123; if (!key) &#123; throw &#39;invoid hmac &quot;key&quot; params.&#39; &#125; &#x2F;&#x2F; 以md5的格式创建一个哈希值 const hash &#x3D; crypto.createHmac(&#39;md5&#39;, key); let result &#x3D; hash.update(data).digest(&#39;hex&#39;); return upperCase ? result.toUpperCase() : result; &#125;, hmac_sha1(data:string, key:string)&#123; return Base64.stringify((HmacSha1(data,key))); &#125;, &#x2F;** base64编码 *&#x2F; encodeBase64(str: string) &#123; if (!str) &#123; return &quot;&quot; &#125; let buff &#x3D; iconv.encode(str, &#39;utf8&#39;); return iconv.decode(buff, &#39;base64&#39;); &#125;, 时间部分 &#x2F;** * 获取指定整点的时间 *&#x2F; export function getGivenHour(dateVal: Date, hour: number) &#123; let t &#x3D; new Date(dateVal.getFullYear(), dateVal.getMonth(), dateVal.getDate(), hour); return t; &#125; &#x2F;** * 获取本月第一天的时间 *&#x2F; export function getMonthFirstDay(dateVal: Date) &#123; let t &#x3D; new Date(dateVal.getFullYear(), dateVal.getMonth(), 1); return t; &#125; export function getThirtyDay(dateVal: Date): number &#123; let t &#x3D; new Date(dateVal.getFullYear(), dateVal.getMonth(), dateVal.getDate()); let time &#x3D; t.getTime() - 30 * 24 * 60 * 60 * 1000 return time; &#125; &#x2F;** * 获取下个月第一天的时间 *&#x2F; export function getNextMonthFirstDay(dateVal: Date) &#123; let t &#x3D; new Date(dateVal.getFullYear(), dateVal.getMonth() + 1, 1); return t; &#125; &#x2F;** * 一天的毫秒数 *&#x2F; export function getDayMs() &#123; return 86400000; &#125; &#x2F;** * 获取本周第一天的时间 *&#x2F; export function getWeekFirstDay(dateVal: Date) &#123; let day &#x3D; getDay(dateVal); let dnum &#x3D; dateVal.getTime() - ((day - 1) * getDayMs()); let d &#x3D; new Date(dnum); return getGivenHour(d, 0); &#125; &#x2F;** * 获取下个周第一天的时间 *&#x2F; export function getNextWeekFirstDay(dateVal: Date) &#123; let day &#x3D; getDay(dateVal); let dnum &#x3D; dateVal.getTime() + ((8 - day) * getDayMs()); let d &#x3D; new Date(dnum); return getGivenHour(d, 0); &#125; &#x2F;** * 获取day，周日转为7 * 周一：1，周二：2，周三：3，周四：4，周五：5，周六：6，周日：7 *&#x2F; function getDay(dateVal: Date) &#123; let day &#x3D; dateVal.getDay(); day &#x3D; day &#x3D;&#x3D; 0 ? 7 : day; return day; &#125; &#x2F;** * 取当前时间(秒) *&#x2F; export function now(): number &#123; return Math.floor(Date.now() &#x2F; 1000); &#125; &#x2F;** * 时间戳转日期 * @param date *&#x2F; export function dateFormat(date: Date, fmtEnum: FmtOpsion): string &#123; let o: Map&lt;string, number&gt; &#x3D; new Map() .set(&quot;M+&quot;, date.getMonth() + 1) .set(&quot;d+&quot;, date.getDate()) .set(&quot;H+&quot;, date.getHours()) .set(&quot;m+&quot;, date.getMinutes()) .set(&quot;s+&quot;, date.getSeconds()) .set(&quot;q+&quot;, Math.floor((date.getMonth() + 3) &#x2F; 3)) &#x2F;&#x2F; 季度 .set(&quot;S&quot;, date.getMilliseconds()); &#x2F;&#x2F; 毫秒 let fmt &#x3D; fmtEnum.toString(); if (new RegExp(&#x2F;(y+)&#x2F;).test(fmt)) &#123; fmt &#x3D; fmt.replace(RegExp.$1, (date.getFullYear() + &quot;&quot;).substr(4 - RegExp.$1.length)); &#125; o.forEach((_val, k) &#x3D;&gt; &#123; if (new RegExp(&quot;(&quot; + k + &quot;)&quot;).test(fmt)) &#123; let val &#x3D; (o.get(k) || &quot;&quot;).toString(); fmt &#x3D; fmt.replace(RegExp.$1, (RegExp.$1.length &#x3D;&#x3D; 1) ? (val) : ((&quot;00&quot; + val).substr((&quot;&quot; + val).length))); &#125; &#125;); return fmt; &#125; export enum FmtOpsion &#123; longDateTime &#x3D; &quot;yyyy-MM-dd HH:mm:ss&quot;, shortDateTime &#x3D; &quot;yyyy-MM-dd&quot; &#125; export function getLongDateTime(date: Date &#x3D; new Date()) &#123; return dateFormat(date, FmtOpsion.longDateTime); &#125; 数据结构部分 export function ListToMap(list: any[], predicate: (item: any) &#x3D;&gt; any) &#123; let map &#x3D; new Map&lt;any, any&gt;(); for (let i &#x3D; 0; i &lt; list.length; i++) &#123; let item &#x3D; list[i]; let key &#x3D; predicate(item); map.set(key, item); &#125; return map; &#125;","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://zxtotti17.github.io/tags/node-js/"}]},{"title":"题目","slug":"题目","date":"2021-07-01T06:58:40.000Z","updated":"2023-04-10T09:24:12.880Z","comments":true,"path":"/post/题目.html","link":"","permalink":"http://zxtotti17.github.io/post/%E9%A2%98%E7%9B%AE.html","excerpt":"题目：从 innodb 的索引结构分析，为什么索引的 key 长度不能太长？key 太长会导致一个页当中能够存放的 key 的数目变少，间接导致索引树的页数目变多，索引层次增加，从而影响整体查询变更的效率。 题目：请解释下为什么鹿晗发布恋情的时候，微博系统会崩溃，如何解决？A. 获取微博通过 pull 方式还是 push 方式 B. 发布微博的频率要远小于阅读微博 C. 流量明星的发微博，和普通博主要区分对待，比如在 sharding的时候，也要考虑这个因素 题目：引用与指针有什么区别？引用与指针区别：引用只是取得数据,无权修改地址，可以修改值,句柄就是一种引用的方式；指针是直接指向内存的,可以修改数据的。 引用访问一个变量是直接访问，而指针是间接访问。 引用是一个变量的别名，本身不单独分配自己的内存空间，而指针有自己的内存空间。 引用在开始的时候就绑定到了一个内存空间(开始必须赋初值),所以他只能是这个内存空间的名字,而不能改成其他的,当然可以改变这个内存空间的值. 题目：mysql为什么要用b+树，不用平衡二叉树做索引结构平衡二叉树 1.非叶子节点最多拥有两个子节点。 2.非叶子节点值大于左边子节点、小于右边子节点。 3.树的左右两边的层级数相差不会大于1。 4.没有值相等重复的节点。!pinghenTwoXTree 大规模数据存储的时候，平衡二叉树往往出现由于树的深度过大而造成磁盘IO读写过于频繁B+树只有叶节点存放数据，其余节点用来索引,索引也会被存储在磁盘上,层数很少,B+树天然具备排序功能,查询速度更稳定","text":"题目：从 innodb 的索引结构分析，为什么索引的 key 长度不能太长？key 太长会导致一个页当中能够存放的 key 的数目变少，间接导致索引树的页数目变多，索引层次增加，从而影响整体查询变更的效率。 题目：请解释下为什么鹿晗发布恋情的时候，微博系统会崩溃，如何解决？A. 获取微博通过 pull 方式还是 push 方式 B. 发布微博的频率要远小于阅读微博 C. 流量明星的发微博，和普通博主要区分对待，比如在 sharding的时候，也要考虑这个因素 题目：引用与指针有什么区别？引用与指针区别：引用只是取得数据,无权修改地址，可以修改值,句柄就是一种引用的方式；指针是直接指向内存的,可以修改数据的。 引用访问一个变量是直接访问，而指针是间接访问。 引用是一个变量的别名，本身不单独分配自己的内存空间，而指针有自己的内存空间。 引用在开始的时候就绑定到了一个内存空间(开始必须赋初值),所以他只能是这个内存空间的名字,而不能改成其他的,当然可以改变这个内存空间的值. 题目：mysql为什么要用b+树，不用平衡二叉树做索引结构平衡二叉树 1.非叶子节点最多拥有两个子节点。 2.非叶子节点值大于左边子节点、小于右边子节点。 3.树的左右两边的层级数相差不会大于1。 4.没有值相等重复的节点。!pinghenTwoXTree 大规模数据存储的时候，平衡二叉树往往出现由于树的深度过大而造成磁盘IO读写过于频繁B+树只有叶节点存放数据，其余节点用来索引,索引也会被存储在磁盘上,层数很少,B+树天然具备排序功能,查询速度更稳定 题目：多线程的优缺点(1)多线程技术使程序的响应速度更快 ,因为用户界面可以在进行其它工作的同时一直处于活动状态; (2)当前没有进行处理的任务时可以将处理器时间让给其它任务; (3)占用大量处理时间的任务可以定期将处理器时间让给其它任务; (4)可以随时停止任务; (5)可以分别设置各个任务的优先级以优化性能。是否需要创建多个线程取决于各种因素。在以下情况下,最适合采用多线程处理:(1)耗时或大量占用处理器的任务阻塞用户界面操作; (2)各个任务必须等待外部资源 (如远程文件或 Internet连接)。 缺点：(1)等候使用共享资源时造成程序的运行速度变慢。这些共享资源主要是独占性的资源 ,如打印机等。 (2)对线程进行管理要求额外的 CPU开销。线程的使用会给系统带来上下文切换的额外负担。当这种负担超过一定程度时,多线程的特点主要表现在其缺点上,比如用独立的线程来更新数组内每个元素。 (3)线程的死锁。即较长时间的等待或资源竞争以及死锁等多线程症状。 (4)对公有变量的同时读或写。当多个线程需要对公有变量进行写操作时,后一个线程往往会修改掉前一个线程存放的数据,从而使前一个线程的参数被修改;另外 ,当公用变量的读写操作是非原子性时,在不同的机器上,中断时间的不确定性,会导致数据在一个线程内的操作产生错误,从而产生莫名其妙的错误,而这种错误是程序员无法预知的。 题目：数据库范式1.数据库表的每一列都是不可分割的基本数据项，同一列中不能有多个值2.要求数据库表中的每个实例或行必须可以被惟一地区分（主键）3.要求一个数据库表中不包含已在其它表中已包含的非主关键字信息（不要有重复一样属性的在别的表中） 题目：堆栈溢出一般是由什么原因导致的？1.函数调用层次太深。函数递归调用时，系统要在栈中不断保存函数调用时的现场和产生的变量，如果递归调用太深，就会造成栈溢出，这时递归无法返回。再有，当函数调用层次过深时也可能导致栈无法容纳这些调用的返回地址而造成栈溢出。2.动态申请空间使用之后没有释放。由于C语言中没有垃圾资源自动回收机制，因此，需要程序主动释放已经不再使用的动态地址空间。申请的动态空间使用的是堆空间，动态空间使用不会造成堆溢出。3.数组访问越界。C语言没有提供数组下标越界检查，如果在程序中出现数组下标访问超出数组范围，在运行过程中可能会内存访问错误。4.指针非法访问。指针保存了一个非法的地址，通过这样的指针访问所指向的地址时会产生内存访问错误。 内存gc常用的方法引用计数 标记清除(lua) 节点复制(v8,erlang)内存数据一般分为堆 栈 静态， 栈来维护程序执行期间上下文的状态","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://zxtotti17.github.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"算法","slug":"算法","date":"2021-06-23T07:06:23.000Z","updated":"2023-04-10T06:46:33.829Z","comments":true,"path":"/post/算法.html","link":"","permalink":"http://zxtotti17.github.io/post/%E7%AE%97%E6%B3%95.html","excerpt":"最常用的几种算法1.快速排序快速排序的最坏运行情况是 O(n²)，比如说顺序数列的快排。但它的平摊期望时间是 O(nlogn)，且 O(nlogn) 记号中隐含的常数因子很小，比复杂度稳定等于 O(nlogn) 的归并排序要小很多。所以，对绝大多数顺序性较弱的随机数列而言，快速排序总是优于归并排序 function quickSort(arr, left, right) { var len = arr.length, partitionIndex, left = typeof left != &#39;number&#39; ? 0 : left, right = typeof right != &#39;number&#39; ? len - 1 : right; if (left &lt; right) { partitionIndex = partition(arr, left, right); quickSort(arr, left, partitionIndex-1); quickSort(arr, partitionIndex+1, right); } return arr; } function partition(arr, left ,right) { // 分区操作 var pivot = left, // 设定基准值（pivot） index = pivot + 1; for (var i = index; i &lt;= right; i++) { if (arr[i] &lt; arr[pivot]) { swap(arr, i, index); index++; } } swap(arr, pivot, index - 1); return index-1; } function swap(arr, i, j) { var temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } function partition2(arr, low, high) { let pivot = arr[low]; while (low &lt; high) { while (low &lt; high &amp;&amp; arr[high] &gt; pivot) { --high; } arr[low] = arr[high]; while (low &lt; high &amp;&amp; arr[low] &lt;= pivot) { ++low; } arr[high] = arr[low]; } arr[low] = pivot; return low; } function quickSort2(arr, low, high) { if (low &lt; high) { let pivot = partition2(arr, low, high); quickSort2(arr, low, pivot - 1); quickSort2(arr, pivot + 1, high); } return arr; }","text":"最常用的几种算法1.快速排序快速排序的最坏运行情况是 O(n²)，比如说顺序数列的快排。但它的平摊期望时间是 O(nlogn)，且 O(nlogn) 记号中隐含的常数因子很小，比复杂度稳定等于 O(nlogn) 的归并排序要小很多。所以，对绝大多数顺序性较弱的随机数列而言，快速排序总是优于归并排序 function quickSort(arr, left, right) { var len = arr.length, partitionIndex, left = typeof left != &#39;number&#39; ? 0 : left, right = typeof right != &#39;number&#39; ? len - 1 : right; if (left &lt; right) { partitionIndex = partition(arr, left, right); quickSort(arr, left, partitionIndex-1); quickSort(arr, partitionIndex+1, right); } return arr; } function partition(arr, left ,right) { // 分区操作 var pivot = left, // 设定基准值（pivot） index = pivot + 1; for (var i = index; i &lt;= right; i++) { if (arr[i] &lt; arr[pivot]) { swap(arr, i, index); index++; } } swap(arr, pivot, index - 1); return index-1; } function swap(arr, i, j) { var temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } function partition2(arr, low, high) { let pivot = arr[low]; while (low &lt; high) { while (low &lt; high &amp;&amp; arr[high] &gt; pivot) { --high; } arr[low] = arr[high]; while (low &lt; high &amp;&amp; arr[low] &lt;= pivot) { ++low; } arr[high] = arr[low]; } arr[low] = pivot; return low; } function quickSort2(arr, low, high) { if (low &lt; high) { let pivot = partition2(arr, low, high); quickSort2(arr, low, pivot - 1); quickSort2(arr, pivot + 1, high); } return arr; } 2.冒泡排序O(n²) function bubbleSort(arr) { var len = arr.length; for (var i = 0; i &lt; len - 1; i++) { for (var j = 0; j &lt; len - 1 - i; j++) { if (arr[j] &gt; arr[j+1]) { // 相邻元素两两对比 var temp = arr[j+1]; // 元素交换 arr[j+1] = arr[j]; arr[j] = temp; } } } return arr; } 3.归并排序O(nlogn) 的时间复杂度。代价是需要额外的内存空间。申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列； 设定两个指针，最初位置分别为两个已经排序序列的起始位置； 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置； 重复步骤 3 直到某一指针达到序列尾； 将另一序列剩下的所有元素直接复制到合并序列尾。 function mergeSort(arr) { // 采用自上而下的递归方法 var len = arr.length; if(len &lt; 2) { return arr; } var middle = Math.floor(len / 2), left = arr.slice(0, middle), right = arr.slice(middle); return merge(mergeSort(left), mergeSort(right)); } function merge(left, right) { var result = []; while (left.length &amp;&amp; right.length) { if (left[0] &lt;= right[0]) { result.push(left.shift()); } else { result.push(right.shift()); } } while (left.length) result.push(left.shift()); while (right.length) result.push(right.shift()); return result; } 4.选择排序首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。 再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。 重复第二步，直到所有元素均排序完毕。无论什么数据进去都是 O(n²) 的时间复杂度 function selectionSort(arr) { var len = arr.length; var minIndex, temp; for (var i = 0; i &lt; len - 1; i++) { minIndex = i; for (var j = i + 1; j &lt; len; j++) { if (arr[j] &lt; arr[minIndex]) { // 寻找最小的数 minIndex = j; // 将最小数的索引保存 } } temp = arr[i]; arr[i] = arr[minIndex]; arr[minIndex] = temp; } return arr; } 5.插入排序将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。 从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。）O(N^(1-2)) function insertionSort(arr) { var len = arr.length; var preIndex, current; for (var i = 1; i &lt; len; i++) { preIndex = i - 1; current = arr[i]; while(preIndex &gt;= 0 &amp;&amp; arr[preIndex] &gt; current) { arr[preIndex+1] = arr[preIndex]; preIndex--; } arr[preIndex+1] = current; } return arr; } 6.桶排序桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。为了使桶排序更加高效，我们需要做到这两点： 在额外空间充足的情况下，尽量增大桶的数量使用的映射函数能够将输入的 N 个数据均匀的分配到 K 个桶中同时，对于桶中元素的排序，选择何种比较排序算法对于性能的影响至关重要。 什么时候最快当输入的数据可以均匀的分配到每一个桶中。O(n) 什么时候最慢当输入的数据被分配到了同一个桶中。时间复杂度为O(nlogn) function bucketSort(arr, bucketSize) { if (arr.length === 0) { return arr; } var i; var minValue = arr[0]; var maxValue = arr[0]; for (i = 1; i &lt; arr.length; i++) { if (arr[i] &lt; minValue) { minValue = arr[i]; // 输入数据的最小值 } else if (arr[i] &gt; maxValue) { maxValue = arr[i]; // 输入数据的最大值 } } //桶的初始化 var DEFAULT_BUCKET_SIZE = 5; // 设置桶的默认数量为5,理论上有多少数有多少桶最快，时间复杂度为O(n) bucketSize = bucketSize || DEFAULT_BUCKET_SIZE; var bucketCount = Math.floor((maxValue - minValue) / bucketSize) + 1; var buckets = new Array(bucketCount); for (i = 0; i &lt; buckets.length; i++) { buckets[i] = []; } //利用映射函数将数据分配到各个桶中 for (i = 0; i &lt; arr.length; i++) { buckets[Math.floor((arr[i] - minValue) / bucketSize)].push(arr[i]); } arr.length = 0; for (i = 0; i &lt; buckets.length; i++) { insertionSort(buckets[i]); // 对每个桶进行排序，这里使用了插入排序 for (var j = 0; j &lt; buckets[i].length; j++) { arr.push(buckets[i][j]); } } return arr; } 常用加密算法DES AES RSA Base64 hash算法中包括 md5 sha1等, 加密算法可以理解为需要带解密的 不能解密的不属于Base64 常用于 http中RSA 公钥加密算法AES 对称加密算法 内容和key常用函数部分有对应代码 lru算法（缓存淘汰算法） func main() { node := Constructor(3) node.Put(2, 1) fmt.Println(node) } // leetcode146_LRU缓存机制 type Node struct { key int value int prev *Node next *Node } type LRUCache struct { cap int header *Node tail *Node m map[int]*Node } func Constructor(capacity int) LRUCache { cache := LRUCache{ cap: capacity, header: &amp;Node{}, tail: &amp;Node{}, m: make(map[int]*Node, capacity), } cache.header.next = cache.tail cache.tail.prev = cache.header return cache } func (this *LRUCache) Get(key int) int { if node, ok := this.m[key]; ok { this.remove(node) this.putHead(node) return node.value } return -1 } func (this *LRUCache) Put(key int, value int) { if node, ok := this.m[key]; ok { node.value = value this.remove(node) this.putHead(node) return } if this.cap &lt;= len(this.m) { // 删除尾部 deleteKey := this.tail.prev.key this.remove(this.tail.prev) delete(this.m, deleteKey) } // 插入到头部 newNode := &amp;Node{key: key, value: value} this.putHead(newNode) this.m[key] = newNode } // 删除尾部节点 func (this *LRUCache) remove(node *Node) { node.prev.next = node.next node.next.prev = node.prev } // 插入头部 func (this *LRUCache) putHead(node *Node) { next := this.header.next this.header.next = node node.next = next next.prev = node node.prev = this.header","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://zxtotti17.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"微信Baidu审核对接方案实现","slug":"微信baidu审核对接方案实现","date":"2021-05-10T10:03:17.000Z","updated":"2022-09-09T08:23:26.891Z","comments":true,"path":"/post/微信baidu审核对接方案实现.html","link":"","permalink":"http://zxtotti17.github.io/post/%E5%BE%AE%E4%BF%A1baidu%E5%AE%A1%E6%A0%B8%E5%AF%B9%E6%8E%A5%E6%96%B9%E6%A1%88%E5%AE%9E%E7%8E%B0.html","excerpt":"微信和百度都有文字及图片视频啥的AI审核接口，文字审核这里就不说了，时间短也比较快，唯一缺点是测试版每秒的并发最多5个，在并发的情况下会出现未审核，有钱的可以升级付费版，没钱的可以在比较空闲的进程中对未审核的作品和评论，进行2次审核，起一个定时器半小时或者1小时来做 下面着重说下图片审核，至于视频及其他的大文件类似 百度审核图片分为2种，1种是图片下载地址的方式，1种是图片base64字符串，第一种方式依据下载图片的大小等因素变动比较大，普遍在2秒左右，所以顺序执行会阻塞当前进程，所以也得并行异步审核，审核结束去更新审核状态。第二种方式base64字符串，那么这里涉及的一个问题，图片如果保存在服务端本地必然占用空间，也不好管理（定期删除啥的），全依赖客户端传图片的网络消耗也比较大，所以用异步下载在直接取BUFFER数据base64转字符串就比较合适，当然存本地临时文件会更快，具体可以根据不同方案来定。 微信审核图片只有1种，就是图片的buffer数据完整审核，性能也比较快，所以服务端的问题也是选择下载还是存临时文件读取临时文件来做审核，可根据需求来定 具体实现代码如下 export async function check(consumer: any, msg: any, _msgObject: any) &#123; &#x2F;&#x2F; consumer.shift(); &#x2F;&#x2F; 回复写入成功 const AiTypeMap:any &#x3D; &#123;&#39;1&#39;:&#123;&#39;1&#39;:true,&#39;10&#39;:true,&#39;13&#39;:true&#125;,&#39;4&#39;:&#123;&#39;1&#39;:true,&#39;6&#39;:true&#125;&#125;;&#x2F;&#x2F;AI审核类型初始 let files &#x3D; msg.files || []; let id &#x3D; msg.id || &#39;&#39;; let platform_id &#x3D; msg.platform_id || &#39;&#39;; const wx &#x3D; &quot;103&quot;;&#x2F;&#x2F;微信小程序渠道号 if (!files || !files.length || !id) &#123; logger.error(&quot;error checkImgSync&quot;); consumer.shift(); &#x2F;&#x2F; 回复写入成功 return &#125; let errFlag &#x3D; false; let imgSensitivePlugin &#x3D; pomelo.app.get(&#39;imgSensitiveService&#39;); for(let i &#x3D; 0;files &amp;&amp; i &lt; files.length; i++)&#123; let path &#x3D; files[i][&#39;path&#39;] || &#39;&#39;; let n_type &#x3D; files[i][&#39;n_type&#39;] || 0; let fileName &#x3D; files[i][&#39;fileName&#39;] || &#39;&#39;; let result:any &#x3D; &#123;conclusionType : 2&#125;; let pos &#x3D; fileName.indexOf(&#39;.&#39;); let type &#x3D; fileName.substring(pos+1,fileName.length); if(n_type &#x3D;&#x3D; 1)&#123;&#x2F;&#x2F;图片 if(platform_id &#x3D;&#x3D; wx)&#123; let binaryData &#x3D; await downImg(path); if(binaryData)&#123; let wxResult &#x3D; await wxImgCheck(binaryData, type); if(wxResult)&#123; let base64Img &#x3D; binaryData.toString(&#39;base64&#39;); result &#x3D; await baiduImgCheck(base64Img, type); &#125;else&#123;&#x2F;&#x2F;审核不通过 errFlag &#x3D; true; break; &#125; &#125; &#125;else&#123; result &#x3D; await baiduImgPathCheck(path, type); &#125; &#x2F;&#x2F; if(result)&#123;&#x2F;&#x2F;测试 if(result.conclusionType !&#x3D; 1 &amp;&amp; result.data)&#123; let list &#x3D; result.data; for(let l &#x3D;0; l &lt; list.length; l++)&#123; if(AiTypeMap[list[0][&#39;type&#39;]] &amp;&amp; AiTypeMap[list[0][&#39;type&#39;]][list[0][&#39;subType&#39;]])&#123; continue; &#125;else&#123; errFlag &#x3D; true; break; &#125; &#125; &#125; if(errFlag)break; &#125; &#125; if(!errFlag)&#123; await imgSensitivePlugin.update(id);&#x2F;&#x2F;更新缓存及db数据 &#125; consumer.shift(); &#x2F;&#x2F; 回复写入成功 &#125;","text":"微信和百度都有文字及图片视频啥的AI审核接口，文字审核这里就不说了，时间短也比较快，唯一缺点是测试版每秒的并发最多5个，在并发的情况下会出现未审核，有钱的可以升级付费版，没钱的可以在比较空闲的进程中对未审核的作品和评论，进行2次审核，起一个定时器半小时或者1小时来做 下面着重说下图片审核，至于视频及其他的大文件类似 百度审核图片分为2种，1种是图片下载地址的方式，1种是图片base64字符串，第一种方式依据下载图片的大小等因素变动比较大，普遍在2秒左右，所以顺序执行会阻塞当前进程，所以也得并行异步审核，审核结束去更新审核状态。第二种方式base64字符串，那么这里涉及的一个问题，图片如果保存在服务端本地必然占用空间，也不好管理（定期删除啥的），全依赖客户端传图片的网络消耗也比较大，所以用异步下载在直接取BUFFER数据base64转字符串就比较合适，当然存本地临时文件会更快，具体可以根据不同方案来定。 微信审核图片只有1种，就是图片的buffer数据完整审核，性能也比较快，所以服务端的问题也是选择下载还是存临时文件读取临时文件来做审核，可根据需求来定 具体实现代码如下 export async function check(consumer: any, msg: any, _msgObject: any) &#123; &#x2F;&#x2F; consumer.shift(); &#x2F;&#x2F; 回复写入成功 const AiTypeMap:any &#x3D; &#123;&#39;1&#39;:&#123;&#39;1&#39;:true,&#39;10&#39;:true,&#39;13&#39;:true&#125;,&#39;4&#39;:&#123;&#39;1&#39;:true,&#39;6&#39;:true&#125;&#125;;&#x2F;&#x2F;AI审核类型初始 let files &#x3D; msg.files || []; let id &#x3D; msg.id || &#39;&#39;; let platform_id &#x3D; msg.platform_id || &#39;&#39;; const wx &#x3D; &quot;103&quot;;&#x2F;&#x2F;微信小程序渠道号 if (!files || !files.length || !id) &#123; logger.error(&quot;error checkImgSync&quot;); consumer.shift(); &#x2F;&#x2F; 回复写入成功 return &#125; let errFlag &#x3D; false; let imgSensitivePlugin &#x3D; pomelo.app.get(&#39;imgSensitiveService&#39;); for(let i &#x3D; 0;files &amp;&amp; i &lt; files.length; i++)&#123; let path &#x3D; files[i][&#39;path&#39;] || &#39;&#39;; let n_type &#x3D; files[i][&#39;n_type&#39;] || 0; let fileName &#x3D; files[i][&#39;fileName&#39;] || &#39;&#39;; let result:any &#x3D; &#123;conclusionType : 2&#125;; let pos &#x3D; fileName.indexOf(&#39;.&#39;); let type &#x3D; fileName.substring(pos+1,fileName.length); if(n_type &#x3D;&#x3D; 1)&#123;&#x2F;&#x2F;图片 if(platform_id &#x3D;&#x3D; wx)&#123; let binaryData &#x3D; await downImg(path); if(binaryData)&#123; let wxResult &#x3D; await wxImgCheck(binaryData, type); if(wxResult)&#123; let base64Img &#x3D; binaryData.toString(&#39;base64&#39;); result &#x3D; await baiduImgCheck(base64Img, type); &#125;else&#123;&#x2F;&#x2F;审核不通过 errFlag &#x3D; true; break; &#125; &#125; &#125;else&#123; result &#x3D; await baiduImgPathCheck(path, type); &#125; &#x2F;&#x2F; if(result)&#123;&#x2F;&#x2F;测试 if(result.conclusionType !&#x3D; 1 &amp;&amp; result.data)&#123; let list &#x3D; result.data; for(let l &#x3D;0; l &lt; list.length; l++)&#123; if(AiTypeMap[list[0][&#39;type&#39;]] &amp;&amp; AiTypeMap[list[0][&#39;type&#39;]][list[0][&#39;subType&#39;]])&#123; continue; &#125;else&#123; errFlag &#x3D; true; break; &#125; &#125; &#125; if(errFlag)break; &#125; &#125; if(!errFlag)&#123; await imgSensitivePlugin.update(id);&#x2F;&#x2F;更新缓存及db数据 &#125; consumer.shift(); &#x2F;&#x2F; 回复写入成功 &#125; //百度图片路径审核 async function baiduImgPathCheck(path: string, type:string): Promise&lt;any&gt; &#123; let imgSensitivePlugin &#x3D; pomelo.app.get(&#39;imgSensitiveService&#39;); return new Promise((resolve, _reject) &#x3D;&gt; &#123; imgSensitivePlugin.checkPath(path, type).then((res: any) &#x3D;&gt; &#123; resolve(res); &#125;).catch((_err: any) &#x3D;&gt; &#123; logger.error(&#39;checkImg error error:%s&#39;, _err) let data &#x3D; &#123;conclusionType : 2&#125;; resolve(data) &#125;) &#125;); &#125; //百度图片审核 async function baiduImgCheck(binaryData: any, type:string): Promise&lt;any&gt; &#123; let imgSensitivePlugin &#x3D; pomelo.app.get(&#39;imgSensitiveService&#39;); return new Promise((resolve, _reject) &#x3D;&gt; &#123; imgSensitivePlugin.checkImg(binaryData, type).then((res: any) &#x3D;&gt; &#123; resolve(res); &#125;).catch((_err: any) &#x3D;&gt; &#123; logger.error(&#39;checkImg error error:%s&#39;, _err) let data &#x3D; &#123;conclusionType : 2&#125;; resolve(data) &#125;) &#125;); &#125; //微信图片审核 async function wxImgCheck(binaryData: any, type:string): Promise&lt;any&gt; &#123; let imgSensitivePlugin &#x3D; pomelo.app.get(&#39;imgSensitiveService&#39;); return new Promise((resolve, _reject) &#x3D;&gt; &#123; imgSensitivePlugin.wxCheckImg(binaryData, type).then((res: any) &#x3D;&gt; &#123; if(res &amp;&amp; res.errcode &#x3D;&#x3D; 0)&#123; resolve(true); &#125; resolve(false); &#125;).catch((_err: any) &#x3D;&gt; &#123; logger.error(&#39;wxCheck error error:%s&#39;, JSON.stringify(_err)); let data &#x3D; false; resolve(data) &#125;) &#125;); &#125; //下载图片 async function downImg(path: string): Promise&lt;any&gt; &#123; let imgSensitivePlugin &#x3D; pomelo.app.get(&#39;imgSensitiveService&#39;); return new Promise((resolve, _reject) &#x3D;&gt; &#123; imgSensitivePlugin.downImg(path).then((res: any) &#x3D;&gt; &#123; resolve(res); &#125;).catch((_err: any) &#x3D;&gt; &#123; logger.error(&#39;downImg error error:%s&#39;, _err) let data &#x3D; null; resolve(data) &#125;) &#125;); &#125; 下载图片异步下载下载完成后将图片数据保存或者直接使用，不用promise就是异步下载，但是因为审核需要逐一审核所以使用选择顺序执行，也可以异步下载保存后再需要使用的时候读取来使用 public downImg(path:string)&#123; return new Promise((resolve, reject)&#x3D;&gt;&#123; https.request(path, function(response) &#123; var data &#x3D; new stream.Transform(); response.on(&#39;data&#39;, function(chunk) &#123; data.push(chunk); &#125;); response.on(&#39;error&#39;, function(err) &#123; return reject(err); &#125;); response.on(&#39;end&#39;, function() &#123; &#x2F;&#x2F; fs.writeFileSync(&#39;image.png&#39;, data.read()); return resolve(data.read()); &#125;); &#125;).end(); &#125;); &#125; baidu的路径和图片两种审核方式区别就一个参数image:imgData,换成imgUrl:path &#x2F;** * 检查图片 * @param imgData 图片二进制数据 * @see https:&#x2F;&#x2F;ai.baidu.com&#x2F;ai-doc&#x2F;ANTIPORN&#x2F;jk42xep4e * @see http:&#x2F;&#x2F;wiki.bigdata.99.com&#x2F;bin&#x2F;view&#x2F;%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F&#x2F;AI%E6%95%8F%E6%84%9F%E8%AF%8D%E6%A8%A1%E5%9D%97&#x2F; *&#x2F; public async checkImg(imgData: any, type:string): Promise&lt;any&gt; &#123; let conf &#x3D; this.app.get(&#39;imgSensitiveConfig&#39;); if (!imgData) &#123; throw &#39;invalid params &quot;checkImg&quot;.&#39; &#125; let url &#x3D; conf.url || &#39;http:&#x2F;&#x2F;apiproxy.debug.web.nd&#x2F;v0.2&#x2F;&#39;, ai_method &#x3D; conf.ai_method || &#39;visitor&#x2F;forwards&#x2F;baidu&#x2F;img_censor&#39;, baidu_app_id &#x3D; conf.baidu_app_id || &#39;&#39;, &#x2F;&#x2F;增加应用自定义的敏感词库导入 baidu_api_key &#x3D; conf.baidu_api_key || &#39;&#39;, baidu_secret_key &#x3D; conf.baidu_secret_key || &#39;&#39;; let imgType &#x3D; type &#x3D;&#x3D; &quot;gif&quot; ? 1 : 0; let data &#x3D; &#123; baidu_app_id: baidu_app_id, baidu_api_key:baidu_api_key, baidu_secret_key:baidu_secret_key, image:imgData, imgType:imgType &#125; url &#x3D; url + ai_method; return this.request(url, &#39;POST&#39;, data, baidu_app_id); &#125; wx审核参数比较重要缺1不可，错误码41005一定是参数有误，41001一定是access_token不对 &#x2F;** * 微信检查图片 * @param imgData 图片二进制数据 * @see https:&#x2F;&#x2F;developers.weixin.qq.com&#x2F;miniprogram&#x2F;dev&#x2F;api-backend&#x2F;open-api&#x2F;sec-check&#x2F;security.imgSecCheck.html * @see http:&#x2F;&#x2F;wiki.bigdata.99.com&#x2F;bin&#x2F;view&#x2F;%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F&#x2F;AI%E6%95%8F%E6%84%9F%E8%AF%8D%E6%A8%A1%E5%9D%97&#x2F; *&#x2F; public async wxCheckImg(imgData: any, type:string): Promise&lt;any&gt; &#123; let conf &#x3D; this.app.get(&#39;imgSensitiveConfig&#39;); if (!Buffer.isBuffer(imgData)) &#123; throw &#39;invalid params &quot;wxCheckImg&quot;.&#39; &#125; let access_token &#x3D; await this.getWxAccessToken(); let checkUrl &#x3D; conf.wx_check_url || &quot;https:&#x2F;&#x2F;api.weixin.qq.com&#x2F;wxa&#x2F;&quot;; checkUrl +&#x3D; &quot;img_sec_check?access_token&#x3D;&quot; + access_token; return this.requestFrom(checkUrl, &#39;POST&#39;, imgData, &quot;image&#x2F;&quot;+type, &quot;1.png&quot;); &#125; private async requestFrom(url: string, method: string, data: any, typeStr:string, fileName:string): Promise&lt;any&gt; &#123; let formData &#x3D; new FormData(); formData.append(&#39;media&#39;, data, &#123;filename:fileName, contentType: typeStr&#125;);&#x2F;&#x2F;media必须是key,fileName必须要有 let resp &#x3D; await fetch(url, &#123; method: method, body: formData, headers: formData.getHeaders() &#125;); return new Promise((resolve, reject) &#x3D;&gt; &#123; if (!resp || resp.status !&#x3D; 200) &#123; logger.warn(&#96;imgSnsitive $&#123;method&#125; $&#123;url&#125; body:%j&#96;, data); let status &#x3D; resp &amp;&amp; resp.status || 0; resp.json().then(res &#x3D;&gt; &#123; logger.warn(&#96;sensitive resp:%s res:%j&#96;, status, res); &#125;); return reject(&#39;sensitive resp status:&#39; + status); &#125; &#x2F;&#x2F; resolve(resp.json()); &#x2F;&#x2F;尝试以json结果返回 resp.json().then(data &#x3D;&gt; &#123; resolve(data); &#125;).catch(_ &#x3D;&gt; &#123; &#x2F;&#x2F;尝试以text结果返回 resp.text().then(data &#x3D;&gt; &#123; resolve(data); &#125;).catch(error &#x3D;&gt; &#123; return reject(error); &#125;); &#125;) &#125;); &#125;","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://zxtotti17.github.io/tags/node-js/"}]},{"title":"Skynet","slug":"skynet","date":"2021-02-20T09:26:44.000Z","updated":"2022-12-28T08:27:57.480Z","comments":true,"path":"/post/skynet.html","link":"","permalink":"http://zxtotti17.github.io/post/skynet.html","excerpt":"","text":"Skynet 是一个基于 Actor 模式的开源并发框架。 skynet 节点，通过 master ，认识网络中所有其它 skynet 节点。它们相互一一建立单向通讯通道。也就是说，如果一共有 100 个 skynet 节点，在它们启动完毕后，会建立起 1 万条通讯通道。 这个系统是单进程多线程模型。 1.安装linux下 yum install git yum -y install autoconf yum -y install readline-devel git clone https://github.com/cloudwu/skynet.git cd skynet make linux mac下 brew install autoconf git clone https://github.com/cloudwu/skynet.git cd skynet make macosx 启动 ./skynet examples/config #开启服务端节点 ./3rd/lua/lua examples/client.lua #开启客户端测试 2.编写其中的服务2.1 c服务service-src中为c服务的位置编写出基本的构造逻辑函数后需要在Makefile中CSERVICE = 后面加上对应的模块名，然后出来编译后出.so文件在examples文件夹下写lua服务，加配置config文件及lua服务文件，通过local servera = skynet.launch(“zx”, “123”)加载对应的c文件进行交互 2.2lua服务同上面的c，文件名为xx_service.lua,skynet.newservice(“xx_service”)创建服务handle,可以通过skynet.call 或者skynet.send来调用其中的函数 2.3 tcp服务server主要调用skynet.socketdriver,skynet.netpack用来解2进制包数据client需要调用client.socket #自学所要用到的文档http://cloudwu.github.io/lua53doc/contents.htmlhttps://github.com/cloudwu/skynet/wikihttps://docs.docker.com/get-started/https://manistein.github.io/blog/post/server/skynet/skynet%E6%BA%90%E7%A0%81%E8%B5%8F%E6%9E%90/ –conf配置信息已经写入注册表，请根据改函数获取注册表变量skynet.getenv(varName) #PP-skynet框架理解PP项目总体是个多线程多进程的分布式系统!JQ由主节点管理不同节点，每个分支节点一个进程，主节点通关进程通信确定其他节点启动是否正常!JG不同节点实现不同业务需求，实现玩家与公共部分的业务分离 负载均衡才有动态加静态的形式，动态就是随机，静态采样玩家id的个十位奇偶判断 skynet的消息调度有2个消息队列，1个全局消息队列，全局消息队列上放的是子线程的消息队列，每个线程上也有自己独立的消息队列!MQ 当初始化一个服务时，Skynet会生成： 一个skynet_context作为服务的实例 一个唯一的服务handle（服务的唯一ID）用来标识服务 一个消息队列message_queue 向框架注册一个callback回调函数（当服务收到有发送来的消息时通过回调方法传入）Lua 协程挂起的会重新进入消息队列的尾巴，同时让出线程的使用权限，一个线程同一时间只会有一个协程运行 lua协程 主要就是resume和yeildyeild 挂起resume 继续","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"http://zxtotti17.github.io/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"Redis 数据结构","slug":"redis_dataSturct","date":"2021-02-05T09:22:19.000Z","updated":"2022-09-09T08:01:04.311Z","comments":true,"path":"/post/redis_dataSturct.html","link":"","permalink":"http://zxtotti17.github.io/post/redis_dataSturct.html","excerpt":"redis 的数据存储类型分为String Hash List Set(集合） zset(有序集合) 1.String为最基本的类型， 及Key value的形式，我们可以根据具体业务上的需求去定义key来达到1对1的关系，可以理解为一个最简单的mstruct sdshdr { // 记录 buf 数组中已使用字节的数量 // 等于 SDS 所保存字符串的长度 int len; // 记录 buf 数组中未使用字节的数量 int free; // 字节数组，用于保存字符串 char buf[];}; SDS 的空间分配策略： len 和free会分配扩充需要的同样空间，知道所有都不够才会在需要分配，string尽量不要超过1MB 缩减字符串的时候原先的len减少多余的放到free中，总大小不变 2.Hash是（key =&gt; value）的集合，相当于一个二级map ，可以通过secoundKey 来确定二级key下的唯一数据，如果遇到复杂业务逻辑需要多个字段来确定唯一性的时候可以考虑用hash的形式保存数据 Hash表的底层原理： typedef struct dictht { // 哈希表数组 dictEntry **table; // 哈希表大小 unsigned long size; // 哈希表大小掩码，用于计算索引值 // 总是等于 size - 1 unsigned long sizemask; // 该哈希表已有节点的数量 unsigned long used;} dictht; !hash1哈希表节点使用 dictEntry 结构表示 typedef struct dictEntry { // 键 void *key; // 值 union &#123; void *val; uint64_t u64; int64_t s64; &#125; v; // 指向下个哈希表节点，形成链表 struct dictEntry *next;} dictEntry; key 属性保存着键值对中的键， 而 v 属性则保存着键值对中的值， 其中键值对的值可以是一个指针， 或者是一个 uint64_t 整数， 又或者是一个 int64_t 整数。 next 属性是指向另一个哈希表节点的指针， 这个指针可以将多个哈希值相同的键值对连接在一次， 以此来解决键冲突（collision）的问题。","text":"redis 的数据存储类型分为String Hash List Set(集合） zset(有序集合) 1.String为最基本的类型， 及Key value的形式，我们可以根据具体业务上的需求去定义key来达到1对1的关系，可以理解为一个最简单的mstruct sdshdr { // 记录 buf 数组中已使用字节的数量 // 等于 SDS 所保存字符串的长度 int len; // 记录 buf 数组中未使用字节的数量 int free; // 字节数组，用于保存字符串 char buf[];}; SDS 的空间分配策略： len 和free会分配扩充需要的同样空间，知道所有都不够才会在需要分配，string尽量不要超过1MB 缩减字符串的时候原先的len减少多余的放到free中，总大小不变 2.Hash是（key =&gt; value）的集合，相当于一个二级map ，可以通过secoundKey 来确定二级key下的唯一数据，如果遇到复杂业务逻辑需要多个字段来确定唯一性的时候可以考虑用hash的形式保存数据 Hash表的底层原理： typedef struct dictht { // 哈希表数组 dictEntry **table; // 哈希表大小 unsigned long size; // 哈希表大小掩码，用于计算索引值 // 总是等于 size - 1 unsigned long sizemask; // 该哈希表已有节点的数量 unsigned long used;} dictht; !hash1哈希表节点使用 dictEntry 结构表示 typedef struct dictEntry { // 键 void *key; // 值 union &#123; void *val; uint64_t u64; int64_t s64; &#125; v; // 指向下个哈希表节点，形成链表 struct dictEntry *next;} dictEntry; key 属性保存着键值对中的键， 而 v 属性则保存着键值对中的值， 其中键值对的值可以是一个指针， 或者是一个 uint64_t 整数， 又或者是一个 int64_t 整数。 next 属性是指向另一个哈希表节点的指针， 这个指针可以将多个哈希值相同的键值对连接在一次， 以此来解决键冲突（collision）的问题。 Redis 中的字典由 dict.h/dict 结构表示： typedef struct dict { // 类型特定函数 dictType *type; // 私有数据 void *privdata; // 哈希表 dictht ht[2]; // rehash 索引 // 当 rehash 不在进行时，值为 -1 int rehashidx; /* rehashing not in progress if rehashidx == -1 */} dict;!hash2 Hash结构的扩容与回收是一种rehash的机制，类似string的扩容，将ht[1]中保存新的数据及同样大小的空数据[]，然后ht[0]释放ht[1]变ht[0],ht[1]重新变成空结构 List是简单的字符串列表,是双向链表， 增删快，数据类型是可重复的，相当于一个数组，适合最新消息显示这样的，头插入或者尾插入 typedef struct listNode { // 前置节点 struct listNode *prev; // 后置节点 struct listNode *next; // 节点的值 void *value;} listNode; 用多个 listNode 结构就可以组成链表 typedef struct list { // 表头节点 listNode *head; // 表尾节点 listNode *tail; // 链表所包含的节点数量 unsigned long len; // 节点值复制函数 void *(*dup)(void *ptr); // 节点值释放函数 void (*free)(void *ptr); // 节点值对比函数 int (*match)(void *ptr, void *key);} list; set是String类型的无序集合，且集合的数据有唯一性，更新集合中的一条数据需要remove在add，最好在外部rowKey确定是唯一数据的时候，比如一个玩家包含玩家的关卡列表数据结构是intset或者hashtable typedef struct intset &#123; &#x2F;&#x2F; 编码方式 uint32_t encoding; &#x2F;&#x2F; 集合包含的元素数量 uint32_t length; &#x2F;&#x2F; 保存元素的数组 int8_t contents[]; &#125; intset; 比如1对1对多的形式，不要用多对1对多来去存储，在并发的时候会导致原子性取不到的情况 zset是set的有序形式，多了一个socure字段进行排序，socure为double型，适用于排行榜去做自动排序 typedef struct zset &#123; zskiplist *zsl; dict *dict; &#125; zset; zset 结构中的 zsl 跳跃表按分值从小到大保存了所有集合元素， 每个跳跃表节点都保存了一个集合元素： 跳跃表节点的 object 属性保存了元素的成员， 而跳跃表节点的 score 属性则保存了元素的分值。 通过这个跳跃表， 程序可以对有序集合进行范围型操作， 比如 ZRANK 、 ZRANGE 等命令就是基于跳跃表 API 来实现的。zset 结构中的 dict 字典为有序集合创建了一个从成员到分值的映射， 字典中的每个键值对都保存了一个集合元素： 字典的键保存了元素的成员， 而字典的值则保存了元素的分值。 通过这个字典， 程序可以用 O(1) 复杂度查找给定成员的分值， ZSCORE 命令就是根据这一特性实现的， 而很多其他有序集合命令都在实现的内部用到了这一特性。 参考文献：http://redisbook.com/","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://zxtotti17.github.io/tags/redis/"}]},{"title":"消息队列","slug":"MQ","date":"2021-01-22T08:57:26.000Z","updated":"2022-09-13T07:07:59.620Z","comments":true,"path":"/post/MQ.html","link":"","permalink":"http://zxtotti17.github.io/post/MQ.html","excerpt":"","text":"消息队列是分布式应用间交换信息的重要组件，消息队列可驻留在内存或磁盘上, 队列可以存储消息直到它们被应用程序读走。 通过消息队列，应用程序可以在不知道彼此位置的情况下独立处理消息，或者在处理消息前不需要等待接收此消息。 所以消息队列可以解决应用解耦、异步消息、流量削锋等问题，是实现高性能、高可用、可伸缩和最终一致性架构中不可以或缺的一环。 现在比较常见的消息队列产品主要有ActiveMQ、RabbitMQ、ZeroMQ、Kafka、RocketMQ等 自己的理解就是在进程间以队列的形式去管理数据交互的方式，主要用发布/订阅的形式，Mqtt是消息队列中间件的协议Mqtt是基于tcp/ip的 具体性能分析如下!MQ 着重说下RabbitMQ 1.mac安装首先需要安装brew &#x2F;bin&#x2F;zsh -c &quot;$(curl -fsSL https:&#x2F;&#x2F;gitee.com&#x2F;cunkai&#x2F;HomebrewCN&#x2F;raw&#x2F;master&#x2F;Homebrew.sh)&quot; brew install rabbitmq #程序目录 cd &#x2F;usr&#x2F;local&#x2F;sbin&#x2F; #启动 sudo .&#x2F;rabbitmq-server 浏览器访问:localhost:15672,默认账号为:guest 密码: guest ## 添加账号 .&#x2F;rabbitmqctl add_user admin admin ## 添加访问权限 .&#x2F;rabbitmqctl set_permissions -p &quot;&#x2F;&quot; admin &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; ## 设置超级权限 .&#x2F;rabbitmqctl set_user_tags admin administrator","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://zxtotti17.github.io/tags/MQ/"}]},{"title":"node.js插件","slug":"node-js插件","date":"2020-11-11T07:03:25.000Z","updated":"2022-09-09T08:01:21.852Z","comments":true,"path":"/post/node-js插件.html","link":"","permalink":"http://zxtotti17.github.io/post/node-js%E6%8F%92%E4%BB%B6.html","excerpt":"方便开发者根据自身的需求对pomelo原有的功能进行有效的扩展，此目录下可以扩展业务插件。 1.高并发下的统计数据插件 import readNumPlugin &#x3D; require(&#39;.&#x2F;plugins&#x2F;read-num-plugin&#39;); app.use(readNumPlugin, &#123; readNum: &#123; minute:10, expired:24 * 3600, redis_dbid:dbConfig.REDIS.master, worksTable:&quot;works&quot;, clickTable:&quot;click&quot; &#125; &#125;); 调用方式let readNum &#x3D; pomelo.app.get(&#39;readNumService&#39;); let arrWorks &#x3D; []; let res &#x3D; await readNum.addWorksClick(arrWorks); let readNum &#x3D; pomelo.app.get(&#39;readNumService&#39;); let workId &#x3D; &quot;123456&quot;; let res &#x3D; await readNum.getWorkClick(workId); 游客或者会员在点击文章的时候，需要对文章的点击量做一个计数统计。考虑到点击量计数的准确性，有以下几个需求： 用户可以不需要登录每当用户点击文章的详情页面，这个文章的点击量+1用户能实时看到文章点击量，也就是用户点击后能及时看到+1点击量最终保存在数据库中，最终一致性作者在后台编辑文章然后保存时，如果这期间有点击量的增加，保存文章时不能覆盖掉这段时间的增量需要对用户去重处理，也就是一个人在一定时间内多次点击只计数一次，防止用户不断刷新或者使用爬虫不断请求某个API要过滤掉百度和谷歌的爬虫请求（根据User-Agent头判断，可以先不做）一、设计思路 1、因为用户的数量可能很多，所以要求做到高并发，直接在数据库做加1操作不行，考虑利用缓存计数； 2、要求最终数据库数据一致性，考虑利用定时任务从缓存中获取； 3、用户可以匿名，所以缓存的key设计可以用文章标题的hash+用户ip； 4、防止爬虫或者快速刷接口，需要在后端对同一个用户的同一篇文章在缓存中打标； 5、保存文章更新的时候，不能更新点击量，点击量通过定时任务从缓存中获取，防止数据被覆盖； 5、考虑到缓存的使用效率，需要对缓存的key做过期设置，或者主动清除旧的key。 所以设计的时候将统计在缓存中进行统计每隔10分钟（可配置）更新一次统计数据到db，减小了db再高并发情况下的压力 用string类型缓存用户ip的时间，10分钟内只计算一次 用hash类型缓存作品点击数，定时更新，及删除 //验证添加点击 public async checkAndAdd(works_id: string, ip: string): Promise&lt;any&gt; &#123; let update_time &#x3D; await this.getWorkIp(works_id, ip); let now &#x3D; Math.floor(new Date().getTime() &#x2F; 1000 &#x2F; 60 &#x2F; this.minute); if(update_time &lt; now)&#123; let addWorkClick &#x3D; await this.addWorkIp(works_id, ip, now); if(addWorkClick)&#123; await this.addWorkClick(works_id, now);&#x2F;&#x2F;1 &#125; &#125; return true; &#125; //统计更新db public async sensitiveReadNum():Promise&lt;any&gt;&#123; let now &#x3D; Math.floor(new Date().getTime() &#x2F; 1000 &#x2F; 60 &#x2F; this.minute); let create_time &#x3D; new Date(new Date().toLocaleDateString() + &quot; 00:00:00&quot;).getTime()&#x2F;1000; let ret &#x3D; await this.getAllWorkClick(now - 1); if(!ret) return false; for(let k in ret)&#123; let workInfo &#x3D; await this.getWorkInfo(k); if(workInfo &amp;&amp; workInfo.length &gt; 0)&#123; workInfo[0].click_num +&#x3D; Number(ret[k]); &#125; this.execSync(&#39;worksSync.update&#39;, workInfo[0]); if(!await this.addDailyClicks(workInfo[0].id, workInfo[0].user_id, ret[k], workInfo[0].click_num, create_time))&#123; logger.error(&quot;addDailyClicks fail&quot;, now); &#125; &#125; return ret; &#125; db更新用mq队列的形式保证更新正常执行及并发压力，同时可以将统计的丢到另一个进程，在另一个进程异步做统计","text":"方便开发者根据自身的需求对pomelo原有的功能进行有效的扩展，此目录下可以扩展业务插件。 1.高并发下的统计数据插件 import readNumPlugin &#x3D; require(&#39;.&#x2F;plugins&#x2F;read-num-plugin&#39;); app.use(readNumPlugin, &#123; readNum: &#123; minute:10, expired:24 * 3600, redis_dbid:dbConfig.REDIS.master, worksTable:&quot;works&quot;, clickTable:&quot;click&quot; &#125; &#125;); 调用方式let readNum &#x3D; pomelo.app.get(&#39;readNumService&#39;); let arrWorks &#x3D; []; let res &#x3D; await readNum.addWorksClick(arrWorks); let readNum &#x3D; pomelo.app.get(&#39;readNumService&#39;); let workId &#x3D; &quot;123456&quot;; let res &#x3D; await readNum.getWorkClick(workId); 游客或者会员在点击文章的时候，需要对文章的点击量做一个计数统计。考虑到点击量计数的准确性，有以下几个需求： 用户可以不需要登录每当用户点击文章的详情页面，这个文章的点击量+1用户能实时看到文章点击量，也就是用户点击后能及时看到+1点击量最终保存在数据库中，最终一致性作者在后台编辑文章然后保存时，如果这期间有点击量的增加，保存文章时不能覆盖掉这段时间的增量需要对用户去重处理，也就是一个人在一定时间内多次点击只计数一次，防止用户不断刷新或者使用爬虫不断请求某个API要过滤掉百度和谷歌的爬虫请求（根据User-Agent头判断，可以先不做）一、设计思路 1、因为用户的数量可能很多，所以要求做到高并发，直接在数据库做加1操作不行，考虑利用缓存计数； 2、要求最终数据库数据一致性，考虑利用定时任务从缓存中获取； 3、用户可以匿名，所以缓存的key设计可以用文章标题的hash+用户ip； 4、防止爬虫或者快速刷接口，需要在后端对同一个用户的同一篇文章在缓存中打标； 5、保存文章更新的时候，不能更新点击量，点击量通过定时任务从缓存中获取，防止数据被覆盖； 5、考虑到缓存的使用效率，需要对缓存的key做过期设置，或者主动清除旧的key。 所以设计的时候将统计在缓存中进行统计每隔10分钟（可配置）更新一次统计数据到db，减小了db再高并发情况下的压力 用string类型缓存用户ip的时间，10分钟内只计算一次 用hash类型缓存作品点击数，定时更新，及删除 //验证添加点击 public async checkAndAdd(works_id: string, ip: string): Promise&lt;any&gt; &#123; let update_time &#x3D; await this.getWorkIp(works_id, ip); let now &#x3D; Math.floor(new Date().getTime() &#x2F; 1000 &#x2F; 60 &#x2F; this.minute); if(update_time &lt; now)&#123; let addWorkClick &#x3D; await this.addWorkIp(works_id, ip, now); if(addWorkClick)&#123; await this.addWorkClick(works_id, now);&#x2F;&#x2F;1 &#125; &#125; return true; &#125; //统计更新db public async sensitiveReadNum():Promise&lt;any&gt;&#123; let now &#x3D; Math.floor(new Date().getTime() &#x2F; 1000 &#x2F; 60 &#x2F; this.minute); let create_time &#x3D; new Date(new Date().toLocaleDateString() + &quot; 00:00:00&quot;).getTime()&#x2F;1000; let ret &#x3D; await this.getAllWorkClick(now - 1); if(!ret) return false; for(let k in ret)&#123; let workInfo &#x3D; await this.getWorkInfo(k); if(workInfo &amp;&amp; workInfo.length &gt; 0)&#123; workInfo[0].click_num +&#x3D; Number(ret[k]); &#125; this.execSync(&#39;worksSync.update&#39;, workInfo[0]); if(!await this.addDailyClicks(workInfo[0].id, workInfo[0].user_id, ret[k], workInfo[0].click_num, create_time))&#123; logger.error(&quot;addDailyClicks fail&quot;, now); &#125; &#125; return ret; &#125; db更新用mq队列的形式保证更新正常执行及并发压力，同时可以将统计的丢到另一个进程，在另一个进程异步做统计 2.验证码插件将验证码写成一个外置插件，这样需要调用的时候只需要在入口处引入在特定地方调用即可非常方便，同时也可挂载到别的应用 import verifierApiPlugin &#x3D; require(&#39;.&#x2F;plugins[表情]erifier-api-plugin&#39;); app.use(verifierApiPlugin, &#123; verifierApi: &#123; file:&#39;verifierApi.json&#39;, codeNum:4, expired:24 * 3600, redis_dbid:dbConfig.REDIS.master, tableName:&quot;verifier&quot; &#125; &#125;); 调用方式 let verifierApi &#x3D; pomelo.app.get(&#39;verifierApiService&#39;); let code &#x3D; &#39;xxxx&#39;; let res &#x3D; await verifierApi.check(text); &#96;&#96;&#96; 前置依赖需要安装 &#96;&#96;&#96; bash cnpm i svg-captcha --save 或者npm install --save svg-captcha 主要功能是验证验证码和刷新生成验证码 &#x2F;** * 检查验证码 * *&#x2F; public async check(text: string, route:string, userCode:string, platformId:number): Promise&lt;number&gt; &#123; let conf &#x3D; this.app.get(&#39;verifierApiConfig&#39;); let platform &#x3D; conf[route].platform; let max &#x3D; conf[route].max_pre_day || 10; let begin &#x3D; conf[route].bagin_pre_day || 1; if(platform &amp;&amp; platform[platformId])&#123; max &#x3D; platform[platformId].max_pre_day || 21; begin &#x3D; platform[platformId].bagin_pre_day || 20; &#125; let date &#x3D; new Date().toLocaleDateString(); if(!conf[route])&#123; throw &#39;invalid params &quot;route&quot;.&#39; &#125; let storage &#x3D; this.app.get(&#39;dbstorageService&#39;); let rows &#x3D; await this.getCache(date, route, userCode, storage); if (rows &amp;&amp; rows.length) &#123; if(rows[0].num &gt; max)&#123; return 2; &#125;else if(rows[0].num &lt; begin || rows[0].code &#x3D;&#x3D; text.toLowerCase())&#123; rows[0].num++; if(await this.addCache(rows[0], storage))&#123; return 1; &#125; &#125; &#125; return 0; &#125; &#x2F;&#x2F;刷新验证码得到图形验证码 public async getCode(route:string, userCode:string): Promise&lt;any&gt; &#123; let conf &#x3D; this.app.get(&#39;verifierApiConfig&#39;); let date &#x3D; new Date().toLocaleDateString(); if(!route)&#123; throw &#39;invalid params &quot;route&quot;.&#39; &#125; if(conf[route])&#123; let begin &#x3D; conf[route].bagin_pre_day || 1; let storage &#x3D; this.app.get(&#39;dbstorageService&#39;); let rows &#x3D; await this.getCache(date, route, userCode, storage); let codeMap &#x3D; this.createCode(); if (rows &amp;&amp; rows.length) &#123; rows[0].code &#x3D; codeMap.code; if(rows[0].num &gt;&#x3D; begin)&#123; if(await this.addCache(rows[0], storage))&#123; return &#123;is_verify:1, verify_svg:codeMap.data&#125;; &#125; &#125; &#125;else&#123; let opts &#x3D; &#123; userCode:userCode, date:date, route:route, code:codeMap.code, num:0 &#125; await this.addCache(opts, storage); &#125; &#125; return &#123;is_verify:0, verify_svg:&#39;&#39;&#125;; &#125; &#x2F;&#x2F;插件生成验证码部分 可根据需求自行更改生成字数及干扰条纹配置 public createCode():any&#123; const colorMap &#x3D; [&#39;#eeeeee&#39;, &#39;skyblue&#39;, &#39;#c8c8c8&#39;] &#x2F;&#x2F; 配置背景图片颜色集合 const randomColor &#x3D; colorMap[Math.floor(Math.random() * colorMap.length)] &#x2F;&#x2F;随机颜色 let option &#x3D; &#123; size: this.codeNum, &#x2F;&#x2F;验证码长度 width: 200, height: 150, background: randomColor,&#x2F;&#x2F;干扰线条数 noise: 2, fontSize: 32, ignoreChars: &#39;0o1i&#39;, &#x2F;&#x2F;验证码字符中排除&#39;0o1i&#39; color: true &#x2F;&#x2F; 验证码的字符是否有颜色，默认没有，如果设定了背景，则默认有 &#125; let code &#x3D; svgCaptcha.create(option); let strCode &#x3D; code.text.toLowerCase(); &#x2F;&#x2F; let sCode &#x3D; &quot;A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,1,2,3,4,5,6,7,8,9,0&quot;; &#x2F;&#x2F; let arrCode &#x3D; sCode.split(&quot;,&quot;); &#x2F;&#x2F; let strCode &#x3D; &quot;&quot;; &#x2F;&#x2F; for(let i &#x3D; 0;i &lt; this.codeNum; i++)&#123; &#x2F;&#x2F; let random &#x3D; Math.floor(Math.random()*arrCode.length); &#x2F;&#x2F; strCode +&#x3D; arrCode[random]; &#x2F;&#x2F; &#125; return &#123;code:strCode, data:code.data&#125;; &#125;","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://zxtotti17.github.io/tags/node-js/"}]},{"title":"Mongodb笔记","slug":"mongodb笔记","date":"2020-07-28T04:54:03.000Z","updated":"2022-09-09T08:03:18.108Z","comments":true,"path":"/post/mongodb笔记.html","link":"","permalink":"http://zxtotti17.github.io/post/mongodb%E7%AC%94%E8%AE%B0.html","excerpt":"下载地址：https://www.mongodb.com/download-center#community 解压sudo tar -zxvf mongodb-osx-ssl-x86_64-4.0.9.tgzexport PATH=/usr/local/mongodb/bin:$PATH 1、首先我们创建一个数据库存储目录 /data/db： sudo mkdir -p /data/dbsudo mongod –dbpath=/data/db#建议换一个路径，然后先启动mongod进程会卡着日志的地方，再开一个窗口启动mongo就可以了 sudo mount -uw / #增加写权限 使用用户名密码连接mongodb://admin:123456@localhost/ 一般的命令show dbs use runoob #如果数据库不存在，则创建数据库，否则切换到指定数据库。 db.dropDatabase() #删除当前db指向的数据库 MongoDB 中使用 createCollection() 方法来创建集合db.createCollection(name, options) #在 MongoDB 中，你不需要创建集合。当你插入一些文档时，MongoDB 会自动创建集合 增删改查db.test.drop() #删除集合 db.col.insert() db.col.update(&#123;&#39;title&#39;:&#39;MongoDB 教程&#39;&#125;,&#123;$set:&#123;&#39;title&#39;:&#39;MongoDB&#39;&#125;&#125;,&#123;multi:true&#125;)#更新多条有同一标签的数据 db.col.save()#入的文档来替换已有文档，_id 主键存在就更新，不存在就插入 # 条件 $lt &lt; $lte 小于等于 $gt &gt; $gte 大于 $ne 不等 db.col.find(&#123;key1:value1, key2:value2&#125;).pretty() #and db.col.find( #or &#123; $or: [ &#123;key1: value1&#125;, &#123;key2:value2&#125; ] &#125; ).pretty() db.col.find(&#123;&quot;title&quot; : &#123;$type : &#39;string&#39;&#125;&#125;) db.col.find().limit(1) #限制1条数 数组 db.col.find().skip(1) #跳过1条 db.col.find().sort(1) #1升序 -1降序 3者同时的时候优先顺序是 sort skip limit db.values.createIndex(&#123;open: 1, close: 1&#125;, &#123;background: true&#125;) #建立索引1正序 -1反序 创建工作在后台执行 1、查看集合索引 db.col.getIndexes() 2、查看集合索引大小 db.col.totalIndexSize() 3、删除集合所有索引 db.col.dropIndexes() 4、删除集合指定索引 db.col.dropIndex(&quot;索引名称&quot;) db.mycol.aggregate([&#123;$group : &#123;_id : &quot;$by_user&quot;, num_tutorial : &#123;$sum : 1&#125;&#125;&#125;]) &#x3D; select by_user, count(*) from mycol group by by_user $sum 计算总和 $avg 计算平均值 $min 获取集合中所有文档对应值得最小值","text":"下载地址：https://www.mongodb.com/download-center#community 解压sudo tar -zxvf mongodb-osx-ssl-x86_64-4.0.9.tgzexport PATH=/usr/local/mongodb/bin:$PATH 1、首先我们创建一个数据库存储目录 /data/db： sudo mkdir -p /data/dbsudo mongod –dbpath=/data/db#建议换一个路径，然后先启动mongod进程会卡着日志的地方，再开一个窗口启动mongo就可以了 sudo mount -uw / #增加写权限 使用用户名密码连接mongodb://admin:123456@localhost/ 一般的命令show dbs use runoob #如果数据库不存在，则创建数据库，否则切换到指定数据库。 db.dropDatabase() #删除当前db指向的数据库 MongoDB 中使用 createCollection() 方法来创建集合db.createCollection(name, options) #在 MongoDB 中，你不需要创建集合。当你插入一些文档时，MongoDB 会自动创建集合 增删改查db.test.drop() #删除集合 db.col.insert() db.col.update(&#123;&#39;title&#39;:&#39;MongoDB 教程&#39;&#125;,&#123;$set:&#123;&#39;title&#39;:&#39;MongoDB&#39;&#125;&#125;,&#123;multi:true&#125;)#更新多条有同一标签的数据 db.col.save()#入的文档来替换已有文档，_id 主键存在就更新，不存在就插入 # 条件 $lt &lt; $lte 小于等于 $gt &gt; $gte 大于 $ne 不等 db.col.find(&#123;key1:value1, key2:value2&#125;).pretty() #and db.col.find( #or &#123; $or: [ &#123;key1: value1&#125;, &#123;key2:value2&#125; ] &#125; ).pretty() db.col.find(&#123;&quot;title&quot; : &#123;$type : &#39;string&#39;&#125;&#125;) db.col.find().limit(1) #限制1条数 数组 db.col.find().skip(1) #跳过1条 db.col.find().sort(1) #1升序 -1降序 3者同时的时候优先顺序是 sort skip limit db.values.createIndex(&#123;open: 1, close: 1&#125;, &#123;background: true&#125;) #建立索引1正序 -1反序 创建工作在后台执行 1、查看集合索引 db.col.getIndexes() 2、查看集合索引大小 db.col.totalIndexSize() 3、删除集合所有索引 db.col.dropIndexes() 4、删除集合指定索引 db.col.dropIndex(&quot;索引名称&quot;) db.mycol.aggregate([&#123;$group : &#123;_id : &quot;$by_user&quot;, num_tutorial : &#123;$sum : 1&#125;&#125;&#125;]) &#x3D; select by_user, count(*) from mycol group by by_user $sum 计算总和 $avg 计算平均值 $min 获取集合中所有文档对应值得最小值 mongoDB的主从副本集mongod –port “PORT” –dbpath “YOUR_DB_DATA_PATH” –replSet “REPLICA_SET_INSTANCE_NAME”mongod –port 27017 –dbpath “D:\\set up\\mongodb\\data” –replSet rs0以上实例会启动一个名为rs0的MongoDB实例，其端口号为27017。启动后打开命令提示框并连接上mongoDB服务。在Mongo客户端使用命令rs.initiate()来启动一个新的副本集。我们可以使用rs.conf()来查看副本集的配置查看副本集状态使用 rs.status() 命令添加副本集的成员，我们需要使用多台服务器来启动mongo服务。进入Mongo客户端，并使用rs.add()方法来添加副本集的成员rs.add(“mongod1.net:27017”)db.isMaster()# 判断当前运行的Mongo服务是否为主节点可以使用命令副本集在主机宕机后，副本会接管主节点成为主节点 （渣男的品质） mongo备份mongodump -h dbhost -d dbname -o dbdirectory #-d 数据库实例 -o 备份数据存放位置 mongo监控mongostat是mongodb自带的状态检测工具 bin/mongostat bin/mongotop mongo覆盖查询db.users.ensureIndex(&#123;gender:1,user_name:1&#125;) db.users.find(&#123;gender:&quot;M&quot;&#125;,&#123;user_name:1,_id:0&#125;) #MongoDB的不会去数据库文件中查找。相反，它会从索引中提取数据 mongo查询分析db.users.find(&#123;gender:&quot;M&quot;&#125;,&#123;user_name:1,_id:0&#125;).explain() indexOnly: 字段为 true ，表示我们使用了索引 mongodb原子操作$set用来指定一个键并更新键值，若键不存在并创建。{ $set : { field : value } }$unset用来删除一个键。{ $unset : { field : 1} }$inc$inc可以对文档的某个值为数字型（只能为满足要求的数字）的键进行增减的操作。{ $inc : { field : value } }$push用法：{ $push : { field : value } }把value追加到field里面去，field一定要是数组类型才行，如果field不存在，会新增一个数组类型加进去$pushAll同$push,只是一次可以追加多个值到一个数组字段内。{ $pushAll : { field : value_array } }$pull从数组field内删除一个等于value值。{ $pull : { field : value } }$addToSet增加一个值到数组内，而且只有当这个值不在数组内才增加。$pop删除数组的第一个或最后一个元素{ $pop : { field : 1 } }$rename修改字段名称{ $rename : { old_field_name : new_field_name } }$bit位操作，integer类型{$bit : { field : {and : 5}}} db.collection.findAndModify() #查询并更新 db.col.findAndModify ( &#123; query: &#123; _id: 123456789, available: &#123; $gt: 0 &#125; &#125;, #查询 update: &#123; $inc: &#123; available: -1 &#125;, $push: &#123; checkout: &#123; by: &quot;abc&quot;, date: new Date() &#125; &#125; &#125; #更新 &#125; )","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"http://zxtotti17.github.io/tags/mongodb/"}]},{"title":"Node中间件","slug":"node中间件","date":"2020-07-14T08:01:50.000Z","updated":"2021-11-30T09:05:29.725Z","comments":true,"path":"/post/node中间件.html","link":"","permalink":"http://zxtotti17.github.io/post/node%E4%B8%AD%E9%97%B4%E4%BB%B6.html","excerpt":"","text":"node中间件可以概括为在请求的过程中或者进程间通信过程中过滤，交给函数处理之前先交给他处理比如用来做中间件的 body-parser method-override 自己写的心跳及检测用户登录验证功能 app.use(&#39;&#x2F;&#39;,function(req,res,next)&#123; console.log(&#39;1&#39;); next(); &#x2F;&#x2F;重要代码 &#125; bodyParser.js 原理解析判断请求为 post 请求，则进行解析。因为是 post 请求，传输数据可能会很大，需要一点一点传。创建 postData 变量，存储在变量里面使用 querystring模块解析post参数将解析好的参数对象添加到req的属性中 req.body执行下一个中间件 next() method-override增加请求类型 错误处理可以自定义一个中间件做最外层处理app.use(&#39;&#x2F;&#39;, function(err,req,res,next)&#123; res.send(&#39;网络异常。。。&#39;) &#x2F;&#x2F;要改提示信息在这里改即可：res.send(&#39;网络异常，请稍后重试&#39;) &#125;","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://zxtotti17.github.io/tags/node-js/"}]},{"title":"Python学习笔记","slug":"python学习笔记","date":"2020-07-09T08:20:08.000Z","updated":"2022-09-09T08:01:11.676Z","comments":true,"path":"/post/python学习笔记.html","link":"","permalink":"http://zxtotti17.github.io/post/python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html","excerpt":"","text":"1.遇到的问题SyntaxError: Non-ASCII character ‘\\xe4’#-- coding: utf-8 -- 或者 #coding=utf-8 mac上的环境变量open ~/.bash_profile中加入如下然后保存 source ~/.bash_profile#Setting PATH for Python 3.8 export PYTHON3&#x3D;&#x2F;Library&#x2F;Frameworks&#x2F;Python.framework&#x2F;Versions&#x2F;3.8&#x2F;bin alias python3&#x3D;&quot;&#x2F;Library&#x2F;Frameworks&#x2F;Python.framework&#x2F;Versions&#x2F;3.8&#x2F;bin&#x2F;python3&quot; export PATH&#x3D;$MYSQL:$PYTHON3:$PATH: zip函数&gt;&gt;&gt;a &#x3D; [1,2,3] &gt;&gt;&gt; b &#x3D; [4,5,6] &gt;&gt;&gt; c &#x3D; [4,5,6,7,8] &gt;&gt;&gt; zipped &#x3D; zip(a,b) # 打包为元组的列表 [(1, 4), (2, 5), (3, 6)] &gt;&gt;&gt; zip(a,c) # 元素个数与最短的列表一致 [(1, 4), (2, 5), (3, 6)] &gt;&gt;&gt; zip(*zipped) # 与 zip 相反，*zipped 可理解为解压，返回二维矩阵式 [(1, 2, 3), (4, 5, 6)]","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"python","slug":"python","permalink":"http://zxtotti17.github.io/tags/python/"}]},{"title":"Mysql笔记","slug":"mysql_biji","date":"2020-07-06T08:40:36.000Z","updated":"2022-09-13T07:07:15.377Z","comments":true,"path":"/post/mysql_biji.html","link":"","permalink":"http://zxtotti17.github.io/post/mysql_biji.html","excerpt":"第1章 SQL基础1.数据分为DDL(数据定义语言)，DML(数据操纵语言)，DCL(数据控制语言) 1.1 DDL语句 mysql -uroot -p create database test1; use test1; show tables; #查看所有表 drop database test1; create table emp(ename varchar(10),hiredate date,sal decimal(2,10),deptno int(2)); desc emp; #查看表信息 show create table emp \\G; #\\G使得记录能够按照字段竖向排列 以便显示更长内容 drop table emp; alter table emp modify ename varchar(20); #修改表字段 alter table emp add column age int(3); #添加字段 alter table emp drop colum age #删除字段 alter table emp change age age123 int(4); #字段改名同时修改类型 alter table emp add birth date after ename; #修改字段排列顺序 alter table emp rename emp1;","text":"第1章 SQL基础1.数据分为DDL(数据定义语言)，DML(数据操纵语言)，DCL(数据控制语言) 1.1 DDL语句 mysql -uroot -p create database test1; use test1; show tables; #查看所有表 drop database test1; create table emp(ename varchar(10),hiredate date,sal decimal(2,10),deptno int(2)); desc emp; #查看表信息 show create table emp \\G; #\\G使得记录能够按照字段竖向排列 以便显示更长内容 drop table emp; alter table emp modify ename varchar(20); #修改表字段 alter table emp add column age int(3); #添加字段 alter table emp drop colum age #删除字段 alter table emp change age age123 int(4); #字段改名同时修改类型 alter table emp add birth date after ename; #修改字段排列顺序 alter table emp rename emp1; 1.2 DML语句 增删改查 insert into emp (ename,sal) values(&#39;dony&#39;,1000); delete from emp where ename &#x3D; &#39;xxx&#39;; select distinct age from emp1; #查询的内容去重 select * from emp order by age,deptno desc; #根据某个字段排序 select age,count(1) from emp group by age with rollup; #分类统计计数及总数 select age,count(1) from emp group by age having count(1)&gt;1; select ename,deptname from emp,dept where emp.age &#x3D; dept.age; #联查,内链接 select ename,deptname from emp left jion dept on emp.deptno &#x3D; dept.deptno; #表链接很多情况下优于子查询 select * from dept union all select * from emp; #集合显示不去重 select * from dept union select * from emp; #集合显示去重 You can&#39;t specify target table &#39; for update in FROM clause Mysql不让对查询到的目标语句进行更新 DELETE FROM playeritems WHERE id IN(SELECT mid FROM (SELECT min(id) as mid FROM playeritems WHERE uid &#x3D; &#39;1300200112870961&#39; GROUP BY iname HAVING count(iname) &gt; 1 )as tmp); 1.3 DCL语句 grant select,insert on sakila.* to &#39;z1@localhost&#39; identified by &#39;123&#39;; #赋予用户权限 revoke insert on sakila.* from &#39;z1@localhost&#39;; #回收权限2.常用函数 select NOW(); #xxxx-xx-xx xx:xx:xx select UNIX_TIMESTAMP(now()); #时间戳 select FROM_UNIXTIME(时间戳); #xxxx-xx-xx xx:xx:xx IF(value,t,f) #如果value为真，返回t,否则返回f select if(a &gt; 2000, &#39;high&#39;,&#39;low&#39;) from B IFNULL(value1,value2) #如果value1不为空，返回value1,否则返回value2 select ifnull(a , 0) from B CASE WHEN value THEN res1 ... ELSE def END #如果value1真，返回res1,否则返回def select case when a&lt;2000 then &#39;low&#39; else &#39;high&#39; end from B CASE exp WHEN value THEN res1 ... ELSE def END #如果exp &#x3D; value1真，返回res1,否则返回def select case a when 1000 then &#39;low&#39; when 2000 then &#39;mid&#39; else &#39;high&#39; end from B 第2章 存储引擎1.mysql的存储引擎有好多种，这边记录2种 1.1 MyISAM 不支持事务、不支持外键、速度快、表锁 1.2 InnoDB 支持提交、回滚、奔溃恢复能力的事务安全，行锁 2.myssql事务 start transaction; sql 操作 commit and chain; 3.防止sql注入 $re &#x3D; &quot;&#x2F;(|\\&#39;|(\\%27)|\\;|(\\%3b)|\\&#x3D;|(\\%3d)|\\(|(\\%28)|\\)|(\\%29)|(\\&#x2F;*) |(\\%2f%2a)|(\\ *&#x2F;)|(\\%2a%2f)|\\+|(\\%2b)|\\&lt;|(\\%3c)|\\&gt;|(\\%3e)|\\(--))|\\[|\\%5b|\\]|\\%5d)&#x2F;&quot;; if(preg_match($re, $aa) &gt;0)&#123; echo(&quot;参数不对&quot;); return 0; &#125; 4.SQL MODEANSI 使语法行为更符合sqlSTRICT_TRANS_TABLES 试用于事务，严格模式，报错不警告,不允许非法日期TRADITIONAL 严格模式，适用于事务非事务，不警告直接报错 5.sql分区RANGE分区：基于一个给定连续区间范围，把数据分配到不同分区LIST分区：类似RANGEHASH分区：基于给定的分区个数，把数据分配到不同分区KEY分区：类似于HASH分区RANGE\\LIST\\HASH分区键必须INT型 好处4点存储更多数据、优化查询、快速删除数据、获得更大查询吞吐量Range分区利用取值范围将数据分成分区 CREATE TABLE emp( id INT NOT NULL, NAME VARCHAR(20), age INT ) PARTITION BY RANGE(ID)( PARTITION p0 VALUES LESS THAN (6), PARTITION p1 VALUES LESS THAN (11), PARTITION pmax VALUES LESS THAN maxvalue ); &#96;&#96;&#96; while LIST分区是建立离散的之列表告诉数据库特定值在哪个分区 &#96;&#96;&#96; bash CREATE TABLE expense( expense_date DATE NOT NULL, category INT, amount DECIMAL (10,3) ) PARTITION BY LIST(category)( PARTITION p0 VALUES IN(3,5),#可字符串在5.5版本后 PARTITION p1 VALUES IN(1,10), PARTITION p2 VALUES IN(4,9), PARTITION p3 VALUES IN(2), PARTITION p4 VALUES IN(6) ); Columns分区可分为 RANGE Columns和LIST Columns分区都支持int\\date\\string,还支持多列 CREATE TABLE expense( a INT, b INT ) PARTITION BY RANGE COLUMS(a,b)( PARTITION p0 VALUES IN(0,10),#可字符串在5.5版本后 PARTITION p1 VALUES IN(10,10), PARTITION p2 VALUES IN(10,29) ); HASH分区用来分散热点读，确保数据在预留分区平均分布，有常规分区和线性分区 #常规 平衡不方便 CREATE TABLE emp( id INT NOT NULL, NAME VARCHAR(20), age INT ) PARTITION BY HASH(ID) PARTITIONS 4; #线性 快速不平衡 CREATE TABLE emp( id INT NOT NULL, NAME VARCHAR(20), age INT ) PARTITION BY LINEAR HASH(ID) PARTITIONS 4; key分区类似HASH分区，数据类型除TEXThe BLOB以外都可以 RANGE&amp;LIST 分区管理 分区被删除了分区中的数据也被删除了 alter table xxx drop partition p2; #删 alter table xxx add partition (partiton p5 values less than (2025)) #增 不能添加一个包含现有分区值列表中的任意值分区 alter table xxx reorganize partition p3 into ( partition p2 values less than (2005), partition p3 values less than (2015) ); #拆分 alter table xxx reorganize partition p1,p2,p3 into ( partition p1 values less than (2015) ); #合并 HASH&amp;KEY 分区管理 alter table xxx coalesce partition 2; #原4删2 alter table xxx coalesce partition 8; #原4加8 6.SQL优化 通过慢查询日志定位效率低的sql,在查询过程中出现的情况可以用show processlist命令查看mysql进程，看锁表及进程状态 将慢的sql提取做explain分析，type的性能如下 ALL,全表扫瞄 index,索引全扫描 range,索引范围扫描 常见&lt;&lt;=&gt;&gt;=\\between ref,使用非唯一索引扫描或者唯一索引前缀扫描（联合索引） eq_ref,使用唯一索引 const/system,单表中最多有一个匹配行 NULL，不查表直接得到结果 自上而下效率越来越高 通过show profile分析sqlselect @@have_profiling; #查询是否支持 select @@profiling; #查询是否开启 set profiling&#x3D;1; #开启 show profiles; #显示sql的执行排列 show profile for query 4; #查找具体某一条的状态 show profile cpu for query 4; #查询莫一条在具体（all\\cpu\\block io\\context\\switch\\page faults） mac或者linux当mysql连接不上的时候加ALTER USER ‘root’@’localhost’ IDENTIFIED WITH mysql_native_password BY ‘password’; 7.mysql配置优化在mysqld下 为所有线程打开的表的数量。增加这个值会增加mysqld需要的文件描述符的数量。因此，您必须确保在[mysqld_safe]节中的变量“open-files-limit”中将允许打开的文件数量至少设置为4096table_open_cache=2000 内部(内存)临时表的最大大小。如果一个表比这个值大，那么它将自动转换为基于磁盘的表。可以有很多。tmp_table_size=94M 我们应该在缓存中保留多少线程以供重用。当客户机断开连接时，如果之前的线程数不超过thread_cache_size，则将客户机的线程放入缓存。如果您有很多新连接，这将大大减少所需的线程创建量(通常，如果您有一个良好的线程实现，这不会带来显著的性能改进)。thread_cache_size=10 如果用于快速创建索引的临时文件比这里指定的使用键缓存的文件大，则首选键缓存方法。这主要用于强制大型表中的长字符键使用较慢的键缓存方法来创建索引。key_buffer_size=8M 用于对MyISAM表执行全表扫描的缓冲区的大小。如果需要完整的扫描，则为每个线程分配。read_buffer_size=16Mread_rnd_buffer_size=32M 如果在SHOW GLOBAL STATUS输出中每秒看到许多sort_merge_passes，可以考虑增加sort_buffer_size值，以加快ORDER BY或GROUP BY操作的速度，这些操作无法通过查询优化或改进索引来改进。sort_buffer_size=16M InnoDB用于缓冲日志数据的缓冲区大小。一旦它满了，InnoDB就必须将它刷新到磁盘。由于它无论如何每秒刷新一次，所以将它设置为非常大的值是没有意义的(即使是长事务)。innodb_log_buffer_size=5M 与MyISAM不同，InnoDB使用缓冲池来缓存索引和行数据。设置的值越大，访问表中的数据所需的磁盘I/O就越少。在专用数据库服务器上，可以将该参数设置为机器物理内存大小的80%。但是，不要将它设置得太大，因为物理内存的竞争可能会导致操作系统中的分页。注意，在32位系统上，每个进程的用户级内存可能被限制在2-3.5G，所以不要设置得太高。innodb_buffer_pool_size=20M ORDER BY 或者GROUP BY 操作的buffer缓存大小innodb_sort_buffer_size = 64M 为了提升扩展性和刷脏效率，在5.7.4版本里引入了多个page cleaner线程。从而达到并行刷脏的效果在该版本中，Page cleaner并未和buffer pool绑定，其模型为一个协调线程 + 多个工作线程，协调线程本身也是工作线程。因此如果innodb_page_cleaners设置为8，那么就是一个协调线程，加7个工作线程innodb_page_cleaners = 4 mysql客户端连接数据库是交互式连接，通过jdbc连接数据库是非交互式连接interactive_timeout = 100 # 交互式连接超时wait_timeout = 100 # 非交互连接超时 8.mysql索引背后的数据结构及算法 B-Tree为了描述B-Tree，首先定义一条数据记录为一个二元组[key, data]，key为记录的键值，对于不同数据记录，key是互不相同的；data为数据记录除key外的数据。那么B-Tree是满足下列条件的数据结构：d为大于1的一个正整数，称为B-Tree的度。h为一个正整数，称为B-Tree的高度。每个非叶子节点由n-1个key和n个指针组成，其中d&lt;=n&lt;=2d。每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null 。所有叶节点具有相同的深度，等于树高h。key和指针互相间隔，节点两端是指针。一个节点中的key从左到右非递减排列。所有节点组成树结构。每个指针要么为null，要么指向另外一个节点。如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于(v(key_1))，其中(v(key_1))为node的第一个key的值。如果某个指针在节点node最右边且不为null，则其指向节点的所有key大于(v(key_m))，其中(v(key_m))为node的最后一个key的值。如果某个指针在节点node的左右相邻key分别是(key_i)和(key_{i+1})且不为null，则其指向节点的所有key小于(v(key_{i+1}))且大于(v(key_i))。图2是一个d=2的B-Tree示意图。!1594024645933 由于B-Tree的特性，在B-Tree中按key检索数据的算法非常直观：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到null指针，前者查找成功，后者查找失败。B-Tree上查找算法的伪代码如下： BTree_Search(node, key) &#123; if(node &#x3D;&#x3D; null) return null; foreach(node.key) &#123; if(node.key[i] &#x3D;&#x3D; key) return node.data[i]; if(node.key[i] &gt; key) return BTree_Search(point[i]-&gt;node); &#125; return BTree_Search(point[i+1]-&gt;node); &#125; data = BTree_Search(root, my_key);关于B-Tree有一系列有趣的性质，例如一个度为d的B-Tree，设其索引N个key，则其树高h的上限为(log_d((N+1)/2))，检索一个key，其查找节点个数的渐进复杂度为(O(log_dN))。从这点可以看出，B-Tree是一个非常有效率的索引数据结构。 B+TreeMySQL就普遍使用B+Tree实现其索引结构与B-Tree相比，B+Tree有以下不同点：每个节点的指针上限为2d而不是2d+1。内节点不存储data，只存储key；叶子节点不存储指针。图3是一个简单的B+Tree示意。!1594091073360 一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针 MyISAM索引使用的是B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址!1594103060655 InnoDB索引InnoDB也使用B+Tree作为索引结构第一重大区别是InnoDB的数据文件本身就是索引文件，InnoDB表数据文件本身就是主索引!1594103257328因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有）如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址1594103590868聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择 InnoDB的主键选择与插入优化在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键 （百万条以下的数据看不出来多大区别） 1、B+树的层级更少。 相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快； 2、B+树查询速度更稳定。 B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定; 3、B+树天然具备排序功能。 B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。 4、B+树全节点遍历更快。 B+树遍历整棵树只需要遍历所有的叶子节点即可，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。 9.mysql 调优过程中的常用命令ps -es|grep mysql 当启动不了或者报错的时候，mysql Password字段是authentication_string,配置太多会报错启动用/usr/local/mysql/bin/mysqld –user=mysql 刷新数据库 进mysql后Access denied for user ‘root@localhost’报错update mysql.user set authentication_string=’123’ where user=’root’; macs上的环境变量open ~/.bash_profile中加入如下然后保存 source ~/.bash_profile#windos下 安装要装一个vcredistx64mysqld –skip-grant-tables 进入后修改密码 #mysql export MYSQL&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin export PATH&#x3D;$MYSQL:$PYTHON3:$PATH: 查看MySQL服务器配置信息mysql&gt; show variables; 查看MySQL服务器运行的各种状态值mysql&gt; show global status; mysql一定要定期清理日志，不然会出莫名其妙的问题，什么有的库打开就断开连接这样的ERROR 1030 (HY000) at line 33: Got error 168 from storage enginemysql&gt; reset master;#清除日志 连接数查看show status like ‘Threads%’;SHOW VARIABLES LIKE ‘%max_connections%’;set global max_connections = 1000;flush privileges; #!/bin/bashexport pid=ps -ef | grep mysql | head -n 1 | awk &#39;&#123;print $2&#125;&#39; 取mysql的pidecho password | sudo kill -9 $pidmysql -uroot -pxx -e “set global max_connections = 1000;reset master;…”sh -x xxx.sh 看问题","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://zxtotti17.github.io/tags/mysql/"}]},{"title":"游戏成就任务系统设计","slug":"游戏成就任务系统设计","date":"2020-06-29T01:07:21.000Z","updated":"2023-03-23T09:02:28.051Z","comments":true,"path":"/post/游戏成就任务系统设计.html","link":"","permalink":"http://zxtotti17.github.io/post/%E6%B8%B8%E6%88%8F%E6%88%90%E5%B0%B1%E4%BB%BB%E5%8A%A1%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1.html","excerpt":"","text":"游戏中的成就任务一般是伴随着玩家操作，及一些游戏次数记录所以可以用一个监听如node里面的 var EventEmitter = require(&#39;events&#39;).EventEmitter; var life = new EventEmitter(); //这里不用on，也可以用addEventListener life.on(&#39;doSth&#39;, function(who){ console.log(&#39;给 &#39; + who + &#39; 倒水&#39;); }) life.emit(&#39;doSth&#39;,&#39;Sunny&#39;); EventEmitter相当于一个生产者消费者模式，事件发布订阅的形式注册监听的请求回发数据，对应的请求去对应执行相应的成就改变请求的类型可以存放在map中，如 {&quot;server.game.inter&quot;:[...class],&quot;server.game.interAct&quot;:[...class]} 对应请求的列表取出后的对其中类的回调依次执行在返回类似的map {&quot;1&quot;:{“up”:1},&quot;2&quot;:{“up”:1}} 在更新任务返回给客户端显示 成就任务中需要获得物品的可以定义一个基类 类属性self.idlist = list;list可以为传参进来的物品列表，该列表是需要我们监听的物品改变一般返回给客户端需要物品及数量，可以在返回的里面判断增加多少 let up = 0;//单一物品 for(k in returnData.gain){ if(self.idlist.indexOf(k) &gt; -1){ up+= returnData.gain[k]; } } return up;","categories":[{"name":"设计方法","slug":"设计方法","permalink":"http://zxtotti17.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"http://zxtotti17.github.io/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"Es6 Js规范","slug":"js规范","date":"2020-06-09T09:59:15.000Z","updated":"2020-06-24T09:29:35.525Z","comments":true,"path":"/post/js规范.html","link":"","permalink":"http://zxtotti17.github.io/post/js%E8%A7%84%E8%8C%83.html","excerpt":"数组拷贝 const itemsCopy &#x3D; [...items]; 取值方式 const [first, second] &#x3D; arr; 函数初始化 function f3(a) &#123; const b &#x3D; a || 1; &#x2F;&#x2F; ... &#125; function f4(a &#x3D; 1) &#123; &#x2F;&#x2F; ... &#125; 输出数组 const x &#x3D; [1, 2, 3, 4, 5]; console.log(...x); new Date(...[2016, 8, 5]); 数组遍历 let sum &#x3D; 0; numbers.forEach((num) &#x3D;&gt; &#123; sum +&#x3D; num; &#125;); sum &#x3D;&#x3D;&#x3D; 15;","text":"数组拷贝 const itemsCopy &#x3D; [...items]; 取值方式 const [first, second] &#x3D; arr; 函数初始化 function f3(a) &#123; const b &#x3D; a || 1; &#x2F;&#x2F; ... &#125; function f4(a &#x3D; 1) &#123; &#x2F;&#x2F; ... &#125; 输出数组 const x &#x3D; [1, 2, 3, 4, 5]; console.log(...x); new Date(...[2016, 8, 5]); 数组遍历 let sum &#x3D; 0; numbers.forEach((num) &#x3D;&gt; &#123; sum +&#x3D; num; &#125;); sum &#x3D;&#x3D;&#x3D; 15;","categories":[],"tags":[]},{"title":"基础知识","slug":"common_knowledge","date":"2020-05-22T06:42:58.000Z","updated":"2022-09-09T08:23:21.944Z","comments":true,"path":"/post/common_knowledge.html","link":"","permalink":"http://zxtotti17.github.io/post/common_knowledge.html","excerpt":"异步：异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。 基本功能 进程管理进程控制、进程同步、进程通信、死锁处理、处理机调度等。 内存管理内存分配、地址映射、内存保护与共享、虚拟内存等。 文件管理文件存储空间的管理、目录管理、文件读写管理和保护等。 设备管理完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。 主要包括缓冲管理、设备分配、设备处理、虛拟设备等。 ps查看某个时间点的进程信息。 示例：查看自己的进程 ps -l示例：查看系统所有进程 ps aux示例：查看特定的进程 ps aux | grep threadxps aux | grep node 查看所有node进程 pstree查看进程树。 示例：查看所有进程树 pstree -A top实时显示进程信息。 示例：两秒钟刷新一次 top -d 2 netstat查看占用端口的进程 示例：查看特定端口的进程 netstat -anp | grep portlsof -i:42031实时读取文件 tail -fn 100 xxx.log kill杀进程kill 9 29876","text":"异步：异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。 基本功能 进程管理进程控制、进程同步、进程通信、死锁处理、处理机调度等。 内存管理内存分配、地址映射、内存保护与共享、虚拟内存等。 文件管理文件存储空间的管理、目录管理、文件读写管理和保护等。 设备管理完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。 主要包括缓冲管理、设备分配、设备处理、虛拟设备等。 ps查看某个时间点的进程信息。 示例：查看自己的进程 ps -l示例：查看系统所有进程 ps aux示例：查看特定的进程 ps aux | grep threadxps aux | grep node 查看所有node进程 pstree查看进程树。 示例：查看所有进程树 pstree -A top实时显示进程信息。 示例：两秒钟刷新一次 top -d 2 netstat查看占用端口的进程 示例：查看特定端口的进程 netstat -anp | grep portlsof -i:42031实时读取文件 tail -fn 100 xxx.log kill杀进程kill 9 29876 #计算机网络物理层、数据链路层、网络层、传输层、应用层物理层：单工通信：单向传输半双工通信：双向交替传输全双工通信：双向同时传输 数据链路层：模拟信号转换成数字信号，封装成帧等特点 网络层：IP协议 传输层：TCP/UDP协议 应用层：HTTP协议 长连接与短连接的理解：之所以网络上说HTTP分为长连接和短连接，其实本质上是说的TCP连接。TCP连接是一个双向dao的通道，它是可以保持一段时间不关闭的，因此TCP连接才有真正的长连接和短连接这一说。HTTP协议说到底是应用层的协议，而TCP才是真正的传输层协议，只有负责传输的这一层才需要建立连接。因此“HTTP连接”这一概念压根就不应该出现，HTTP只是一个应用层的协议，根本就没有连接这一说法，就像FTP协议一样，我们从来不会说“FTP连接”吧。归根到底，其实说的连接都是只传输层的TCP连接。相反说HTTP请求和HTTP响应反而更加准确一些都是通过TCP连接这个数据通道来传输请求和响应的。说到这里就彻底的改变了之前的错误认识，以后记住长连接，短连接都是指的传输层的TCP连接，而不是应用层的HTTP协议。HTTP的长连接和短连接本质上是TCP长连接和短连接。HTTP属于应用层协议，在传输层使用TCP协议，在网络层使用IP协议。IP协议主要解决网络路由和寻址问题，TCP协议主要解决如何在IP层之上可靠的传递数据包，使在网络上的另一端收到发端发出的所有包，并且顺序与发出顺序一致。TCP有可靠，面向连接的特点。现在的疑问既然说到了长连接，那么什么是长连接，短连接呢？HTTP1.1中又是如何实现长连接的呢？那么长短连接又分别有什么优缺点呢？正如我们学习一个新知识的时候，总是会问自己这三个问题一样：XXX是什么？XXX怎么用？XXX的好处？像我们一般的普通web应用，csdn写博客的平台，这种采用长连接有什么用呢？1，如何理解HTTP协议是无状态的HTTP协议是无状态的，指的是协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。也就是说，打开一个服务器上的网页和你之前打开这个服务器上的网页之间没有任何联系。HTTP是一个无状态的面向连接的协议，无状态不代表HTTP不能保持TCP连接，更不能代表HTTP使用的是UDP协议（无连接）。2，什么是长连接、短连接？在HTTP/1.0中，默认使用的是短连接。也就是说，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。如果客户端浏览器访问的某个HTML或其他类型的 Web页中包含有其他的Web资源，如JavaScript文件、图像文件、CSS文件等；当浏览器每遇到这样一个Web资源，就会建立一个HTTP会话。但从 HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头有加入这行代码：Connection:keep-alive 服务器和客户端都要设置在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的 TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接要客户端和服务端都支持长连接。HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。3，TCP连接当网络通信时采用TCP协议时，在真正的读写操作之前，server与client之间必须建立一个连接，当读写操作完成后，双方不再需要这个连接 时它们可以释放这个连接，连接的建立是需要三次握手的，而释放则需要4次握手，所以说每个连接的建立都是需要资源消耗和时间消耗的。经典的三次握手示意图：经典的四次分手关闭图：4，TCP短连接我们模拟一下TCP短连接的情况，client向server发起连接请求，server接到请求，然后双方建立连接。client向server发送消息，server回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close操作，不过一般都是client先发起close操作。为什么呢，一般的server不会回复完client后立即关闭连接的，当然不排除有特殊的情况。从上面的描述看，短连接一般只会在client/server间传递一次读写操作。短连接的操作步骤是：建立连接——数据传输——关闭连接…建立连接——数据传输——关闭连接5，TCP长连接接下来我们再模拟一下长连接的情况，client向server发起连接，server接受client连接，双方建立连接。Client与server完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。比如你请求了csdn的一个网页，这个网页里肯定还包含了CSS、JS等等一系列资源，如果你是短连接（也就是每次都要重新建立TCP连接）的话，那你每打开一个网页，基本要建立几个甚至几十个TCP连接，但如果是长连接的话，那么这么多次HTTP请求（这些请求包括请求网页内容，CSS文件，JS文件，图片等等），其实使用的都是一个TCP连接，很显然是可以节省很多消耗的。另外，最后关于长连接还要多提一句，那就是，长连接并不是永久连接的。如果一段时间内（具体的时间长短，是可以在header当中进行设置的，也就是所谓的超时时间），这个连接没有HTTP请求发出的话，那么这个长连接就会被断掉。这一点其实很容易理解，否则的话，TCP连接将会越来越多，直到把服务器的TCP连接数量撑爆到上限为止。现在想想，对于服务器来说，服务器里的这些个长连接其实很有数据库连接池的味道，大家都是为了节省连接重复利用嘛，对不对？长连接的操作步骤是：建立连接——数据传输…（保持连接）…数据传输——关闭连接","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[]},{"title":"游戏中的运营活动框架思路","slug":"game_run","date":"2019-11-22T08:15:07.000Z","updated":"2022-09-13T07:10:03.884Z","comments":true,"path":"/post/game_run.html","link":"","permalink":"http://zxtotti17.github.io/post/game_run.html","excerpt":"游戏的运营活动一般会有好多种类型，但是这些类型的功能一般是有共同和非共同的部分，这里记录一个对多类型运营活动的管理框架通过模板表录入运营活动的参数，包括跳转模块，开启方法，红点方法，等级等。如果有类似活动结束发奖的奖励表也可以用表来记录不同活动operation_id对应的奖励进行管理。!bg1.初始化玩家排行 init_sky_bless_rank() -&gt; List &#x3D; [PlayerSkyBless || PlayerSkyBless &lt;- get_all_player_st_sky_bless(), PlayerSkyBless #player_st_sky_bless.bless_times &gt; 0], SortFunction &#x3D; fun(A,B) -&gt; if A #player_st_sky_bless.bless_times &#x3D;:&#x3D; B #player_st_sky_bless.bless_times -&gt; A #player_st_sky_bless.last_time &#x3D;&lt; B #player_st_sky_bless.last_time; true -&gt; A #player_st_sky_bless.bless_times &gt; B #player_st_sky_bless.bless_times end end, SortList &#x3D; lists:sort(SortFunction,List), Num &#x3D; length(SortList), Tran &#x3D; fun() -&gt; if Num &gt; 0 -&gt; lists:foreach( fun(Seq) -&gt; PlayerSkyBless &#x3D; lists:nth(Seq,SortList), lib_ets:insert(sky_bless_player_ranking,#sky_lantern_bless_player_ranking&#123; player_id &#x3D; PlayerSkyBless #player_st_sky_bless.player_id,ranking &#x3D; Seq&#125;,replace), BlessRanking &#x3D; #sky_lantern_bless_ranking&#123; ranking &#x3D; Seq, player_id &#x3D; PlayerSkyBless #player_st_sky_bless.player_id, times &#x3D; PlayerSkyBless #player_st_sky_bless.bless_times, bless_time &#x3D; PlayerSkyBless #player_st_sky_bless.last_time &#125;, lib_ets:insert(sky_bless_ranking,BlessRanking,replace) end, lists:seq(1,Num) ); true -&gt; noop end end, game_db:do(Tran).","text":"游戏的运营活动一般会有好多种类型，但是这些类型的功能一般是有共同和非共同的部分，这里记录一个对多类型运营活动的管理框架通过模板表录入运营活动的参数，包括跳转模块，开启方法，红点方法，等级等。如果有类似活动结束发奖的奖励表也可以用表来记录不同活动operation_id对应的奖励进行管理。!bg1.初始化玩家排行 init_sky_bless_rank() -&gt; List &#x3D; [PlayerSkyBless || PlayerSkyBless &lt;- get_all_player_st_sky_bless(), PlayerSkyBless #player_st_sky_bless.bless_times &gt; 0], SortFunction &#x3D; fun(A,B) -&gt; if A #player_st_sky_bless.bless_times &#x3D;:&#x3D; B #player_st_sky_bless.bless_times -&gt; A #player_st_sky_bless.last_time &#x3D;&lt; B #player_st_sky_bless.last_time; true -&gt; A #player_st_sky_bless.bless_times &gt; B #player_st_sky_bless.bless_times end end, SortList &#x3D; lists:sort(SortFunction,List), Num &#x3D; length(SortList), Tran &#x3D; fun() -&gt; if Num &gt; 0 -&gt; lists:foreach( fun(Seq) -&gt; PlayerSkyBless &#x3D; lists:nth(Seq,SortList), lib_ets:insert(sky_bless_player_ranking,#sky_lantern_bless_player_ranking&#123; player_id &#x3D; PlayerSkyBless #player_st_sky_bless.player_id,ranking &#x3D; Seq&#125;,replace), BlessRanking &#x3D; #sky_lantern_bless_ranking&#123; ranking &#x3D; Seq, player_id &#x3D; PlayerSkyBless #player_st_sky_bless.player_id, times &#x3D; PlayerSkyBless #player_st_sky_bless.bless_times, bless_time &#x3D; PlayerSkyBless #player_st_sky_bless.last_time &#125;, lib_ets:insert(sky_bless_ranking,BlessRanking,replace) end, lists:seq(1,Num) ); true -&gt; noop end end, game_db:do(Tran). 2.处理玩家排行 deal_update_player_ranking(PlayerId) -&gt; PlayerSkyBless &#x3D; get_player_st_sky_bless(PlayerId), BlessTimes &#x3D; PlayerSkyBless #player_st_sky_bless.bless_times, BlessTime &#x3D; PlayerSkyBless #player_st_sky_bless.last_time, NowRanking &#x3D; get_sky_bless_player_ranking(PlayerId), Tran &#x3D; fun() -&gt; if NowRanking &#x3D;&#x3D; 0 -&gt; Len &#x3D; length(get_all_sky_bless_ranking()), NewRanking &#x3D; #sky_lantern_bless_ranking&#123; ranking &#x3D; Len + 1, player_id &#x3D; PlayerId, times &#x3D; BlessTimes, bless_time &#x3D; BlessTime &#125;, lib_ets:insert(sky_bless_ranking,NewRanking,replace), lib_ets:insert(sky_bless_player_ranking,#sky_lantern_bless_player_ranking&#123; player_id &#x3D; PlayerId,ranking &#x3D; Len + 1&#125;,replace), ranking_sort(PlayerId,BlessTimes,BlessTime,Len); true -&gt; lib_ets:update(sky_bless_ranking,NowRanking,[&#123;#sky_lantern_bless_ranking.times,BlessTimes&#125;, &#123;#sky_lantern_bless_ranking.bless_time,BlessTime&#125;]), ranking_sort(PlayerId,BlessTimes,BlessTime,NowRanking - 1) end end, game_db:do(Tran). ranking_sort(_,_,_,0) -&gt; noop; ranking_sort(PlayerId,BlessTimes,Time,Ranking) -&gt; BlessRanking &#x3D; get_sky_bless_ranking(Ranking), case sort(BlessTimes,Time,BlessRanking #sky_lantern_bless_ranking.times,BlessRanking #sky_lantern_bless_ranking.bless_time) of true -&gt; NewRanking &#x3D; #sky_lantern_bless_ranking&#123; ranking &#x3D; Ranking, player_id &#x3D; PlayerId, times &#x3D; BlessTimes, bless_time &#x3D; Time &#125;, ARanking &#x3D; #sky_lantern_bless_ranking&#123; ranking &#x3D; Ranking + 1, player_id &#x3D; BlessRanking #sky_lantern_bless_ranking.player_id, times &#x3D; BlessRanking #sky_lantern_bless_ranking.times, bless_time &#x3D; BlessRanking #sky_lantern_bless_ranking.bless_time &#125;, lib_ets:insert(sky_bless_player_ranking,#sky_lantern_bless_player_ranking&#123; player_id &#x3D; BlessRanking #sky_lantern_bless_ranking.player_id,ranking &#x3D; Ranking + 1&#125;,replace), lib_ets:insert(sky_bless_player_ranking,#sky_lantern_bless_player_ranking&#123; player_id &#x3D; PlayerId,ranking &#x3D; Ranking&#125;,replace), lib_ets:insert(sky_bless_ranking,NewRanking,replace), lib_ets:insert(sky_bless_ranking,ARanking,replace), ranking_sort(PlayerId,BlessTimes,Time,Ranking - 1); false -&gt; noop end. 3.通过公共管理进程对活动进行管理发奖及消息通知 handle_cast(&#123;async_send&#125;, &#123;true,State&#125;) -&gt; catch api_st_sky_bless:timer_notify(State), start_timer(1), &#123;noreply, &#123;true,[]&#125;&#125;; handle_cast(&#123;activity_stop&#125;,State) -&gt; mod_st_sky_bless:give_award(), &#123;noreply,State&#125;;","categories":[{"name":"设计方法","slug":"设计方法","permalink":"http://zxtotti17.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"http://zxtotti17.github.io/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"游戏全局通知红点系统","slug":"game_red","date":"2019-08-23T09:44:00.000Z","updated":"2022-09-13T07:10:24.671Z","comments":true,"path":"/post/game_red.html","link":"","permalink":"http://zxtotti17.github.io/post/game_red.html","excerpt":"","text":"红点功能贯穿游戏所有功能，像是一个全局的通知，用一个配置表记录所有游戏功能及入口和红点、开启的方法名加载进内存!Red15669620461084主入口界面时候调用取得已开启的功能列表mod_function:get_all_game_function() 构造成带父子关系的功能列表 &#123;Id,[&#123;GameFunction #game_function.id&#125;|List1]&#125; | lists:delete(&#123;Id,List1&#125;,L) 通过核心回调到所有模块的红点方法 IsRed &#x3D; if Mod &#x3D;&#x2F;&#x3D; &#39;&#39;, Func &#x3D;&#x2F;&#x3D; &#39;&#39; -&gt; try erlang:apply(Mod,Func,[PlayerId]) of Result -&gt; Result catch _ : _ -&gt; false end; true -&gt; false end, 最后将缓存中的玩家红点数据替换 lib_ets:delete(player_red, PlayerId), lib_ets:insert( player_red, #player_red&#123; player_id &#x3D; PlayerId, red_list &#x3D; N &#125;, replace ), 不同的功能触发红点改变需要有个打点的函数,在功能需要改变红点状态的时候通知进来更新缓存 notify_game_function_is_red (PlayerId,FunctionId) -&gt; case mod_function:check_lock(PlayerId,FunctionId) of false -&gt; noop; _ -&gt; GameFunction &#x3D; code_db:get(game_function,[FunctionId]), Mod &#x3D; list_to_atom(GameFunction #game_function.red_mod), Func &#x3D; list_to_atom(GameFunction #game_function.red_func), IsRed &#x3D; if Mod &#x3D;&#x2F;&#x3D; &#39;&#39;, Func &#x3D;&#x2F;&#x3D; &#39;&#39; -&gt; try erlang:apply(Mod,Func,[PlayerId]) of Result -&gt; Result catch _ : _ -&gt; false end; true -&gt; false end, if GameFunction #game_function.relation &gt; 0 -&gt; notify_relation_game_function_is_red(PlayerId,GameFunction #game_function.relation,FunctionId,IsRed);%通知父类联动的函数 true -&gt; update_game_function_cache(PlayerId,FunctionId,IsRed) end end.","categories":[{"name":"设计方法","slug":"设计方法","permalink":"http://zxtotti17.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"http://zxtotti17.github.io/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"Redis笔记","slug":"redis笔记","date":"2019-08-01T08:52:31.000Z","updated":"2022-09-09T08:23:02.527Z","comments":true,"path":"/post/redis笔记.html","link":"","permalink":"http://zxtotti17.github.io/post/redis%E7%AC%94%E8%AE%B0.html","excerpt":"Redis是什么、特点、优势redis是Key-Value数据库,数据包含各种数据 字符串String、字典Hash、列表List、集合Set、有序集合SortedSet等redis支持数据持久化，重启再次加载,支持数据备份(支持分布式),Redis是单进程单线程的Redis的优势性能高 读速度110000/s 写速度81000/s丰富的数据类型 redis安装（Linux）、启动、退出、设置密码、远程连接 1 安装redis下载redis安装包（如：redis-2.8.17.tar.gz）cd redis-5.0.5makesrc/redis-server 也可改配置redis.conf 并修改 daemonize no 为 daemonize yes 启动服务端redis-server /usr/local/redis-5.0.5/redis.confsrc/redis-cli 启动客户端src/redis-cli shutdown 停止服务 tar -zxvf redis-2.8.17.tar.gz cd redis-2.8.17 make sudo make install 2 后台启动服务端 nohup redis-server &amp; 3 启动客户端、验证 cd &#x2F;usr&#x2F;local&#x2F;bin redis-cli set var &quot;hello world&quot; get var","text":"Redis是什么、特点、优势redis是Key-Value数据库,数据包含各种数据 字符串String、字典Hash、列表List、集合Set、有序集合SortedSet等redis支持数据持久化，重启再次加载,支持数据备份(支持分布式),Redis是单进程单线程的Redis的优势性能高 读速度110000/s 写速度81000/s丰富的数据类型 redis安装（Linux）、启动、退出、设置密码、远程连接 1 安装redis下载redis安装包（如：redis-2.8.17.tar.gz）cd redis-5.0.5makesrc/redis-server 也可改配置redis.conf 并修改 daemonize no 为 daemonize yes 启动服务端redis-server /usr/local/redis-5.0.5/redis.confsrc/redis-cli 启动客户端src/redis-cli shutdown 停止服务 tar -zxvf redis-2.8.17.tar.gz cd redis-2.8.17 make sudo make install 2 后台启动服务端 nohup redis-server &amp; 3 启动客户端、验证 cd &#x2F;usr&#x2F;local&#x2F;bin redis-cli set var &quot;hello world&quot; get var Reis key序号 Redis keys命令及描述1 DEL key该命令用于在 key 存在是删除 key。2 DUMP key序列化给定 key ，并返回被序列化的值。3 EXISTS key检查给定 key 是否存在。4 EXPIRE key seconds为给定 key 设置过期时间。5 EXPIREAT key timestampEXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。6 PEXPIRE key milliseconds设置 key 的过期时间亿以毫秒计。7 PEXPIREAT key milliseconds-timestamp设置 key 过期时间的时间戳(unix timestamp) 以毫秒计8 KEYS pattern查找所有符合给定模式( pattern)的 key 。例如keys * 返回所有的key9 MOVE key db将当前数据库的 key 移动到给定的数据库 db 当中。10 PERSIST key移除 key 的过期时间，key 将持久保持。11 PTTL key以毫秒为单位返回 key 的剩余的过期时间。12 TTL key以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。13 RANDOMKEY从当前数据库中随机返回一个 key 。14 RENAME key newkey修改 key 的名称15 RENAMENX key newkey仅当 newkey 不存在时，将 key 改名为 newkey 。16 TYPE key返回 key 所储存的值的类型。…中文文档 Redis 发布订阅占时没用过，看起来跟微信公众号一样,Pub/Sub做延时队列可以用在玩家登录排队上 Redis事务一个事务从开始到结束经过以下三个阶段： 开始事务命令入队执行事务例子 localhost:6379&gt; MULTI OK localhost:6379&gt; set name jihite QUEUED localhost:6379&gt; get name QUEUED localhost:6379&gt; sadd language &quot;c++&quot; &quot;python&quot; &quot;java&quot; QUEUED localhost:6379&gt; smembers language QUEUED localhost:6379&gt; exec 说明：事务以MULTI开始，以EXEC结束 关闭持久化与持久化(RDB)bgsave做镜像全量持久化，aof做增量持久化RDB相当于快照，是fork一个子进程，快照成功后替换aof相当于日志，cow，copy and write,一条一条的数据 这是redis与其他缓存服务的比较明显的特点,如memcache修改配置文件，改完后重启。 #save 900 1 #save 300 10 #save 60 10000 或执行操作命令 CONFIG SET save &quot;&quot; redis相比memcached有哪些优势？ (1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型(2) redis的速度比memcached快很多(3) redis可以持久化其数据 redis常见性能问题和解决方案： (1) Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件(2) 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次(3) 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内(4) 尽量避免在压力很大的主库上增加从库(5) 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3… 这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。 Redis 常见的性能问题都有哪些？如何解决？1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。4). Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内 Redis分布式锁拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。 Redis做异步队列一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。 Hash结构原子性操作Redis中提供了原子性命令SETEX或SET来写入STRING类型数据并设置Key的过期时间： SET key value EX 60 NX ok &gt; SETEX key 60 value ok 但对于HASH结构则没有这样的命令，只能先写入数据然后设置过期时间： HSET key field value ok &gt; EXPIRE key 60 ok 这样就带了一个问题：HSET命令执行成功而EXPIRE命令执行失败（如命令未能成功发送到Redis服务器），那么数据将不会过期。推荐2种解决方式 一.LUA脚本形式 脚本部分的lua代码如下 local fieldIndex&#x3D;3 local valueIndex&#x3D;4 local key&#x3D;KEYS[1] local fieldCount&#x3D;ARGV[1] local expired&#x3D;ARGV[2] for i&#x3D;1,fieldCount,1 do redis.pcall(&#39;HSET&#39;,key,ARGV[fieldIndex],ARGV[valueIndex]) fieldIndex&#x3D;fieldIndex+2 valueIndex&#x3D;valueIndex+2 end redis.pcall(&#39;EXPIRE&#39;,key,expired) 具体可以根据需求改造 一般有2种形式 1).eval 立即执行一段lua脚本代码，redisAPI函数有两个参数，第一个是lua脚本的字符串，第二个是对应脚本参数数组项目中具体使用如下 &#x2F;** * hash原子批量操作 * count 插入多少条数据 * time 过期时间 * data 数据key - value *&#x2F; public async setOrAddList(databaseId: string, rowKey:string, count:number, time:number, data: any, flag?: QueryFlag): Promise&lt;boolean&gt; &#123; rowKey &#x3D; this.getRowKey(rowKey); let redisDb: Database &#x3D; this.service.connect(databaseId); let dispatch &#x3D; redisDb.dispatch(flag); let client &#x3D; dispatch.adapter; let arr &#x3D; []; arr.push(CommandMode.Key);&#x2F;&#x2F;key 标识1 arr.push(rowKey); arr.push(count); arr.push(time); for(let k in data)&#123; arr.push(k); arr.push(data[k]); &#125; let luaStr &#x3D; &quot;local fieldIndex&#x3D;3;local valueIndex&#x3D;4;local key&#x3D;KEYS[1];local fieldCount&#x3D;ARGV[1];local expired&#x3D;ARGV[2];for i&#x3D;1,fieldCount,1 do redis.pcall(&#39;HSET&#39;,key,ARGV[fieldIndex],ARGV[valueIndex]) fieldIndex&#x3D;fieldIndex+2 valueIndex&#x3D;valueIndex+2 end;redis.pcall(&#39;EXPIRE&#39;,key,expired);&quot; let result &#x3D; await client.EVAL(luaStr, arr); if(!result)&#123; logger.error(&#39;setOrAddList rowKey:%s count:%s&#39;, rowKey, count) &#125; return result &#125; 2). evalsha 这个先将lua脚本加载内存中得到一串文件码字符串，在通过字符串读取及传参 SCRIPT LOAD &quot;local fieldIndex&#x3D;3;local valueIndex&#x3D;4;local key&#x3D;KEYS[1];local fieldCount&#x3D;ARGV[1];local expired&#x3D;ARGV[2];for i&#x3D;1,fieldCount,1 do redis.pcall(&#39;HSET&#39;,key,ARGV[fieldIndex],ARGV[valueIndex]) fieldIndex&#x3D;fieldIndex+2 valueIndex&#x3D;valueIndex+2 end;redis.pcall(&#39;EXPIRE&#39;,key,expired);&quot; &quot;e03e7868920b7669d1c8c8b16dcee86ebfac650d&quot; &gt; evalsha e03e7868920b7669d1c8c8b16dcee86ebfac650d 1 key 2 1000 field1 value1 field2 value2 二：事务Redis命令只会在有语法错误或对Key使用了错误的数据类型时执行失败。因此，只要我们保证将正确的写数据和设置过期时间的命令作为一个整体发送到服务器端即可，使用Lua脚本正式基于此。 public async Task&lt;bool&gt; WriteAsync(string key, IDictionary&lt;string, string&gt; valueDict, TimeSpan expiry) &#123; var tranc &#x3D; Database.CreateTransaction(); foreach (var item in valueDict) &#123; tranc.HashSetAsync(key, item.Key, item.Value); &#125; tranc.KeyExpireAsync(key, expiry); return await tranc.ExecuteAsync(); &#125;","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://zxtotti17.github.io/tags/redis/"}]},{"title":"游戏中大型自动比赛玩法设计","slug":"game_bigmatch","date":"2019-07-30T08:08:45.000Z","updated":"2022-09-13T07:09:16.476Z","comments":true,"path":"/post/game_bigmatch.html","link":"","permalink":"http://zxtotti17.github.io/post/game_bigmatch.html","excerpt":"争霸赛赛程范例3月1日 0：00~3月3日 12:00 报名 40级以上手动报名3月3日 13：00 淘汰赛 “13:00取数据，提前1小时向玩家发送邮件提醒13:10开始出战报，每隔5分钟出1场战报天榜负5局进入地榜，地榜负5局则被淘汰”3月4日 14:00 16强赛（32进16） “每小时1局，每局取1次数据，5局3胜制天地榜同时进行比赛开始前1小时向玩家发送邮件提醒取数据制度”3月5日 14:00 16进83月6日 14:00 8进43月7日 14:00 半决赛3月8日 14:00 决赛3月8日 决赛全部结束 统一发放奖励 比赛的时间控制由单独时间进程来控制时间的推进，相当于php中的crontab,表结构上一个玩家比赛进程表player_race,一个各阶段玩家成员信息表player_race_member，后期系统匹配各阶段玩家匹配信息表player_race_opponent，一个各阶段玩家战报信息表player_race_report，一个各阶段玩家结果表player_race_result，玩家表可以分为 玩家比赛信息表 player_st_jjc_race 玩家匹配信息表 player_st_jjc_race_opponent 玩家日志表 player_st_jjc_race_score_log 第一步 报名很简单直接报名请求记录玩家数据就行,报名时间结束时触发事件对所有玩家进行匹配 case try_get_player_server_war(PlayerId) of null -&gt; Tran &#x3D; fun() -&gt; game_db:write(#player_server_war &#123; player_id &#x3D; PlayerId, apply_time &#x3D; lib_misc:get_local_timestamp() &#125;) % mod_deploy:get(PlayerId, ?RACE_SERVER_WAR) end, game_db:do(Tran); _ -&gt; exit(already_apply) end. % 本服报名结束手机玩家数据 apply_over() -&gt; List &#x3D; get_all_player_server_war(), Tran &#x3D; fun() -&gt; lists:foreach( fun(Rec) -&gt; game_db:write(Rec #player_server_war &#123; race_step &#x3D; ?RS_TIAN_BANG_TAOTAI &#125;) end, List ) end, game_db:do(Tran), ?INFO(&quot;apply_over&quot;,[]), ZoneList &#x3D; lists:foldl( fun(PlayerServerWar, R) -&gt; [PlayerServerWar #player_server_war.player_id | R] end, [], get_all_player_server_war() ), mod_race:init_race_member( ?RACE_SERVER_WAR, 0, ?RS_TIAN_BANG_TAOTAI, 0, ZoneList, normal ). 注意的是用一个单独的进程来管理活动步骤开启结束!Er15646489002180","text":"争霸赛赛程范例3月1日 0：00~3月3日 12:00 报名 40级以上手动报名3月3日 13：00 淘汰赛 “13:00取数据，提前1小时向玩家发送邮件提醒13:10开始出战报，每隔5分钟出1场战报天榜负5局进入地榜，地榜负5局则被淘汰”3月4日 14:00 16强赛（32进16） “每小时1局，每局取1次数据，5局3胜制天地榜同时进行比赛开始前1小时向玩家发送邮件提醒取数据制度”3月5日 14:00 16进83月6日 14:00 8进43月7日 14:00 半决赛3月8日 14:00 决赛3月8日 决赛全部结束 统一发放奖励 比赛的时间控制由单独时间进程来控制时间的推进，相当于php中的crontab,表结构上一个玩家比赛进程表player_race,一个各阶段玩家成员信息表player_race_member，后期系统匹配各阶段玩家匹配信息表player_race_opponent，一个各阶段玩家战报信息表player_race_report，一个各阶段玩家结果表player_race_result，玩家表可以分为 玩家比赛信息表 player_st_jjc_race 玩家匹配信息表 player_st_jjc_race_opponent 玩家日志表 player_st_jjc_race_score_log 第一步 报名很简单直接报名请求记录玩家数据就行,报名时间结束时触发事件对所有玩家进行匹配 case try_get_player_server_war(PlayerId) of null -&gt; Tran &#x3D; fun() -&gt; game_db:write(#player_server_war &#123; player_id &#x3D; PlayerId, apply_time &#x3D; lib_misc:get_local_timestamp() &#125;) % mod_deploy:get(PlayerId, ?RACE_SERVER_WAR) end, game_db:do(Tran); _ -&gt; exit(already_apply) end. % 本服报名结束手机玩家数据 apply_over() -&gt; List &#x3D; get_all_player_server_war(), Tran &#x3D; fun() -&gt; lists:foreach( fun(Rec) -&gt; game_db:write(Rec #player_server_war &#123; race_step &#x3D; ?RS_TIAN_BANG_TAOTAI &#125;) end, List ) end, game_db:do(Tran), ?INFO(&quot;apply_over&quot;,[]), ZoneList &#x3D; lists:foldl( fun(PlayerServerWar, R) -&gt; [PlayerServerWar #player_server_war.player_id | R] end, [], get_all_player_server_war() ), mod_race:init_race_member( ?RACE_SERVER_WAR, 0, ?RS_TIAN_BANG_TAOTAI, 0, ZoneList, normal ). 注意的是用一个单独的进程来管理活动步骤开启结束!Er15646489002180 % 每一个活动开始所要做的处理 activity_start (ActivityId) -&gt; case mod_server:is_game_server() of true -&gt; xdh_race_srv:activity_start(ActivityId); false -&gt; case mod_server:is_cc_server() of true -&gt; % cc_server_war_cron_srv:activity_start(Id); noop; false -&gt; noop end end. % 每一个活动结束所要做的处理 activity_stop (ActivityId) -&gt; case mod_server:is_game_server() of true -&gt; xdh_race_srv:activity_stop(ActivityId); false -&gt; case mod_server:is_cc_server() of true -&gt; % cc_server_war_cron_srv:activity_stop(Id); noop; false -&gt; noop end end. 在到点时间的相应上做特殊处理 第二步 开启淘汰赛淘汰赛的开启同样用时间进程来控制，到点后调用启动方法!Er15646493808263 （判断结束 、清上一轮数据）淘汰赛相当于一个递归的过程，全服玩家进行了一场比赛后记录玩家信息及淘汰结果直到淘汰赛结束的条件,同时需要一个全服步骤数据记录，然后循环比赛其中每一轮淘汰赛可分为 判断结束 、清上一轮数据 、不重复随机匹配 、 战斗及数据记录 、 循环!Er15647109579023 （不重复随机匹配 循环） &lt;!-- 战斗部分及记录 --&gt; race_fight (RaceId, ZoneId, RaceStep, TeamIdA, TeamIdB) -&gt; #player_race &#123; race_times &#x3D; RaceTimes &#125; &#x3D; get_player_race(RaceId, ZoneId), Tran &#x3D; fun() -&gt; case race_call(RaceId, fight, [RaceStep, TeamIdA, TeamIdB]) of [] -&gt; exit(&#123;invalid_fight, RaceId, TeamIdA, TeamIdB&#125;); ReportList -&gt; &#123;_, WinTeamId&#125; &#x3D; lists:foldr( fun(Report, &#123;NowIndex, NowWinTeamId&#125;) -&gt; #war_result &#123; winner &#x3D; &#123;_, WinnerId&#125;, army_result1 &#x3D; #army_result &#123; army_key &#x3D; &#123;_, PlayerIdA&#125; &#125;, army_result2 &#x3D; #army_result &#123; army_key &#x3D; &#123;_, PlayerIdB&#125; &#125; &#125; &#x3D; Report, NewWinTeamId &#x3D; if NowIndex &#x3D;:&#x3D; length(ReportList) -&gt; WinTeamId &#x3D; if WinnerId &#x3D;:&#x3D; PlayerIdA -&gt; TeamIdA; true -&gt; TeamIdB end, game_db:write(#player_race_result &#123; race_id &#x3D; RaceId, zone_id &#x3D; ZoneId, race_step &#x3D; RaceStep, player_id &#x3D; TeamIdA, player_id1 &#x3D; TeamIdB, race_times &#x3D; RaceTimes, version &#x3D; ?GET_ENV(vsn, &quot;&quot;), report_time &#x3D; lib_misc:get_local_timestamp(), winner_id &#x3D; WinTeamId &#125;), WinTeamId; true -&gt; NowWinTeamId end, game_db:write(#player_race_report &#123; race_id &#x3D; RaceId, zone_id &#x3D; ZoneId, race_step &#x3D; RaceStep, player_id &#x3D; TeamIdA, race_times &#x3D; RaceTimes, index &#x3D; NowIndex, attacker_id &#x3D; PlayerIdA, defender_id &#x3D; PlayerIdB, winner_id &#x3D; WinnerId, report_id &#x3D; war_report_srv:record_war_report(Report, 30 * 86400) &#125;), &#123; NowIndex - 1, NewWinTeamId &#125; end, &#123;length(ReportList), 0&#125;, ReportList ), WinTeamId end end, &#123;atomic, TeamId&#125; &#x3D; game_db:do(Tran), TeamId. 在淘汰赛结束后，将剩余晋级玩家进入晋级赛步骤，同时初始化随机匹配!Er15647120482687一下两种匹配方式 init_race_member(RaceId, ZoneId, RaceStep, Group, TeamIdList, normal) -&gt; Tran &#x3D; fun() -&gt; lists:foldl( fun(TeamId, NowIndex) -&gt; game_db:write(#player_race_member &#123; race_id &#x3D; RaceId, race_step &#x3D; RaceStep, zone_id &#x3D; ZoneId, group &#x3D; Group, index &#x3D; NowIndex, player_id &#x3D; TeamId &#125;), NowIndex + 1 end, 1, TeamIdList ) end, game_db:do(Tran); init_race_member(RaceId, ZoneId, RaceStep, Group, TeamIdList, random) -&gt; #race_step &#123; match_num &#x3D; MatchNum &#125; &#x3D; get_race_step(RaceStep), Step &#x3D; get_index_step(length(TeamIdList), MatchNum), Tran &#x3D; fun() -&gt; lists:foldl( fun(TeamId, NowIndex) -&gt; game_db:write(#player_race_member &#123; race_id &#x3D; RaceId, race_step &#x3D; RaceStep, zone_id &#x3D; ZoneId, group &#x3D; Group, index &#x3D; NowIndex, player_id &#x3D; TeamId &#125;), if NowIndex + Step &gt; MatchNum * 2 -&gt; 1 + Step div 2; true -&gt; NowIndex + Step end end, 1, lib_misc:shuffle(TeamIdList) ) end, game_db:do(Tran); 第三步 战报战报开启也是进程时间来控制!Er15647145661718 第四步 开启晋级赛同样是进程计时器开启，比赛流程除了一局定输赢以外和淘汰赛基本一致，比赛也是一次性打完，战报根据时间慢慢的播放 % 开启杯赛 timer_start_race() -&gt; case mod_server:is_cc_server() of true -&gt; % cc_server_war_cron_srv:start_race(0); noop; false -&gt; Times &#x3D; mod_server:get_player_server_int_data(?SDT_SERVER_WAR_RACE_TIMES), xdh_race_srv:try_apply(mod_server,set_player_server_int_data,[?SDT_SERVER_WAR_RACE_TIMES,Times + 1]), start_race(), mod_timer:reset(1, ?TIMER_XIAN_DAO_HUI_BEI_SAI) end. start_race() -&gt; RaceStep &#x3D; get_server_war_race_step(), PlayerRace &#x3D; mod_race:get_player_race(?RACE_SERVER_WAR,0), IsOver &#x3D; case mod_race:start_race(?RACE_SERVER_WAR, 0, RaceStep, 3) of true -&gt; true; _ -&gt; mod_timer:reset(0, ?TIMER_XIAN_DAO_HUI_BEI_SAI, 3420), false end, RaceTimes &#x3D; if RaceStep &#x3D;&#x2F;&#x3D; PlayerRace #player_race.race_step -&gt; 1; true -&gt; PlayerRace #player_race.race_times + 1 end, xdh_race_srv:try_apply(mod_server,set_player_server_int_data,[?SDT_SERVER_WAR_RACE_TIMES,RaceTimes]), deal_receive_beisai_data(RaceStep,IsOver). 战斗部分基本一致多一个匹配结果记录表 start_race(RaceId, ZoneId, RaceStep, WinTimes) -&gt; #race_step &#123; match_num &#x3D; MatchNum, next_race &#x3D; NextRace, next_step &#x3D; NextStep &#125; &#x3D; get_race_step(RaceStep), Tran &#x3D; fun() -&gt; PlayerRace &#x3D; get_player_race(RaceId, ZoneId), if PlayerRace #player_race.race_step &#x3D;:&#x3D; RaceStep, PlayerRace #player_race.race_times &#x3D;&#x2F;&#x3D; 0 -&gt; case check_race_over(RaceId, ZoneId, RaceStep) of true -&gt; exit(race_over); _ -&gt; noop end, game_db:write(PlayerRace #player_race &#123; race_times &#x3D; PlayerRace #player_race.race_times + 1, last_time &#x3D; lib_misc:get_local_timestamp() &#125;); true -&gt; clear_race_data(RaceId, ZoneId, RaceStep), init_race_opponent(RaceId, ZoneId, RaceStep), game_db:write(PlayerRace #player_race &#123; race_step &#x3D; RaceStep, race_times &#x3D; 1, last_time &#x3D; lib_misc:get_local_timestamp(), win_times &#x3D; WinTimes &#125;) end, lists:foreach( fun(Group) -&gt; lists:foreach( fun(Index) -&gt; RaceMemberA &#x3D; try_get_player_race_member(RaceId, ZoneId, RaceStep, Group, Index * 2 - 1), RaceMemberB &#x3D; try_get_player_race_member(RaceId, ZoneId, RaceStep, Group, Index * 2), if RaceMemberA &#x3D;:&#x3D; null, RaceMemberB &#x3D;:&#x3D; null -&gt; noop; %%轮空为全空或者B为空 % RaceMemberA &#x3D;:&#x3D; null -&gt; % game_db:write(#player_race_member &#123; % race_id &#x3D; RaceId, % race_step &#x3D; NextRace, % group &#x3D; Group, % index &#x3D; Index, % player_id &#x3D; RaceMemberB #player_race_member.player_id % &#125;); RaceMemberB &#x3D;:&#x3D; null -&gt; TeamIdA &#x3D; RaceMemberA #player_race_member.player_id, case check_opponent_over(RaceId, ZoneId, RaceStep, TeamIdA) of true -&gt; noop; _ -&gt; Opponent &#x3D; try_get_player_race_opponent(RaceId, ZoneId, RaceStep, TeamIdA), game_db:write(Opponent #player_race_opponent &#123; winner_id &#x3D; TeamIdA &#125;), game_db:write(#player_race_member &#123; race_id &#x3D; RaceId, zone_id &#x3D; ZoneId, race_step &#x3D; NextRace, group &#x3D; Group, index &#x3D; Index, player_id &#x3D; TeamIdA &#125;), race_call(RaceId, race_win, [TeamIdA, Group, RaceStep, NextRace]) end; true -&gt; TeamIdA &#x3D; RaceMemberA #player_race_member.player_id, TeamIdB &#x3D; RaceMemberB #player_race_member.player_id, case check_opponent_over(RaceId, ZoneId, RaceStep, TeamIdA) of true -&gt; noop; _ -&gt; case race_fight(RaceId, ZoneId, RaceStep, TeamIdA, TeamIdB) of 0 -&gt; noop; WinnerId -&gt; case check_opponent_over(RaceId, ZoneId, RaceStep, TeamIdA, TeamIdB) of true -&gt; Opponent &#x3D; try_get_player_race_opponent(RaceId, ZoneId, RaceStep, TeamIdA), game_db:write(Opponent #player_race_opponent &#123; winner_id &#x3D; WinnerId &#125;), game_db:write(#player_race_member &#123; race_id &#x3D; RaceId, zone_id &#x3D; ZoneId, race_step &#x3D; NextRace, group &#x3D; Group, index &#x3D; Index, player_id &#x3D; WinnerId &#125;), race_call(RaceId, race_win, [WinnerId, Group, RaceStep, NextRace]); _ -&gt; noop end end end end end, lists:seq(1, MatchNum) ) end, get_all_race_group() ), IsOver &#x3D; check_race_over(RaceId, ZoneId, RaceStep), if IsOver &#x3D;:&#x3D; true -&gt; NowPlayerRace &#x3D; get_player_race(RaceId, ZoneId), game_db:write(NowPlayerRace #player_race &#123; race_step &#x3D; NextStep, race_times &#x3D; 0, last_time &#x3D; lib_misc:get_local_timestamp() &#125;); true -&gt; noop end, IsOver end, &#123;atomic, Result&#125; &#x3D; game_db:do(Tran), Result. 第五步 出晋级赛战报 % 播报战报及通知 deal_receive_beisai_data(RaceStep,IsOver) -&gt; Tran &#x3D; fun() -&gt; % write_race_data(RaceReportList,RaceResultList,MemberList,OpponentList, WorldWarList), if IsOver &#x3D;:&#x3D; true -&gt; #race_step &#123; next_step &#x3D; NextStep &#125; &#x3D; mod_race:get_race_step(RaceStep), % return_bet(RaceStep), if RaceStep &#x3D;:&#x3D; ?RS_RACE_1 -&gt; % give_award(),给予奖励 ZoneId &#x3D; 0, case mod_race:try_get_player_race_member(?RACE_SERVER_WAR, ZoneId, ?RS_RACE_1_OVER, ?RG_TIAN_BANG, 1) of null -&gt; noop; Member -&gt; ServerId &#x3D; mod_player:get_player_data(Member #player_race_member.player_id,server_id), ServerName &#x3D; mod_server:get_server_name(ServerId), NickName &#x3D; mod_player:get_player_data(Member #player_race_member.player_id,nickname), api_chat:centre_screen_message_notify( ?MEST_XIAN_DAO_HUI_GUAN_JUN, [&#123;ServerName&#125;,&#123;NickName&#125;] ) end; true -&gt; noop end, mod_server:set_player_server_int_data(?SDT_SERVER_WAR_RACE_STEP, NextStep), mod_server:set_player_server_int_data(?SDT_SERVER_WAR_RACE_TIMES, 0), mod_timer:close(1,?TIMER_XIAN_DAO_HUI_BEI_SAI); true -&gt; noop end end, game_db:do(Tran). % api_server_war:notify_new_report().","categories":[{"name":"设计方法","slug":"设计方法","permalink":"http://zxtotti17.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"http://zxtotti17.github.io/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"Erlang List模块函数使用大全","slug":"Erlang List模块函数使用大全","date":"2019-05-07T11:49:16.000Z","updated":"2022-09-09T07:59:22.031Z","comments":true,"path":"/post/Erlang List模块函数使用大全.html","link":"","permalink":"http://zxtotti17.github.io/post/Erlang%20List%E6%A8%A1%E5%9D%97%E5%87%BD%E6%95%B0%E4%BD%BF%E7%94%A8%E5%A4%A7%E5%85%A8.html","excerpt":"Erlang List模块函数使用大全 一，带函数Pred1, all(Pred, List) -&gt; boolean()如果List中的每个元素作为Pred函数的参数执行，结果都返回true，那么all函数返回true，否则返回false 例子： lists:all(fun(E) -&gt; true end,[1,2,3,4]). 结果 true 2, any(Pred, List) -&gt; boolean()如果List中至少有一个元素作为Pred函数的参数执行，结果返回true，那么any函数返回true，否则返回false 例子 lists:any(fun(E) -&gt; is_integer(E) end,[q,2,a,4]). 结果 true 3，dropwhile(Pred, List1) -&gt; List2将List1列表中的元素作为参数执行Pred函数，如果返回true，将其丢弃，最后返回剩余元素组成的列表 例子 lists:dropwhile(fun(E) -&gt; is_atom(E) end,[a,1,2,a,b]). 结果 [1,2,a,b] 4，filter(Pred, List1) -&gt; List2返回一个列表，这个列表是由List1中执行Pred函数返回true的元素组成。 lists:filter(fun(E) -&gt; is_integer(E) end,[q,2,a,4]). 结果： [2,4]","text":"Erlang List模块函数使用大全 一，带函数Pred1, all(Pred, List) -&gt; boolean()如果List中的每个元素作为Pred函数的参数执行，结果都返回true，那么all函数返回true，否则返回false 例子： lists:all(fun(E) -&gt; true end,[1,2,3,4]). 结果 true 2, any(Pred, List) -&gt; boolean()如果List中至少有一个元素作为Pred函数的参数执行，结果返回true，那么any函数返回true，否则返回false 例子 lists:any(fun(E) -&gt; is_integer(E) end,[q,2,a,4]). 结果 true 3，dropwhile(Pred, List1) -&gt; List2将List1列表中的元素作为参数执行Pred函数，如果返回true，将其丢弃，最后返回剩余元素组成的列表 例子 lists:dropwhile(fun(E) -&gt; is_atom(E) end,[a,1,2,a,b]). 结果 [1,2,a,b] 4，filter(Pred, List1) -&gt; List2返回一个列表，这个列表是由List1中执行Pred函数返回true的元素组成。 lists:filter(fun(E) -&gt; is_integer(E) end,[q,2,a,4]). 结果： [2,4] 5，map(Fun, List1) -&gt; List2将List1中的每个元素去在Fun中执行，然后返回一个元素，最后返回的这些元素组成一个列表，返回给List2例子：lists:map(fun(X)-&gt;[X,X] end, [a,b,c]).结果：[[a,a],[b,b],[c,c]] 6，flatmap(Fun, List1) -&gt; List2这个函数和map比较类似，相当于执行了lists:append(lists:map(List1)).也就是把map的结果进行append处理例子：lists:flatmap(fun(X)-&gt;[X,X] end, [a,b,c]).结果：[a,a,b,b,c,c] 7，foldl(Fun, Acc0, List) -&gt; Acc1Fun这个函数有两个参数第一个参数是List中的元素，第二个参数是Fun函数执行完后的返回值，这个参数第一次执行时就是Acc0例子：对[1,2,3,4,5]求和lists:foldl(fun(X, Sum) -&gt; X + Sum end, 0, [1,2,3,4,5]).结果：15执行过程：首先，Fun第一次执行时，X的值取列表List的第一个元素1，Sum取0, Fun第二次执行时，X的值取列表List的第二个元素2，Sum取Fun第一次的返回值 依次轮推，直到List中每个元素执行完，最后foldl返回最后一次的结果。 8，foldr(Fun, Acc0, List) -&gt; Acc1foldr这个函数和foldl比较相似不过是Fun执行时，X的值先取List的最后一个，然后取倒数第二个。 9，foreach(Fun, List) -&gt; ok以List中的每个元素为参数执行Fun函数，执行顺序按照List中元素的顺序，这个函数最后返回ok。是单边的例子 lists:foreach(fun(X)-&gt; %%using X to do somethings %% end,List) 10，keymap(Fun, N, TupleList1) -&gt; TupleList2对TupleList1中的每个元素的第N项作为参数在Fun中处理，然后这个第N项最后就被替换为Fun执行完返回的值例子：List1 = [{name,”zhangjing”},{name,”zhangsan”}].lists:keymap(fun(X)-&gt; list_to_atom(X) end,2,List1).结果：[{name,zhangjing},{name,zhangsan}] 11，mapfoldl(Fun, Acc0, List1) -&gt; {List2, Acc1}这个函数等于是把map和foldl函数结合起来。将List1中的每一个元素执行Fun函数，执行后花括号的第一个值作为返回值返回，第二个值作为参数传给Fun，作为下一次用。例子：lists:mapfoldl(fun(X, Sum) -&gt; {2*X, X+Sum} end,0, [1,2,3,4,5]).{[2,4,6,8,10],15} 12，mapfoldr(Fun, Acc0, List1) -&gt; {List2, Acc1}这个函数相当于将map和foldr结合起来 13，merge(Fun, List1, List2) -&gt; List3这个函数的功能也是把List1和List2合并到一起，只不过是List1和List2的元素要作为参数在Fun中执行，如果Fun返回true，那么返回值就是List1在前，List2在后。否则，反之。例子lists:merge(fun(A,B)-&gt; false end, [3,4],[2,1]).结果[2,1,3,4] 14，partition(Pred, List) -&gt; {Satisfying, NotSatisfying}这个函数的功能是将List分成两个List1和List2，List1是将List元素作为参数去Pred函数中执行返回true的元素组成，List2由Pred返回false的元素组成。注意，返回的是一个元组例子lists:partition(fun(A) -&gt; A rem 2 == 1 end, [1,2,3,4,5,6,7]).结果{[1,3,5,7],[2,4,6]} 15，sort(Fun, List1) -&gt; List2如果Fun函数返回true，则排序是从小到大的顺序，否则，从大到小。其中Fun有两个参数。例子lists:sort(fun(A,B)-&gt; false end,[1,2,3]).结果[3,2,1] 16，splitwith(Pred, List) -&gt; {List1, List2}将List分成List1和List2，List1由List中元素在Pred函数返回true的组成，但是有一点，如果遇到为false的，则将剩下的元素全部放到List2中，List1中就只有前面为true的。例子lists:splitwith(fun(A) -&gt; is_atom(A) end, [a,b,1,c,d,2,3,4,e]).结果{[a,b],[1,c,d,2,3,4,e]} 17，takewhile(Pred, List1) -&gt; List2List1中的元素element依次执行Pred(element),如果返回true，则获取这个元素，直到有元素执行Pred(element)返回false例子lists:takewhile(fun(E)-&gt; is_atom(E) end,[a,b,1,e,{c},[d]]).结果[a,b] 18,umerge(Fun, List1, List2) -&gt; List3这个函数和merge不同的是 当Fun返回true时，返回的List3中不能出现相同的元素疑问：但是当Fun返回false时，List3中可以有相同的元素。例子(Fun返回true的情况)lists:umerge(fun(A,B)-&gt; true end,[1,2],[2,3]).结果[1,2,3](Fun为false的情况)lists:umerge(fun(A,B)-&gt; false end,[1,2],[2,3]).[2,3,1,2]好神奇，竟然2有重复 19，usort(Fun, List1) -&gt; List2按照Fun函数进行排序，如果Fun返回true，那么只返回List1的第一个元素如果Fun返回false，那么List1从大到小排序例子1lists:usort(fun(A,B) -&gt; true end, [1,2,2,3,4]).结果[1] 例子2lists:usort(fun(A,B) -&gt; false end, [1,2,2,3,4]).结果[4,3,2,2,1] 20，zipwith(Combine, List1, List2) -&gt; List3将List1和list2中的每个元素执行Combine函数，然后返回一个元素，List3就是由Combine函数返回的一个个元素组成的。功能和map有点像，但是这里是对两个列表的操作。例子lists:zipwith(fun(X, Y) -&gt; X+Y end, [1,2,3], [4,5,6]).结果[5,7,9] 21，zipwith3(Combine, List1, List2, List3) -&gt; List4将List1和list2，list3中的每个元素执行Combine函数，然后返回一个元素，List4就是由Combine函数返回的一个个元素组成的。功能和map有点像，但是这里是对三个列表的操作。例子lists:zipwith3(fun(X, Y, Z) -&gt; X+Y+Z end, [1,2,3], [4,5,6],[7,8,9]).结果[12,15,18] 二，不带函数Pred1，append(ListOfLists) -&gt; List1ListOfLists都是由List组成的，而List一个列表，里面可以是任何类型的元素这个函数就是将ListOfLists里面的所有列表的元素按顺序编成一个列表提示：ListOfLists里面的元素必须都是列表才能用这个函数 例子 lists:append([[1, 2, 3], [a, b], [4, 5, 6]]). 结果： [1,2,3,a,b,4,5,6] 2，append(List1, List2) -&gt; List3将List1和List2两个列表连接起来，组成一个列表，然后返回新的这个列表这个函数的功能等同于List1 ++ List2 例子 lists:append(“abc”, “def”). 结果 “abcdef” 3，concat(Things) -&gt; string()这里的Things是一个列表，里面由atom() | integer() | float() | string()将这个列表里面的元素拼成一个字符串，然后返回 例子 lists:concat([doc, ‘/‘, file, ‘.’, 3]). 结果 doc/file.3” 4，delete(Elem, List1) -&gt; List2List1是由很多Element组成的，这个函数的功能是在List1中寻找第一个和Elem元素一样的，然后删除之，返回删除后新的列表。 例子 lists:delete({name,”zhangsan”},[{name,”lisi”},{name,”zhangsan”},{name,”wangmazi”})). 结果 [{name,”lisi”},{name,”wangmazi”}] 5，duplicate(N, Elem) -&gt; List返回一个由N个Elem组成的列表。 例子 lists:duplicate(5,”test”). 结果 [“test”,”test”,”test”,”test”,”test”] 6，flatlength(DeepList) -&gt; integer() &gt;= 0我的理解是DeepList就是列表里面套列表计算列表的长度，即用flatten函数将DeepList转化成List后元素的个数这个函数和length()的区别就是：length函数是得到列表元素的个数，而flatlength函数是先将DeepList转化成List后的个数譬如说List = [1,2,[3,4]]这个列表用length(List)求的值是：3lists:flatlength(List)求的值是：4其实lists:flatlength(List) = length(flatten(List)) 7，flatten(DeepList) -&gt; List将DeepList变成只有term()的list例子：lists:flatten([[a,a],[b,b],[c,c]]).结果：[a,a,b,b,c,c] 8，flatten(DeepList, Tail) -&gt; List就是将DeepList变成只有term的List后，在后面再加一个Tail。例子：lists:flatten([[a,a],[b,b],[c,c]],[dd]).结果：[a,a,b,b,c,c,dd] 9,keydelete(Key, N, TupleList1) -&gt; TupleList2这个函数适合处理列表里面的元素是元组的情况删除TupleList1中元素第N个元素和Key一致的元素，只删除第一个一样的，后面一样的不删除例子：List = [{name,”zhangjing”},{sex,”male”},{name,”zhangsan”},{sex,”male”}],lists:keydelete(“male”,2,List)结果：[{name,”zhangjing”},{name,”zhangsan”},{sex,”male”}] 10,keyfind(Key, N, TupleList) -&gt; Tuple | false查找TupleList中的一个Tuple，如果查找到，返回，如果没有查找到，则返回false这个Tuple必须满足第N个元素和key是一样。例子：List1 = [{name,”zhangjing”},{name,”zhangsan”}].lists:keyfind(“zhangjing”,2,List1)结果：{name,”zhangjing”} 11，keymember(Key, N, TupleList) -&gt; boolean()如果TupleList中的元素中存在第N个元素和key一致，则返回true，否则返回false例子：List1 = [{name,”zhangjing”},{name,”zhangsan”}].lists:keymember(“zhangjing”,2,List1).结果：true 12，keymerge(N, TupleList1, TupleList2) -&gt; TupleList3将TupleList1和TupleList2进行混合，组成一个TupleList，新组成的TupleList是按照Tuple的第N个元素进行排序的例子：List1 = [{name,”zhangjing”},{name,”zhangsan”}].List2 = [{nick,”zj”},{nick,”zs”}].lists:keymerge(2,List1,List2).结果：[{name,”zhangjing”}, {name,”zhangsan”}, {nick,”zj”}, {nick,”zs”}] 13，keyreplace(Key, N, TupleList1, NewTuple) -&gt; TupleList2在TupleList1的Tuple中找出第N个元素和Key一致，然后用NewTuple将这个Tuple替换掉，如果没有找到，则返回原来的TupleList1例子：List1 = [{name,”zhangjing”},{name,”zhangsan”}]lists:keyreplace(“zhangjing”,2,List1,{nickname,”netzj”}).结果：[{nickname,”netzj”},{name,”zhangsan”}] 14，keysearch(Key, N, TupleList) -&gt; {value, Tuple} | false这个函数和keyfind差不多，就是返回值的结构不一样也是在TupleList中找一个Tuple，这个Tuple的第N个元素和Key一样。例子：List1 = [{name,”zhangjing”},{name,”zhangsan”}]lists:keysearch(“zhangjing”,2,List1).结果：{value,{name,”zhangjing”}} 15，keysort(N, TupleList1) -&gt; TupleList2对TupleList1中的Tuple按照第N个元素进行排序，然后返回一个新的顺序的TupleList。不过这种排序是固定的。例子：List1 = [{name,”zhangsan”},{name,”zhangjing”}].lists:keysort(2,List1).结果：[{name,”zhangjing”},{name,”zhangsan”}] 16，keystore(Key, N, TupleList1, NewTuple) -&gt; TupleList2这个函数和keyreplace函数比较像，不同的是，这个keystore在没有找到对应的Tuple时，会将这个NewTuple追加在这个TupleList1的最后。例子：List1 = [{name,”zhangsan”},{name,”zhangjing”}].找到了的情况lists:keystore(“zhangjing”,2,List1,{name,”netzhangjing”}).[{name,”netzhangjing”},{name,”zhangsan”}]没有找到的情况lists:keystore(“zhanging”,2,List1,{name,”netzhangjing”}).[{name,”zhangjing”},{name,”zhangsan”},{name,”netzhangjing”}] 17，keytake(Key, N, TupleList1) -&gt; {value, Tuple, TupleList2} | false在TupleList1中找Tuple，这个Tuple的第N个元素和Key一致，如果找到了这么一个Tuple那么返回，{value, Tuple, TupleList2} 其中TupleList2是去掉Tuple的TupleList1.例子：List1 = [{name,”zhangjing”},{name,”zhangsan”},{name,”lisi”}].lists:keytake(“zhangjing”,2,List1).结果：{value,{name,”zhangjing”},[{name,”zhangsan”},{name,”lisi”}]} 18，last(List) -&gt; Last返回：List最后一个元素例子：List1 = [{name,”zhangjing”},{name,”zhangsan”},{name,”lisi”}].lists:last(List1).结果：{name,”lisi”} 19，max(List) -&gt; Max取出List中最大的元素，一般List是整型时比较适合。例子：lists:max([1,10,15,6]).结果：15 20，member(Elem, List) -&gt; boolean()如果Elem和List中的某个元素匹配（相同），那么返回true，否则返回false例子lists:member({sex,”1”},[{sex,”1”},{sex,”2”},{sex,”3”}]).结果：true 21，merge(ListOfLists) -&gt; List1ListOfLists是一个列表，里面由子列表构成这个函数的功能就是将这些子列表合并成一个列表。例子：lists:merge([[{11}],[{22}],[{33}]]).结果[{11},{22},{33}] 22，merge(List1, List2) -&gt; List3List1和List2分别是一个列表，这个函数的功能是将这两个列表合并成一个列表。例子：lists:merge([11],[22]).结果[11,22][2,1,3,4] 23, merge3(List1, List2, List3) -&gt; List4将List1，List2，List3合并成一个列表例子lists:merge3([11],[22],[33,44]).结果：[11,22,33,44] 24，min(List) -&gt; Min返回List中的最小的元素，和max函数对应例子lists:min([1,2,3]).结果1 25，nth(N, List) -&gt; Elem返回List中的第N个元素。例子lists:nth(2,[{name,”zhangsan”},{name,”lisi”},{name,”wangmazi”}]).结果{name,”lisi”} 26，nthtail(N, List) -&gt; Tail返回List列表中第N个元素后面的元素例子lists:nthtail(3, [a, b, c, d, e]).结果[d,e] 27，prefix(List1, List2) -&gt; boolean()如果List1是List2的前缀(也就是说List1和List2前部分相同)，那么返回true，否则返回false 28，reverse(List1) -&gt; List2将List1反转例子lists:reverse([1,2,3,4]).结果[4,3,2,1] 29,reverse(List1, Tail) -&gt; List2将List1反转，然后将Tail接在反转List1的后面，然后返回例子lists:reverse([1, 2, 3, 4], [a, b, c]).[4,3,2,1,a,b,c] 30，seq(From, To) -&gt; Seq其中From和To都是整型，这个函数返回一个从From到To的一个整型列表。例子lists:seq(1,10).结果[1,2,3,4,5,6,7,8,9,10] 31，seq(From, To, Incr) -&gt; Seq返回一个整型列表，这个列表的后一个元素比前一个元素大Incr。例子lists:seq(1,10,4).[1,5,9] 32，sort(List1) -&gt; List2将List1中的元素从小到大排序，然后返回新的一个列表。例子lists:sort([3,2,1]).结果[1,2,3] 33，split(N, List1) -&gt; {List2, List3}将List1分成List2和List3其中List2包括List1的前N个元素，List3包含剩余的。例子lists:split(3,[1,2,3,4,5]).结果{[1,2,3],[4,5]} 这个函数和partition数有区别，partition是遍历全部的List，而splitwith在遍历时遇到false的情况则马上结束遍历，返回结果。 34，sublist(List1, Len) -&gt; List2返回从第一个元素到第Len个元素的列表，这个Len大于List1的长度时，返回全部。例子lists:sublist([1,2,3,4,5,6],3).结果[1,2,3] 35，sublist(List1, Start, Len) -&gt; List2返回从List1的第Start个位置开始，后面Len个元素的列表。例子lists:sublist([1,2,3,4], 2, 2).结果[2,3] 36，subtract(List1, List2) -&gt; List3等同于 List1 – List2这个函数功能是返回一个List1的副本，对于List2中的每个元素，第一次在List1副本中出现时被删掉。例子lists:subtract(“112233”,”12”).结果“1233” 37，suffix(List1, List2) -&gt; boolean()如果List1是List2的后缀，那么返回true，否则返回false例子lists:suffix(“22”,”1122”).结果true 38，sum(List) -&gt; number()返回List中每个元素的和。其中List中的元素都应该是number()类型的。例子lists:sum([1,2,3,4]).结果10 39，ukeymerge(N, TupleList1, TupleList2) -&gt; TupleList3TupleList1和TupleList2里面的元素都是元组将TupleList1和TupleList2合并，合并的规则是按照元组的第N个元素，如果第N个元素有相同的，那么保留TupleList1中的，删除TupleList2中的。 40，ukeysort(N, TupleList1) -&gt; TupleList2TupleList1里面的元素都是元组这个函数也同样返回一个元素是元组的列表，返回的这个列表是按照元组的第N个元素来排序的，如果元组中有出现第N个元素相同的情况，删除掉后面的一个元组。例子lists:ukeysort(1,[{name,”zhangsan”},{sex,”male”},{name,”himan”}]).结果[{name,”zhangsan”},{sex,”male”}] 41，umerge(ListOfLists) -&gt; List1这个函数和merge唯一不同的就是，里面不能出现相同的元素，如果出现相同的，那么删除之，只保留一个唯一的例子lists:umerge([[1,2],[2,3]]).结果[1,2,3]分析：由于[[1,2],[2,3]]中merge后是[1,2,2,3],这个时候有两个相同的元素2，所以只保存一个2，所以结果是[1,2,3]. 42，umerge3(List1, List2, List3) -&gt; List4将List1, List2, List3合并和merge3不同的是返回的List4中不能出现重复的元素例子lists:merge3([1,2],[2,3],[3,4]).结果[1,2,3,4] 43，unzip(List1) -&gt; {List2, List3}List1里面的元素是元组，每个元组由两个元素组成，返回值List2包含每个List1中每个元组的第一个元素返回值List3包含每个List1中每个元组的第二个元素。例子lists:unzip([{name,”zhangsan”},{sex,”male”},{city,”hangzhou”}]).结果{[name,sex,city],[“zhangsan”,”male”,”hangzhou”]} 44，unzip3(List1) -&gt; {List2, List3, List4}List1里面的元素是元组，每个元组由三个元素组成，返回值List2包含每个List1中每个元组的第一个元素；返回值List3包含每个List1中每个元组的第二个元素；返回值List4包含每个List1中每个元组的第三个元素。例子lists:unzip3([{name,”zhangsan”,”apple”},{sex,”male”,”banana”},{city,”hangzhou”,”orange”}]).结果{[name,sex,city], [“zhangsan”,”male”,”hangzhou”], [“apple”,”banana”,”orange”]}注意，最终返回的是一个元组。 45，usort(List1) -&gt; List2将List1按照从小到大的顺序排序，如果排序后有重复的元素，删除重复的，只保存一个唯一的。例子lists:usort([4,3,2,1,2,3,4]).结果[1,2,3,4] 46，zip(List1, List2) -&gt; List3将两个长度相同的列表合并成一个列表List3是里面的每一个元组的第一个元素是从List1获取的，而每个元组的第二个元素是从List2中获取的例子lists:zip([name,sex,city],[“zhangsan”,”male”,”hangzhou”]).结果[{name,”zhangsan”},{sex,”male”},{city,”hangzhou”}]注意，如果List1和List2长度不一致，那么这个函数将会报错。 47，zip3(List1, List2, List3) -&gt; List4将三个长度相同的列表合并成一个列表List3是里面的每一个元组的第一个元素是从List1获取的，而每个元组的第二个元素是从List2中获取的每个元组的第三个元素是从List3中获取的。例子lists:zip3([name,sex,city],[“zhangsan”,”male”,”hangzhou”],[“nick”,”1”,”zhejiang”]).结果[{name,”zhangsan”,”nick”}, {sex,”male”,”1”}, {city,”hangzhou”,”zhejiang”}]","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"http://zxtotti17.github.io/tags/Erlang/"}]},{"title":"Erlang OTP学习","slug":"Erlang-OTP学习","date":"2019-04-09T08:50:32.000Z","updated":"2022-09-09T07:59:25.290Z","comments":true,"path":"/post/Erlang-OTP学习.html","link":"","permalink":"http://zxtotti17.github.io/post/Erlang-OTP%E5%AD%A6%E4%B9%A0.html","excerpt":"","text":"1.-behaviour(gen_server)它表示让编译器检查，当前module是否实现了gen_server指定的所有回调接口 2.gen_server:start_link(ServerName, Module, Args, Options) -&gt; Result这个方法用来启动一个server，其中：参数ServerName指定了服务名参数Module指定了该server的callback模块参数Args将作为服务初始化的启动参数（服务初始化时会调用：Module:init([Args])）参数Options指定了一些特性参数，通常可以直接使用[] 如果服务启动成功，返回{ok, Pid} 3.Module:init([Args])这个方法会在服务初始化时被回调，参数Args就是gen_server:start_link中倒数第二个参数，若初始化成功，该方法放回{ok, State},其中State将作为启动服务的State 4.gen_server:call(ServerRef, Request)这个方法供callback模块向ServerRef代表的服务发送Request请求（callback模块通常会在之上再封装一层接口供客户端调用，譬如这里的add，find方法），注意该方法是一个同步调用，它会一直等待服务器返回一个响应消息（除非等待超时，默认5s） 5.Module:handle_call(Request, From, State) -&gt; Result这是一个回调方法，用来处理gen_server:call(ServerRef, Request)发出的请求，其中：Request，表示客户端请求From，表示请求来自哪个客户端State，表示当前服务器状态 Result为handle_call 请求处理结果，它有以下几种类型{reply,Reply,NewState}{reply,Reply,NewState,Timeout}{reply,Reply,NewState,hibernate}{noreply,NewState}{noreply,NewState,Timeout}{noreply,NewState,hibernate}{stop,Reason,Reply,NewState} | {stop,Reason,NewState} 这几种返回值有什么区别呢？如果返回的是以reply开头，那么Reply将会作为响应返回给客户端如果返回的是以noreply开头，那么服务器将不会返回任何消息给客户端（这会导致客户端阻塞，因为客户端调用的gen_server:call方法是一个同步调用，当它发出请求后，会一直等待服务器发送响应消息，除非等待超时） 6.gen_server:cast(ServerRef, Request)这个方法同gen_server:call(ServerRef, Request)，但它最大的区别就是该调用是异步的，它不需要等待服务器返回任何处理结果 7.Module:handle_cast(Request, State) -&gt; Result这个方法用来处理gen_server:cast(ServerRef, Request)发出的请求，由于不会返回结果给客户端，所以参数列表中也没有From 8.检查进程是否加载 erlang:whereis(?MODULE). 9.查看进程的信息 erlang:process_info(pid(0,PID,0)).","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"http://zxtotti17.github.io/tags/Erlang/"}]},{"title":"充值流程","slug":"充值流程","date":"2019-03-06T12:01:38.000Z","updated":"2021-11-30T08:57:21.994Z","comments":true,"path":"/post/充值流程.html","link":"","permalink":"http://zxtotti17.github.io/post/%E5%85%85%E5%80%BC%E6%B5%81%E7%A8%8B.html","excerpt":"","text":"接触到的充值流程是这样的1.客户端发起请求-&gt;lcm后台，lcm后台确认充值成功，会将充值的金额变成平台货币保存在平台端，并通知到客户端充值成功，收到充值成功的客户端对游戏服务端发起请求，游戏服务端收到请求后，请求lcm平台调用spend方法，平台确认信息相符就扣币并告诉游戏服务端消费成功，游戏服务端在将平台货币转换为对应的游戏币，同时告诉客户端充值成功 2.平台充值成功会产生回调直接通知游戏服务端，服务端接收请求，后请求平台spend，成功后发币记录，客户端请求服务端查到有记录就告知客户端成功不做spend 掉单：如果掉单1.平台回调请求会保证执行spend方法，达到补单的效果2.客户端能读到平台币，直接通过平台剩余币与游戏服务端直接交易 注意：任何时间判断以天为单位要特别小心，如果出现两版批次连续很容易出问题","categories":[{"name":"设计方法","slug":"设计方法","permalink":"http://zxtotti17.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"http://zxtotti17.github.io/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-01-01T08:50:32.000Z","updated":"2020-06-24T07:58:16.163Z","comments":true,"path":"/post/hello-world.html","link":"","permalink":"http://zxtotti17.github.io/post/hello-world.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new &quot;My New Post&quot; More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"C++设计模式","slug":"c++设计模式","date":"2018-12-25T14:38:51.000Z","updated":"2022-09-09T07:59:18.097Z","comments":true,"path":"/post/c++设计模式.html","link":"","permalink":"http://zxtotti17.github.io/post/c++%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F.html","excerpt":"","text":"c++设计模式： 简单工厂模式 工厂模式有一种非常形象的描述，建立对象的类就如一个工厂，而需要被建立的对象就是一个个产品；在工厂中加工产品，使用产品的人，不用在乎产品是如何生产出来的。从软件开发的角度来说，这样就有效的降低了模块之间的耦合。 使用情景： 在不确定会有多少个处理操作时应该考虑使用简单工厂模式，如针对同样的接收到的数据，处理的逻辑可能会不同，可能以后还会增加新的操作。案例：如果实现计算器的功能时，对于同样的输入数据，可能执行加、减、乘、除，甚至其他的功能。因此可以抽象出一个操作的抽象类或是接口，提供一个统一的处理方法(此处为process)，然后每种操作创建出一个子类出来。而判断具体使用哪个具体的实现类是在工厂类中进行判断的(将存放操作的变量传递给工厂的生产方法)。工厂类始终返回的是这个抽象类，这样如果对原有功能进行更改或是新添加新的功能，也不会对原来的其他类做修改，只编译修改的那个类或是新的类就可以了。这样就做到了把耦合降到最低，同时也便于维护。 简单工厂：针对同样的数据，不同的操作用同一个接口 工厂方法：针对同样的数据，不同的操作用不同的接口 抽象工厂：针对不同的数据，不同的操作用不同的接口 策略模式：依赖c++的多态，抽象类的指针可以访问所有子类对象，（纯虚函数），可以用一个指针访问所有策略的实现类 单例模式：单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例单例模式(不能让一个程序打开两次 如：不能同时打开2个迅雷 迅雷用的单例模式) 访问者模式:适用于数据结构相对未定的系统，它把数据结构和作用于结构上的操作之间的耦合解脱开，使得操作集合可以相对自由的演化。访问者模式使得增加新的操作变的很容易，就是增加一个新的访问者类。访问者模式将有关的行为集中到一个访问者对象中(做任何更改不需要修改基类，不依赖虚函数) 观察者模式：定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态上发生变化时，会通知所有观察者对象，使他们能够自动更新自己。(QT的信号机制，Windows的消息机制都应用了观察者模式，还有订阅邮件，邮件到了就会给你发邮件) 建造者模式：使得产品内部表象可以独立地变化，客户不必知道产品内部组成的细节。可以强制实行一种分步骤进行的建造过程。用一个接口完成不同的操作，需要对客户的需求进行把握。(如：登陆QQ，自动选择所在地的服务器) 解释器模式：给定一个语言后，解释器模式可以定义出其文法的一种表示，并同时提供一个解释器。客户端可以使用这个解释器来解释这个语言中的句子。(如：360读取lua脚本，这个细节的实现就是解释器模式) 命令模式：把发出命令的责任和执行命令的责任分割开，委派给不同的对象允许请求的一方和发送的一方独立开来，使得请求的一方不必知道接收请求的一方的接口，更不必知道请求是怎么被接收，以及操作是否执行，何时被执行以及是怎么被执行的。(命令模式在客户端与服务器之间用的最多 (C/S架构)) 模板模式：不同的子类可以以不同的方式实现这些抽象方法， 从而对剩余的逻辑有不同的实现。先制定一个顶级逻辑框架， 而将逻辑的细节留给具体的子类去实现。(适用于本地化，做一个软件，在日本是日文，美国是英语…) 桥接模式：将抽象化与实现化脱离，使得二者可以独立的变化， 也就是指在一个软件系统的抽象化和实现化之间使用组合聚合关系而不是继承关系，从而使两者可以独立的变化。(相当于配电脑去装机，把各个模块组合到一起) 适配器模式：把一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口原因不匹配而无法一起工作的两个类能够一起工作。 外观模式：外部与一个子系统的通信必须通过一个统一的外观对象进行。每一个子系统只有一个外观类，而且此外观类只有一个实例，也就是说它是一个单例模式。但整个系统可以有多个外观类。(多个子系统方法都需要一个外观类统一管理，用统一的接口方便消费者使用) 享元模式：享元模式大幅度的降低内存中对象的数量，使用享元模式主要是为了优化内存，相同功能可以并行使用。 原型模式：允许动态的增加或减少产品类，产品类不需要非得有任何事先确定的等级结构，原始模型模式适用于任何的等级结构。缺点是每一个类都必须配备一个克隆方法。 责任链模式：在责任链模式中，很多对象由每一个对象对其下家的引用而接起来形成一条链。请求在这个链上传递，直到链上的某一个对象决定处理此请求。处理者有两个选择：承担责任或者把责任推给下家。一个请求可以最终不被任何接收端对象所接受。(例如：晚上去上英语课，为了好开溜坐到了最后一排，哇，前面坐了好几个漂亮的MM哎，找张纸条，写上“Hi, 可以做我的女朋友吗？如果不愿意请向前传”，纸条就一个接一个的传上去了，糟糕，传到第一排的MM把纸条传给老师了) 中介者模式：中介者模式包装了一系列对象相互作用的方式， 使得这些对象不必相互明显作用。从而使他们可以松散偶合。 当某些对象之间的作用发生改变时，不会立即影响其他的一些对象之间的作用。（如：TCP/IP打洞技术） 装饰模式：装饰模式以对客户端透明的方式扩展对象的功能是继承关系的一个替代方案，提供比继承更多的灵活性。动态给一个对象增加功能，这些功能可以再动态的撤消。增加由一些基本功能的排列组合而产生的非常大量的功能。 状态模式：意图是让一个对象在其内部状态改变的时候，其行为也随之改变。状态模式需要对每一个系统可能取得的状态创立一个状态类的子类。当系统的状态变化时，系统便改变所选的子类。(如：到了晚上12点要睡觉，到了早上8点要起床…这就是状态) 合成模式：将对象组织到树结构中，可以用来描述整体与部分的关系。合成模式就是一个处理对象的树结构的模式。合成模式把部分与整体的关系用树结构表示出来。(用于树状结构)","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://zxtotti17.github.io/tags/c/"},{"name":"设计模式","slug":"设计模式","permalink":"http://zxtotti17.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Pomelo学习笔记","slug":"pomelo学习笔记","date":"2018-10-23T11:34:45.000Z","updated":"2022-09-09T08:22:45.710Z","comments":true,"path":"/post/pomelo学习笔记.html","link":"","permalink":"http://zxtotti17.github.io/post/pomelo%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html","excerpt":"重新认识pomelo服务器配置在server.json里，通过app.js设置服务器及路由，每一个服务器在server下对应一个文件及为一个进程，其中一定包含handler逻辑代码部分不一定包含remote（远程通信、服务器监听用）例如以下 self.app.rpc.chat.chatRemote.add(session, uid, self.app.get(&#39;serverId&#39;), rid, true, function(users)&#123; next(null, &#123; users:users &#125;); &#125;); 增加服务器改server.json扩充，然后在连接服务器中逻辑进行选服 module.exports.dispatch &#x3D; function(uid, connectors) &#123; var index &#x3D; Math.abs(crc.crc32(uid)) % connectors.length; return connectors[index]; &#125;; filter用于请求前及请求后的处理,可以用于请求排队，或者测试接口时间app.js中可以配置路由压缩及回包压缩方式 app.set(&#39;connectorConfig&#39;, &#123; connector : pomelo.connectors.hybridconnector, useProtobuf : true, useDict: true &#x2F;&#x2F; enable dict &#125;); &#125;); 自建组件在app文件夹下在建立一个自己定义的文件夹，里面有start afterStart stop app.configure(&#39;production|development&#39;, &#39;master&#39;, function() &#123; app.load(helloWorld, &#123;interval: 5000&#125;); &#125;); 一个admin module中一般包括四个回调方法，monitorHandler，masterHandler，clientHandler, start。其中monitorHandler是monitor收到master的请求或者通知时由monitor回调，masterHandler是master收到monitor的请求或者通知时回调，clientHandler是master收到client的请求或通知时回调的, start是当admin module加载完成后，用来执行一些初始化监控时调用。 组件master组件monitor组件connector组件session组件connection组件server组件pushScheduler组件proxy组件remote组件dictionary组件protobuf组件channel组件backendSession组件具体看https://github.com/NetEase/pomelo/wiki/%E7%BB%84%E4%BB%B6%E6%A6%82%E8%BF%B0 环境 getBase() Application.getBase(); 获取应用程序的基本路径 set(setting, val, attach); Application.set(); setting:应用程序的配置；val:需要设置的值；attach:是否将设配置应用到程序。设置或返回配置的值。 get(setting) Application.get(); setting:应用程序的配置。获取配置的值 enabled(setting) Application.enabled(); setting:应用程序的配置。检查配置是否启用 disabled(setting) Application.disabled(); setting:应用程序的配置。检查配置是否禁用 enbale(setting) Application.enbale(); setting:应用程序的配置。启用配置 disable(setting) Application.disabled(); setting:应用程序的配置。禁用配置 configure(env,fn,type) Application.configure();env:应用环境;fn:回调函数;type:服务类型. 初始化 start() Application.start(); 启动应用程序。它会加载默认的组件和启动所有加载的组件。 registerAdmin(moduleId,module,opts) Application.registerAdmin(); moduleId:(可选参数)模块id或者有modeule提供的模块Id;module:模块对象或者模块的工程函数;opts:模块构造函数的参数。 filter(filter) Application.filter(); filter:provide before and after filter method。add a filter to before and after filter before(bf) Application.before(); bf:before filter。Add before filter after(af) Application.after(); af:after filter。Add after filter load(name, component, opts) Application.load(); name:组件的名称（可选）；component：组件的实例或者组件的工厂函数；opts：组件构造函数的参数（可选）。加载组件 loadConfig(key,val) Application.loadConfig(); key:环境配置的关键字;val:环境配置的值。导入json文件来配置环境。","text":"重新认识pomelo服务器配置在server.json里，通过app.js设置服务器及路由，每一个服务器在server下对应一个文件及为一个进程，其中一定包含handler逻辑代码部分不一定包含remote（远程通信、服务器监听用）例如以下 self.app.rpc.chat.chatRemote.add(session, uid, self.app.get(&#39;serverId&#39;), rid, true, function(users)&#123; next(null, &#123; users:users &#125;); &#125;); 增加服务器改server.json扩充，然后在连接服务器中逻辑进行选服 module.exports.dispatch &#x3D; function(uid, connectors) &#123; var index &#x3D; Math.abs(crc.crc32(uid)) % connectors.length; return connectors[index]; &#125;; filter用于请求前及请求后的处理,可以用于请求排队，或者测试接口时间app.js中可以配置路由压缩及回包压缩方式 app.set(&#39;connectorConfig&#39;, &#123; connector : pomelo.connectors.hybridconnector, useProtobuf : true, useDict: true &#x2F;&#x2F; enable dict &#125;); &#125;); 自建组件在app文件夹下在建立一个自己定义的文件夹，里面有start afterStart stop app.configure(&#39;production|development&#39;, &#39;master&#39;, function() &#123; app.load(helloWorld, &#123;interval: 5000&#125;); &#125;); 一个admin module中一般包括四个回调方法，monitorHandler，masterHandler，clientHandler, start。其中monitorHandler是monitor收到master的请求或者通知时由monitor回调，masterHandler是master收到monitor的请求或者通知时回调，clientHandler是master收到client的请求或通知时回调的, start是当admin module加载完成后，用来执行一些初始化监控时调用。 组件master组件monitor组件connector组件session组件connection组件server组件pushScheduler组件proxy组件remote组件dictionary组件protobuf组件channel组件backendSession组件具体看https://github.com/NetEase/pomelo/wiki/%E7%BB%84%E4%BB%B6%E6%A6%82%E8%BF%B0 环境 getBase() Application.getBase(); 获取应用程序的基本路径 set(setting, val, attach); Application.set(); setting:应用程序的配置；val:需要设置的值；attach:是否将设配置应用到程序。设置或返回配置的值。 get(setting) Application.get(); setting:应用程序的配置。获取配置的值 enabled(setting) Application.enabled(); setting:应用程序的配置。检查配置是否启用 disabled(setting) Application.disabled(); setting:应用程序的配置。检查配置是否禁用 enbale(setting) Application.enbale(); setting:应用程序的配置。启用配置 disable(setting) Application.disabled(); setting:应用程序的配置。禁用配置 configure(env,fn,type) Application.configure();env:应用环境;fn:回调函数;type:服务类型. 初始化 start() Application.start(); 启动应用程序。它会加载默认的组件和启动所有加载的组件。 registerAdmin(moduleId,module,opts) Application.registerAdmin(); moduleId:(可选参数)模块id或者有modeule提供的模块Id;module:模块对象或者模块的工程函数;opts:模块构造函数的参数。 filter(filter) Application.filter(); filter:provide before and after filter method。add a filter to before and after filter before(bf) Application.before(); bf:before filter。Add before filter after(af) Application.after(); af:after filter。Add after filter load(name, component, opts) Application.load(); name:组件的名称（可选）；component：组件的实例或者组件的工厂函数；opts：组件构造函数的参数（可选）。加载组件 loadConfig(key,val) Application.loadConfig(); key:环境配置的关键字;val:环境配置的值。导入json文件来配置环境。 组件相关 route(serverType, routeFunc) Application.route(); serverType:服务类型;routeFunc:路由功能函数,如：routeFunc(session, msg, app, cb) 未指定的服务类型设置路由功能。如： app.route(&#39;area&#39;, routeFunc); var routeFunc &#x3D; function(session, msg, app, cb) &#123; &#x2F;&#x2F; all request to area would be route to the first area server var areas &#x3D; app.getServersByType(&#39;area&#39;); cb(null, areas[0].id); &#125; 获取相关配置，组件方法 getMaster() Application.getMaster() 获得Maseter服务的信息 getCurServer() Application.getCurServer() 获得当前服务的信息 getServerId() Application.getServerId() 获得当前服务的ID getServerType() Application.getServerType() 获得当前服务的类型 getServers() Application.getServers() 获得所有当前服务的信息 getServersFromConfig() Application.getServersFromConfig() 从server.json中获得所有服务的信息 getServerTypes() Application.getServerTypes() 获得所有服务的类型 getServerById(serverId) Application.getServerById() 根据服务ID从服务集群中获得服务的信息 getServerFromConfig(serverId) Application.getServerFromConfig() 根据服务ID从server.json中获得服务的信息 getServersByType(serverType) Application.getServersByType() 根据服务类型获取服务信息 isFrontend(server) Application.isFrontend() 检查服务是否是一个前端服务 isBackend(server) Application.isBackend() 检查服务是否是一个后端服务 isMaster() Application.isMaster() 检查当前服务是否是主服务 addServers(servers) Application.addServers() servers：新服务信息列表。添加新服务信息到正在运行的应用程序中 removerServers(ids) Application.removerServers() ids：服务id列表。从当前运行的应用程序中删除服务信息。 创建和维护本地服务的信道。 createChannel(name) ChannelService.prototype.createChannel() 根据信道名称创建信道，如果该信道已存在则返回已存在的信道 getChannel(name,create) ChannelService.prototype.getChannel() name:信道名称，create:如果为true，并且信道不存在时，则创建新的信道。根据信道名称获取信道 destroyChannel(name) ChannelService.prototype.destroyChannel() 根据信道名称，删除信道 pushMessageByUids(route, msg, uids, cb) ChannelService.prototype.pushMessageByUids() route：消息路由；msg：发送到客户端的消息；uids：接收消息的客户端列表，格式 [&#123;uid: userId, sid: frontendServerId&#125;]；cb：回调函数 cb(err)。根据uids将消息推送给客户端，如果uids中的sid未指定，则忽略相应的客户端 broadcast(stype,route, msg, opts, cb) ChannelService.prototype.broadcast() stype：前端服务的类型;route：路由;msg：消息;opts：广播参数;cb：回调函数。广播消息到所有连接的客户端。 Channel add(uid,sid) Channel.prototype.add() uid:用户编号；sid：用户连接到的前端服务id。添加指定用户到信道。 leave(uid,sid) Channel.prototype.leave() uid:用户编号；sid：用户连接到的前端服务id。从信道中移除用户。 getMembers() Channel.prototype.getMembers() 获得信道中的成员 getMember(uid) Channel.prototype.getMember() 根据uid获取成员信息 destroy() Channel.prototype.destroy() 销毁信道 pushMessage(route,msg,cb) Channel.prototype.pushMessage() route：消息路由，msg：要推送的消息，cb：回调函数。将消息推送给信道的所有成员。 GlobalChannelService destroyChannel(name,cb) GlobalChannelService.prototype.destroyChannel() uid:用户编号；sid：用户连接到的前端服务id。添加指定用户到信道。 add(name,uid,sid,cb) GlobalChannelService.prototype.add() name:信道名称；uid：用户id；sid：前端服务id；cb：回调函数。 添加成员到信道。 leave(name,uid,sid,cb) GlobalChannelService.prototype.leave() name:信道名称；uid：用户id；sid：前端服务id；cb：回调函数。 从信道中移除成员。 pushMessage() GlobalChannelService.prototype.pushMessage(serverType, route, msg,channelName, opts, cb) serverType：前端服务的类型, route：路由, msg：需要推送的消息,channelName：信道名称, opts：参数, cb：回调函数 通过全局信道发送消息 LocalSessionService get(frontendId,sid,cb) LocalSeesionService.prototype.get() frontendId:会话链接的前端服务id,sid:会话Id,cb:回调函数。根据前端服务和会话id获得本地会话 getByUid(name,uid,sid,cb) LocalSeesionService.prototype.getByUid() frontendId:会话链接的前端服务id,uid：绑定到会话的用户id，cb：回调函数。args: cb(err, localSessions)。根据前端服务和用户id获取本地会话。 kickBySid(name,uid,sid,cb) LocalSeesionService.prototype.kickBySid() frontendId:会话链接的前端服务id,sid:会话Id,cb:回调函数。根据会话id踢掉该会话。 kickByUid() LocalSeesionService.prototype.kickByUid() frontendId:会话链接的前端服务id,uid：用户id,cb:回调函数。根据用户id踢掉该会话。 LocalSession bind(uid,cb) LocalSeesion.prototype.bind() uid:用户编号;cb:回调函数。callfunction(err)。绑定当前会话，用于前端服务的推送和全局会话的绑定。 unbind(uid,cb) LocalSeesion.prototype.unbind() uid:用户编号;cb:回调函数。callfunction(err)。取消绑定。 set(key,value) LocalSeesion.prototype.set() 将key&#x2F;value添加到本地会话中 get(key) LocalSeesion.prototype.get() 根据key从本地会话中获取值。 push(key,cb) LocalSeesion.prototype.push() 将本地会话中的key&#x2F;value添加到全局会话中 pushAll(cb) LocalSeesion.prototype.pushAll() 将本地会话中的所有key&#x2F;value添加到全会话中 SessionService kick(uid,cb) SeesionService.prototype.kick() 踢掉该用户的所有离线会话 kickBySession(sid,cb) SeesionService.prototype.kickBySession() sid:会话编号;cb:回调函数。根据会话id踢掉一个在线用户 sendMessage(sid,msg) SeesionService.prototype.sendMessage()根据会话id向客户端发送消息 sendMessageByUid(uid,msg) SeesionService.prototype.sendMessageByUid() 根据用户id向客户端发送消息 Pomelo createApp(opts) Pomelo.create() 创建一个Pomelo 应用程序","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://zxtotti17.github.io/tags/node-js/"}]},{"title":"Node笔记","slug":"node笔记","date":"2018-08-21T09:04:37.000Z","updated":"2023-04-10T07:02:09.974Z","comments":true,"path":"/post/node笔记.html","link":"","permalink":"http://zxtotti17.github.io/post/node%E7%AC%94%E8%AE%B0.html","excerpt":"第一章 node简介1.1 node的特点 1.1.1 异步I/O 绝大多数操作以异步方式进行调用 1.1.2 事件与回调函数 1.1.3 单线程，但是可以用WebWorkers的方式解决单线程的问题（子进程），用Master-Worker用master统一管理子进程 1.1.4 跨平台 1.1.5 c++速度大约是node的2.5倍 1.2 模块机制 1.2.1 分为核心模块和文件模块，require没带路径的为核心模块，直接加载进内存，带路径的为文件模块,核心模块中有c++和javascript两部分，其中buffer、crypto、evals、fs、os、等都是c++部分的 1.2.2 npm安装的核心模块插件在package.json中定义 1.3 异步I/O 1.3.1 操作系统内核对I/O只有：阻塞I/O和非阻塞I/O，node中的异步I/O模型由事件循环、观察者、请求对象、I/O线程池 整个系统可以理解为事件循环相当于厨子，不停的询问是否有新的订单，观察者相当于收银员，收到用户的订单将订单分给厨子，而订单相当于请求对象，参数、方法、回调函数斗封装在请求对象中, 以上是异步I/O的第一步，io线程池相当于放订单的桌子， 请求对象-&gt;I/O线程池-&gt;观察者-&gt;事件循环 1.3.2 非异步的I/O主要是setTimeout(),setInterval(),setImmediate(),process.nextTick()","text":"第一章 node简介1.1 node的特点 1.1.1 异步I/O 绝大多数操作以异步方式进行调用 1.1.2 事件与回调函数 1.1.3 单线程，但是可以用WebWorkers的方式解决单线程的问题（子进程），用Master-Worker用master统一管理子进程 1.1.4 跨平台 1.1.5 c++速度大约是node的2.5倍 1.2 模块机制 1.2.1 分为核心模块和文件模块，require没带路径的为核心模块，直接加载进内存，带路径的为文件模块,核心模块中有c++和javascript两部分，其中buffer、crypto、evals、fs、os、等都是c++部分的 1.2.2 npm安装的核心模块插件在package.json中定义 1.3 异步I/O 1.3.1 操作系统内核对I/O只有：阻塞I/O和非阻塞I/O，node中的异步I/O模型由事件循环、观察者、请求对象、I/O线程池 整个系统可以理解为事件循环相当于厨子，不停的询问是否有新的订单，观察者相当于收银员，收到用户的订单将订单分给厨子，而订单相当于请求对象，参数、方法、回调函数斗封装在请求对象中, 以上是异步I/O的第一步，io线程池相当于放订单的桌子， 请求对象-&gt;I/O线程池-&gt;观察者-&gt;事件循环 1.3.2 非异步的I/O主要是setTimeout(),setInterval(),setImmediate(),process.nextTick() 1.4 异步编程 1.4.1 异步编程的解决方案分为3个： 1）事件发布/订阅模式 2）Promise/Deferred模式 3）流程控制库 1.4.2 事件发布/订阅模式 bash //订阅 emitter.on(&quot;event1&quot;,function(message){ console.log(message); }); //发布 emitter.emit(&#39;event1&#39;,&quot;I Love you&quot;); 1）继承events模块 ``` bash var events = require(‘events’); function Stream(){ events.EventEmitter.call(this); } util.inherits(Stream,events.EventEmitter); ``` 2)利用事件队列解决崩溃问题 事件发布/订阅模式中一般只有一个once()方法，用一个『状态锁』或者『事件队列』防止崩溃 状态锁 ``` bash var status = &quot;ready&quot;; var select = function(callback){ if(status == &quot;ready&quot; ){ status = &quot;pending&quot;; db.select(&quot;SQL&quot;, function(results){ status = &quot;ready&quot;; callback(results); }); } }; ``` 事件队列 ``` bash var proxy = new events.EventEmitter(); var status = function (callback) proxy.once(&quot;selected&quot;, callback); if(status === &quot;ready&quot;){ status = &quot;pending&quot;; db.select(&quot;SQL&quot;, function(result){ proxy.emit(&quot;selected&quot;,result); status = &quot;ready&quot;; }); } } ``` 3）多异步之间的协作方案 借组一个第三方函数和第三方变量来处理异步协作的结果 ``` bash var after = function (times,callback){ var count = 0, results = {}; return function (key, value){ result[key] = value; count++; if(count === times){ callback(results); } } } var done = after(times, render); ``` 1.4.3 Promise/Deferred模式 Promise是高级接口，事件是低级接口，Promise更像链表 Promise中有3种状态 pending - 进行中 fulfilled - 成功 rejected - 失败 状态一旦改变就不可更改，在回调还是同样结果，但是事件错过了监听是得不到结果的 1.4.4 async流程控制模块 1）async的series()方法实现串行（不传参） ``` bash async.series([ function (callback){ fs.readFile(&#39;file1.txt&#39;,&#39;utf-8&#39;,calback); }, function (callback){ fs.readFile(&#39;file2.txt&#39;,&#39;utf-8&#39;,calback); } ],function (err,result){ //result = [file1.txt,file2.txt]等价于先处理file1.txt，在处理file2.txt，错误回调 }); ``` 2）async的parallel()方法实现并行 ``` bash async.parallel([ function (callback){ fs.readFile(&#39;file1.txt&#39;,&#39;utf-8&#39;,calback); }, function (callback){ fs.readFile(&#39;file2.txt&#39;,&#39;utf-8&#39;,calback); } ],function (err,result){ //result = [file1.txt,file2.txt]等价于并行处理file1.txt，在处理file2.txt，错误回调 }); ``` 3）async的waterfall()方法实现串行（传参） 略 4）async.auto()可以根据依赖关系自动分析，以最佳顺序执行 略 1.4.5 流程控制模块Step 1)Step接受任意数量任务，所有任务传行执行 ``` bash Step( function (callback){ fs.readFile(&#39;file1.txt&#39;,&#39;utf-8&#39;,this); }, function (callback){ fs.readFile(&#39;file2.txt&#39;,&#39;utf-8&#39;,this); }, function done(err, content) { console.log(content); } ); ``` 2)Step实现异步任务并行执行要用this的parallel() ``` bash Step( function (callback){ fs.readFile(&#39;file1.txt&#39;,&#39;utf-8&#39;,this.parallel()); }, function (callback){ fs.readFile(&#39;file2.txt&#39;,&#39;utf-8&#39;,this.parallel()); }, function done(err, content) { console.log(arguments); } ); ``` 1.4.6流程控制模块wind 1)wind的$await()方法实现异步等待 2）wind的whenAll()处理并发1.5 异步并发控制 1.5.1 bagpipe解决办法（API添加过载保护，用队列控制并发） ``` bash var Bagpipe = require(‘bagpipe’); //设定最大并发数为10 var bagpipe = new Bagpipe(10); for(var i = 0; i&lt; 100;i++){ bagpipe.push(async, function (){ }); } bagpipe.on(&#39;full&#39;,function (length){ console.warn(&#39;底层系统处理不及时&#39;); }); ``` 1.5.2 拒绝模式 ``` bash var bagpipe = new Bagpipe(10,{ refuse: true }); ``` 1.5.3 超时控制 ``` bash var bagpipe = new Bagpipe(10, { timeout: 3000 }); ```1.6 内存管理 1.6.1 v8内存分为新生代和老生代的 node –max-old-space-size 2048 xxx.js 调整内存大小执行某个脚本 v8堆内存64位系统是1.4G,32位系统是0.7G 新生代内存的回收机制是将堆内存一分为2，使用中的是From，空的是to，进行垃圾回收时，是将from中的存活对象复制到to中，然后释放非存活的，同时from和to对换，缺点是只能使用一半的内存空间 老生带内存的回收机制是将from中的使用的标记，回收未使用的 1.6.2 内部变量无法被外部方法访问 叫闭包（使用外部方法访问内部变量的方法） 1.6.3 查看内存使用process.memoryUsage() os.totalmem os.freemem 1.7 Buffer 1.7.1 Buffer与字符串转换 bash new Buffer(str, [encoding]); buf.write(string, [offset], [length], [encodeing]); buf.tostring([encoding], [start], [end]);1.8 网络 1.8.1 tcp协议中的osi模型（分为 物理层、数据链路层、网络层、传输层、会话层、表示层、应用层） server ``` bash var net = require(‘net’); var server = net.createServer(function(socket){ server.on(‘data’,function(data){ }); server.on(‘end’,function(data){ }); server.on(‘error’,function(data){ }); server.write(‘data’); }); server.listen(port,function(){ }) ``` client ``` bash var net = require(&#39;net&#39;); var client = net.connect({port: 8124},function(socket){ client.on(&#39;data&#39;,function(data){ }); client.on(&#39;end&#39;,function(data){ }); client.on(&#39;error&#39;,function(data){ }); client.write(&#39;data&#39;); }); ``` 1.8.2 UDP是用户数据包协议，一个套接字可以与多个UDP通信 server ``` bash var dgrm = require(&quot;dgrm&quot;); var server = dgrm.createSocket(&quot;udp4&quot;); server.on(&quot;message&quot;, function (msg, rinfo){ console.log(&quot;xxx&quot;); }); server.on(&quot;listening&quot;, function() { var address = server.address(); console.log(&quot;xxx&quot;); }); server.bind(41234); ``` client ``` bash var dgram = require(&#39;dgram&#39;); var messgae = new Buffer(&quot;xxxx&quot;); var client = dgram.createSocket(&quot;udp4&quot;); clinet.send(message, 0, message.length, 41234, &quot;localhost&quot;, function(err,bytes){ client.close(); }); ``` 1.8.3 HTTP是构建在TCP之上属于应用层协议 ``` bash https_request : function(host, path, post_data, cb){ var reqdata = JSON.stringify(post_data); var options = { hostname: host, port: 443, method: &#39;POST&#39;, path: path, headers: { &#39;Content-Type&#39;: &#39;application/json&#39; } }; var req_time_out = setTimeout(function() { req.abort(); cb(400, {code:400,message:&#39;请求超时&#39;}); logger.n.info(&#39;Got Request Timeout.&#39;); }, 10000); var req = https.request(options, function (res) { clearTimeout(req_time_out); //等待响应60秒超时 var res_time_out = setTimeout(function() { res.destroy(); cb(400, {code:400,message:&#39;响应超时&#39;}); logger.n.info(&#39;Got Response Timeout.&#39;); }, 60000); var status_code = res.statusCode; var body = null; logger.n.info(&quot;Got status_code: &quot; + status_code); res.on(&#39;data&#39;,function(data){ body = JSON.parse(data); }).on(&#39;end&#39;, function(){ clearTimeout(res_time_out); cb(status_code, body); }); }).on(&#39;error&#39;, function(e) { cb(400, {code:400,message:e.message}); logger.n.info(&quot;Got error: &quot; + e.message); }); req.write(reqdata); req.end(); } ``` 1.8.4 WebSocket client ``` bash var client= new net.Socket(); var flag = true; var port = 0; client.on(&#39;connect&#39;,function (){ //正常连接 flag = true; logger.boot.info(&#39;socket Connection succeed&#39;); }); client.on(&#39;end&#39;, function() { //flag=false; logger.n.warn(&#39;!!!!!tcp_client disconnected&#39;); setTimeout(Fight_Service.tcp_reconnect, 1000); }); client.on(&#39;data&#39;,function(data){ //得到服务端返回来的数据 Fight_Service.processResp(data); }); client.on(&#39;error&#39;,function(error){ //错误出现之后关闭连接 flag = false; logger.n.error(&#39;socket error:&#39; + error); client.destroy(); setTimeout(Fight_Service.tcp_reconnect, 1000); }); client.on(&#39;close&#39;,function(){ //正常关闭连接 flag = false; logger.n.warn(&#39;socket Connection closed&#39;); client.destroy(); }); Fight_Service.tcp_reconnect = function(worker_id){ //创建socket客户端 client.setEncoding(&#39;binary&#39;); if (port == 0 ){ //连接到服务端115.159.186.60 8400 // logger.boot.info(&quot;socket process_work_id:&quot; + worker_id); worker_id = worker_id % 8; port = 8400 + worker_id; }else{ logger.boot.info(&quot;socket tcp_reconnect&quot;); } logger.boot.info(&quot;socket_port_id:&quot; + port); client.connect(port,&quot;10.96.71.91&quot;); } ```1.9 多进程 1.9.1 child_process模块 1）spawn()启动一个子进程执行命令，无回调，无超时 2）exec()启动一个子进程执行命令，有回调，有超时 3）execFile()启动一个子进程执行可执行文件 4）fork()启动node子进程执行js文件模块 node.js在js执行中是单线程的，但是单线程的进程没办法用像多线程那样直接利用多核cpu，那么node.js就得用主从进程的方式fork出新的子进程，在用master主进程管理分配给子进程，通过多个node子进程的使用来利用多核cpu bash var fork = require(&#39;child_process&#39;).fork; var cpus = require(&#39;os&#39;).cpus(); for(var i = 0; i &lt; cpus.length; i++){ fork(&#39;./worker.js&#39;); } 1.9.2 进程间通信IPC，主线程与工作线程之间通过onmessage()和postMessage()进行通信，子进程对象则由send()方法实现主进程向子进程发送数据 1.9.3 句柄是一种用来标识资源的引用，用来拓展有限的文件描述符 bash child.send(message,[sandHandle])如（child.send(&#39;server&#39;,server)）; 子进程代码 process.on(&#39;message&#39;,function(m, server){ if(m == &#39;server&#39;){ xxxxx } }) 1.9.4 父进程可以通过kill()方法给子进程发送一个SIGTERM信号杀进程 bash chid.kill([signal]); process.kill(pid, [signal]); 在退出中加入自动重启可能会有新用户进来请求丢失的情况，工作进程在得知退出时，向主进程发送一个自杀信号（达到先创建在退出进程） bash /** * cluster mode */ if ( opts.get(&#39;cluster&#39;) || config.APP_CLUSTER.ENABLE) { var cluster = require(&#39;cluster&#39;); if (cluster.isMaster) { console.log(&#39;[CLUSTER MODE] MASTER&#39;); for (var i=0; i&lt;config.APP_CLUSTER.NUM; i++) { cluster.fork(); } cluster.on(&#39;exit&#39;, function(worker, code, signal) { console.log(&#39;worker &#39; + worker.process.pid + &#39; died&#39;); cluster.fork(); }); return; } console.log(&#39;[CLUSTER MODE] WORKER&#39;); } 每个新的子进程监听新对应的端口，同时主进程给子进程的分配中大部分是根据一个特点id,比如玩家的特定id%开的进程数平均分配给不同的进程，没有用户要求的情况可以根据子进程数量随机分配请求如下 bash export function repoRouteTmp(_session: any, msg: any, app: any, next: Function) { let servers = app.getServersByType(&#39;repo&#39;); if (!servers || servers.length === 0) { next(new Error(&#39;can not find server info for type: &#39; + msg.serverType)); return; } let str = app.getServerId(); let id = parseInt(str.replace(/[^\\d]/g, &#39;&#39;)); let server_list: any = []; if (id) { let len = servers.length; for (let i = 0; i &lt; len; i++) { let repo_id = parseInt(servers[i].id.replace(/[^\\d]/g, &#39;&#39;)); if (repo_id &gt; 20 &amp;&amp; id &gt; 20) { server_list.push(servers[i].id); } else if (repo_id &lt; 20 &amp;&amp; id &lt; 20) { server_list.push(servers[i].id); } } } let serverId = 0 if (server_list &amp;&amp; server_list.length) { let end = server_list.length - 1; let index = randomRange(0, end); serverId = server_list[index] } else { let user_id = (msg.data || msg).user_id || `${randomNum()}`; // 游客时使用随机 let count: number = Array.isArray(servers) ? servers.length : 1; let index = Math.abs(crc.crc32(user_id)) % count; serverId = servers[index].id || 0; } next(undefined, serverId); }; 虽然利用了多进程调度的形式利用了多核的cpu来提升效率，但是进程间的通信开销还是不小的 同时进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。 在加上node本身底层的异步io与事件循环本身用的是Libuv的库，这是一个c/c++的跨平台的的基于事件驱动的异步io库，本身是可以利用多线程的属性处理密集io，但是不可否认js本身的优势地方和js的局限性，决定了node.js的性能会低于c++ 虽然线程和进程有本质的区别，但是在串行程序的基础上，线程和进程都是为了能提高程序的效率，线程执行开销小，但不利于资源的管理和保护；而进程正相反。同时，线程适合于在SMP机器上运行，而进程则可以跨机器迁移 在进程内创建、终止线程比创建、终止进程要快； 同一进程内的线程间切换比进程间的切换要快,尤其是用户级线程间的切换。1.10 插件 1.10.1 Sequelizejs db插件 此插件在option索引的位置千万不能写错，写错有大几率导致db堵塞 1.10.2 Lodashjs 文档 1.10.3 Moment.js 文档 案例使用 bash moment(event.start_time).startOf(&#39;day&#39;)/1000; moment.unix(moment().startOf(&#39;month&#39;)/1000).utcOffset(config.TIME_ZONE_DIFF).format(&quot;YYYY-MM-DD HH:mm:ss&quot;);","categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://zxtotti17.github.io/tags/node-js/"}]},{"title":"翻译提取替换","slug":"翻译提取替换","date":"2018-08-03T03:02:18.000Z","updated":"2022-09-13T07:10:48.821Z","comments":true,"path":"/post/翻译提取替换.html","link":"","permalink":"http://zxtotti17.github.io/post/%E7%BF%BB%E8%AF%91%E6%8F%90%E5%8F%96%E6%9B%BF%E6%8D%A2.html","excerpt":"提取提取客户端资源文件之前先要用uc-utf8.php转utf-8 把unicode码转成utf-8的日文在提取将要提取文字的文件整合与getFromHtml.sh 放在同目录下#!&#x2F;bin&#x2F;bash #sh getFromHtml.sh under the template fold #Change filelist.csv to excel file, and give it to translator LANG&#x3D;C grep -r -n -v &#39;^[[:cntrl:][:print:]]*$&#39; . | grep -v &quot;using UnityEngine;&quot; | grep -v svn | grep -v &#x2F;&#x2F; | grep -v \\* | grep -v &quot;\\&#123;\\*&quot; | grep -v &quot;\\&quot;Name\\&quot;&quot; &gt; ~&#x2F;lj_2_3_server.csv sed -i &#39;s@\\t@ @g&#39; ~&#x2F;lj_2_3_server.csv sed -i &#39;s@\\([^:]*\\):\\([0-9]*\\):@\\1\\t\\2\\t@&#39; ~&#x2F;lj_2_3_server.csv 点击下载","text":"提取提取客户端资源文件之前先要用uc-utf8.php转utf-8 把unicode码转成utf-8的日文在提取将要提取文字的文件整合与getFromHtml.sh 放在同目录下#!&#x2F;bin&#x2F;bash #sh getFromHtml.sh under the template fold #Change filelist.csv to excel file, and give it to translator LANG&#x3D;C grep -r -n -v &#39;^[[:cntrl:][:print:]]*$&#39; . | grep -v &quot;using UnityEngine;&quot; | grep -v svn | grep -v &#x2F;&#x2F; | grep -v \\* | grep -v &quot;\\&#123;\\*&quot; | grep -v &quot;\\&quot;Name\\&quot;&quot; &gt; ~&#x2F;lj_2_3_server.csv sed -i &#39;s@\\t@ @g&#39; ~&#x2F;lj_2_3_server.csv sed -i &#39;s@\\([^:]*\\):\\([0-9]*\\):@\\1\\t\\2\\t@&#39; ~&#x2F;lj_2_3_server.csv 点击下载 可以脚本文件内修改输出路径及文件名运行命令提取内容sh getFromHtml 取出后的excel先在编辑软件里打开编码改成ansi, 否则直接excel打开会乱码在excel内，全选，点击数据-&gt;分列-&gt;分隔符号-&gt;Tab键-&gt;确定。。。。以Tab键分割内容完成后的数据格式如下：(A列为行数，B列为行号，C列为提取的原字符)!A46180F494E722BBE7AB60D25E81DD0B如果有发现提取到不需要翻译的错误的，可直接整行删除。。。提交翻译 替换翻译后的文件如果为xls，在最后另起一列，用公式=A1&amp;”^”&amp;B1&amp;”^”&amp;C1连接，拖到底，用连接的主要目的是让文件、行、数据之间有个特殊的符号分割^ 这个符号基本见不到所以用这个，将最后列的数据拷贝到sublime，替换”^ “ 为 “^”去掉多余的数据与行之间的一个空格，然后将\\替换为@@@或者奇怪不重复的符号，如果不替换转换会被转换掉，最后将sublime上的代码考到新建的一个txt中另存为utf-8，上传到服务器对应的目录下面，修改changeHtml.sh这个文件中判断中间的分割符号保存，整个文件权限777. #!&#x2F;bin&#x2F;bash #sh changeHtml.sh result_file #result_file&#39; content #file&#39;s path line_no old_content new_content file&#x3D;$1 if [ -z $file ] then echo &quot;Input result_file&quot; exit fi while read line do IFS&#x3D;&quot;^&quot; arr&#x3D;($line) filename&#x3D;$&#123;arr[0]&#125; line_num&#x3D;$&#123;arr[1]&#125; str_kr&#x3D;$&#123;arr[2]&#125; if [ $str_kr ] then echo $filename echo $line_num echo $str_kr sed -i &#39;&#39;$line_num&#39; c\\&#39;$str_kr&#39;&#39; $filename else echo $line fi done &lt; $file 运行命令替换内容sh changeHtml.sh text.txt 运行完.asset的文件是没办法替换的，要手动自行替换 text.txt数据格式如下!326AD4E2572831FEFC87D564932D6106点击下载","categories":[{"name":"脚本工具","slug":"脚本工具","permalink":"http://zxtotti17.github.io/categories/%E8%84%9A%E6%9C%AC%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"http://zxtotti17.github.io/tags/%E6%B8%B8%E6%88%8F/"}]},{"title":"项目各种配置文件","slug":"项目各种配置文件","date":"2018-07-31T08:43:21.000Z","updated":"2022-09-09T08:24:28.517Z","comments":true,"path":"/post/项目各种配置文件.html","link":"","permalink":"http://zxtotti17.github.io/post/%E9%A1%B9%E7%9B%AE%E5%90%84%E7%A7%8D%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6.html","excerpt":"srpg.conf server &#123; listen 80; listen 443 ssl; # server_name alctwobt.ssl.91dena.cn; server_name alccn2-release.ssl.91dena.cn; # ssl on; ssl_certificate &#x2F;root&#x2F;cert&#x2F;91dena_cn.pem; ssl_certificate_key &#x2F;root&#x2F;cert&#x2F;91dena_cn.key; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; ## APP 11 location &#x2F; &#123; # proxy proxy_pass http:&#x2F;&#x2F;127.0.0.1:5000&#x2F;; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # connect to backend with keepalives proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; proxy_send_timeout 30s; proxy_read_timeout 60s; proxy_connect_timeout 30s; &#125; access_log &#x2F;home&#x2F;log&#x2F;nginxlog&#x2F;cnrelease&#x2F;alccn2.ssl.91dena.cn.access.log main; error_log &#x2F;home&#x2F;log&#x2F;nginxlog&#x2F;cnrelease&#x2F;alccn2.ssl.91dena.cn.error.log; &#125; 点击下载","text":"srpg.conf server &#123; listen 80; listen 443 ssl; # server_name alctwobt.ssl.91dena.cn; server_name alccn2-release.ssl.91dena.cn; # ssl on; ssl_certificate &#x2F;root&#x2F;cert&#x2F;91dena_cn.pem; ssl_certificate_key &#x2F;root&#x2F;cert&#x2F;91dena_cn.key; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; ## APP 11 location &#x2F; &#123; # proxy proxy_pass http:&#x2F;&#x2F;127.0.0.1:5000&#x2F;; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # connect to backend with keepalives proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; proxy_send_timeout 30s; proxy_read_timeout 60s; proxy_connect_timeout 30s; &#125; access_log &#x2F;home&#x2F;log&#x2F;nginxlog&#x2F;cnrelease&#x2F;alccn2.ssl.91dena.cn.access.log main; error_log &#x2F;home&#x2F;log&#x2F;nginxlog&#x2F;cnrelease&#x2F;alccn2.ssl.91dena.cn.error.log; &#125; 点击下载 nginx user nginx; worker_processes auto; worker_rlimit_nofile 150000; error_log &#x2F;tmp&#x2F;error.log; events &#123; worker_connections 65535; multi_accept on ; &#125; http &#123; include mime.types; default_type application&#x2F;octet-stream; log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; $request_time&#39; &#39; $status $body_bytes_sent &quot;$http_referer&quot; &#39; &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; $upstream_response_time&#39;; access_log &#x2F;tmp&#x2F;access.log; sendfile on; tcp_nopush on; keepalive_timeout 120; gzip on; include &#x2F;etcinx&#x2F;title&#x2F;*.conf; &#125; 点击下载 srpg-app #!&#x2F;bin&#x2F;bash ### BEGIN INIT INFO # Provides: webapp # Required-Start: $syslog $remote_fs # Required-Stop: $syslog $remote_fs # Should-Start: $local_fs # Should-Stop: $local_fs # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: Alchemist Webapp # Description: Alchemist Webapp ### END INIT INFO # ### BEGIN CHKCONFIG INFO # chkconfig: 2345 55 25 # description: Alchemist Webapp ### END CHKCONFIG INFO USER&#x3D;&quot;webapp&quot; NAME&#x3D;&quot;webapp&quot; NODE_ENV&#x3D;&quot;production&quot; NODE_BIN_DIR&#x3D;&quot;&#x2F;usr&#x2F;localde&#x2F;bin&quot; NODE_PATH&#x3D;&quot;&#x2F;usr&#x2F;localdebde_modules&quot; APPLICATION_PATH&#x3D;&quot;ar&#x2F;webapps&#x2F;alchemist&#x2F;currentde&#x2F;app&#x2F;app.js&quot; APPLICATION_WORKDIR&#x3D;&quot;ar&#x2F;webapps&#x2F;alchemist&#x2F;currentde&#x2F;app&#x2F;&quot; APPLICATION_OPTION&#x3D;&quot;&quot; LOGFILE&#x3D;&quot;ar&#x2F;webapps&#x2F;alchemist&#x2F;log&#x2F;forever&#x2F;app.log&quot; MIN_UPTIME&#x3D;&quot;5000&quot; SPIN_SLEEP_TIME&#x3D;&quot;10000&quot; PATH&#x3D;$NODE_BIN_DIR:$PATH export NODE_PATH&#x3D;$NODE_PATH start() &#123; echo &#96;runuser -l &quot;$USER&quot; -c &quot;forever list&quot;&#96; | grep -q &quot;$APPLICATION_PATH&quot; if [ &quot;$?&quot; -eq &quot;0&quot; ]; then echo &quot;$NAME is already running.&quot; RETVAL&#x3D;0 else echo &quot;Starting $NAME&quot; runuser -l &quot;$USER&quot; -c &quot;\\ export NODE_ENV&#x3D;$NODE_ENV &amp;&amp; forever \\ -a \\ -l $LOGFILE \\ --minUptime $MIN_UPTIME \\ --spinSleepTime $SPIN_SLEEP_TIME \\ --workingDir $APPLICATION_WORKDIR \\ start $APPLICATION_PATH $APPLICATION_OPTION&quot; 2&gt;&amp;1 &gt; &#x2F;dev&#x2F;null &amp; RETVAL&#x3D;$? fi &#125; stop() &#123; echo &#96;runuser -l &quot;$USER&quot; -c &quot;forever list&quot;&#96; | grep -q &quot;$APPLICATION_PATH&quot; if [ &quot;$?&quot; -eq &quot;0&quot; ]; then echo &quot;Shutting down $NAME&quot; # Tell Forever to stop the process. runuser -l &quot;$USER&quot; -c &quot;forever stop $APPLICATION_PATH&quot; 2&gt;&amp;1 &gt; &#x2F;dev&#x2F;null RETVAL&#x3D;$? else echo &quot;$NAME is not running.&quot; RETVAL&#x3D;0 fi &#125; restart() &#123; stop start &#125; status() &#123; echo &#96;runuser -l &quot;$USER&quot; -c &quot;forever list&quot;&#96; | grep -q &quot;$APPLICATION_PATH&quot; if [ &quot;$?&quot; -eq &quot;0&quot; ]; then echo &quot;$NAME is running.&quot; RETVAL&#x3D;0 else echo &quot;$NAME is not running.&quot; RETVAL&#x3D;3 fi &#125; case &quot;$1&quot; in start) start ;; stop) stop ;; status) status ;; restart) restart ;; *) echo &quot;Usage: &#123;start|stop|status|restart&#125;&quot; exit 1 ;; esac exit $RETVAL 点击下载 td-agent #### ## Output descriptions: ## # Treasure Data (http:&#x2F;&#x2F;www.treasure-data.com&#x2F;) provides cloud based data # analytics platform, which easily stores and processes data from td-agent. # FREE plan is also provided. # @see http:&#x2F;&#x2F;docs.fluentd.org&#x2F;articles&#x2F;http-to-td # # This section matches events whose tag is td.DATABASE.TABLE &lt;match td.*.*&gt; @type tdlog apikey YOUR_API_KEY auto_create_table buffer_type file buffer_path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;buffer&#x2F;td &lt;secondary&gt; @type file path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;failed_records &lt;&#x2F;secondary&gt; &lt;&#x2F;match&gt; ## match tag&#x3D;debug.** and dump to console &lt;match debug.**&gt; @type stdout &lt;&#x2F;match&gt; #### ## Source descriptions: ## ## built-in TCP input ## @see http:&#x2F;&#x2F;docs.fluentd.org&#x2F;articles&#x2F;in_forward &lt;source&gt; @type forward &lt;&#x2F;source&gt; ## built-in UNIX socket input #&lt;source&gt; # @type unix #&lt;&#x2F;source&gt; # HTTP input # POST http:&#x2F;&#x2F;localhost:8888&#x2F;&lt;tag&gt;?json&#x3D;&lt;json&gt; # POST http:&#x2F;&#x2F;localhost:8888&#x2F;td.myapp.login?json&#x3D;&#123;&quot;user&quot;%3A&quot;me&quot;&#125; # @see http:&#x2F;&#x2F;docs.fluentd.org&#x2F;articles&#x2F;in_http &lt;source&gt; @type http port 8888 &lt;&#x2F;source&gt; ## live debugging agent &lt;source&gt; @type debug_agent bind 127.0.0.1 port 24230 &lt;&#x2F;source&gt; #### ## Examples: ## ## File input ## read apache logs continuously and tags td.apache.access #&lt;source&gt; # @type tail # format apache # path &#x2F;var&#x2F;log&#x2F;httpd-access.log # tag td.apache.access #&lt;&#x2F;source&gt; ## File output ## match tag&#x3D;local.** and write to file #&lt;match local.**&gt; # @type file # path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;access #&lt;&#x2F;match&gt; ## Forwarding ## match tag&#x3D;system.** and forward to another td-agent server #&lt;match system.**&gt; # @type forward # host 192.168.0.11 # # secondary host is optional # &lt;secondary&gt; # host 192.168.0.12 # &lt;&#x2F;secondary&gt; #&lt;&#x2F;match&gt; ## Multiple output ## match tag&#x3D;td.*.* and output to Treasure Data AND file #&lt;match td.*.*&gt; # @type copy # &lt;store&gt; # @type tdlog # apikey API_KEY # auto_create_table # buffer_type file # buffer_path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;buffer&#x2F;td # &lt;&#x2F;store&gt; # &lt;store&gt; # @type file # path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;td-%Y-%m-%d&#x2F;%H.log # &lt;&#x2F;store&gt; #&lt;&#x2F;match&gt; #&lt;match *.**&gt; # type file # path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;error.log #&lt;&#x2F;match&gt; &lt;match alchemist.**&gt; type forward heartbeat_type tcp buffer_type file buffer_path &#x2F;var&#x2F;tmp&#x2F;td-agent&#x2F;forward.*.buffer buffer_chunk_limit 8m # チャンクサイズ buffer_queue_limit 256 # 1queueに保存できるchunk数の上限 flush_interval 1s # 10秒に1回送信 flush_at_shutdown true # シャットダウン時にチャンクを処理するか?(ファイルバッファのみ有効) retry_wait 5s # 再送実施までの待ち時間 retry_limit 2 # 再送実施回数 require_ack_response true expire_dns_cache 0 dns_round_robin true &lt;server&gt; host mongodb.alccn.91dena.cn port 24224 &lt;&#x2F;server&gt; # ログ送信失敗時のファイル # # &lt;secondary&gt; # # type file # # path &#x2F;var&#x2F;log&#x2F;td-agent&#x2F;failed&#x2F;forward-failed # #&lt;&#x2F;secondary&gt; &lt;&#x2F;match&gt; 点击下载","categories":[{"name":"脚本工具","slug":"脚本工具","permalink":"http://zxtotti17.github.io/categories/%E8%84%9A%E6%9C%AC%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://zxtotti17.github.io/tags/nginx/"},{"name":"td-agent","slug":"td-agent","permalink":"http://zxtotti17.github.io/tags/td-agent/"}]},{"title":"ALC_Sentry","slug":"ALC-Sentry","date":"2018-07-24T08:06:55.000Z","updated":"2022-09-13T07:04:12.993Z","comments":true,"path":"/post/ALC-Sentry.html","link":"","permalink":"http://zxtotti17.github.io/post/ALC-Sentry.html","excerpt":"1) 安装环境执行命令创建名为sentry的数据库createdb -E utf-8 sentry为sentry项目初始化数据sentry –config=/.sentry/sentry.conf.py upgrade创建新用户sentry –config=/.sentry/sentry.conf.py createuser然后就可以启动服务了sentry –config=/.sentry/sentry.conf.py start另外，还需要启动Workersentry –config=/.sentry/sentry.conf.py celery worker -B假设web服务器端口是9000，那么访问localhost:9000就能开始使用sentry了！ source /usr/local/vir-sentry/bin/activatesentry –config=~/.sentry/sentry.conf.py start &gt;&gt; /usr/local/vir-sentry/logs/sentry.log 2&gt;&amp;1 &amp;","text":"1) 安装环境执行命令创建名为sentry的数据库createdb -E utf-8 sentry为sentry项目初始化数据sentry –config=/.sentry/sentry.conf.py upgrade创建新用户sentry –config=/.sentry/sentry.conf.py createuser然后就可以启动服务了sentry –config=/.sentry/sentry.conf.py start另外，还需要启动Workersentry –config=/.sentry/sentry.conf.py celery worker -B假设web服务器端口是9000，那么访问localhost:9000就能开始使用sentry了！ source /usr/local/vir-sentry/bin/activatesentry –config=~/.sentry/sentry.conf.py start &gt;&gt; /usr/local/vir-sentry/logs/sentry.log 2&gt;&amp;1 &amp; 2）相关命令2.1启动su - webappsource /usr/local/vir-sentry/bin/activatesupervisord -c /etc/supervisord.confsupervisorctl start all2.2关闭命令su - webappsource /usr/local/vir-sentry/bin/activatesupervisorctl stop allkillall supervisord *创建账号 sentry createuser3)基于node的测试demoraven-node-master.zip 4.）界面显示!9E26651338B7EE1345DAFDEF0ADDB9C4 web 服务器相关配置!E4B1DB656739C13A7F75B5578E3CB678","categories":[{"name":"开发环境安装","slug":"开发环境安装","permalink":"http://zxtotti17.github.io/categories/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"}],"tags":[{"name":"Sentry","slug":"Sentry","permalink":"http://zxtotti17.github.io/tags/Sentry/"}]},{"title":"Alchemist_manage服务器部署","slug":"alchemist-manage","date":"2018-07-11T08:55:25.000Z","updated":"2022-09-13T07:05:57.458Z","comments":true,"path":"/post/alchemist-manage.html","link":"","permalink":"http://zxtotti17.github.io/post/alchemist-manage.html","excerpt":"manage服务器代码上传copy srpg_too 目录到 /var/webapps/alchemist_mnt (文件所有者必须为webapp) ruby运行环境构建 1 检查依赖 -ruby(v2.2.2p95~)-gem bundle-Node.js-npm-bower-msyql-redis2.1 设置gem源为淘宝源Gemfile （描述gem之间依赖文件）需要如下修改source ‘https://gems.ruby-china.org/&#39;2.2 安装gem filesu - webappbundle install2.2.1 安装bundle 命令不存在，。gem install bundle2.2.2 提示gem命令不存在，就执行rbenv global 2.2.2， 如果无法运行就重新安装ruby 2.2.2 版本，流程如下su - webappgit clone https://github.com/rbenv/rbenv.git ~/.rbenvcd ~/.rbenv &amp;&amp; src/configure &amp;&amp; make -C srcecho ‘export PATH=”$HOME/.rbenv/bin:$PATH”‘ &gt;&gt; ~/.bash_profile~/.rbenv/bin/rbenv initecho ‘eval “$(rbenv init -)”‘ &gt;&gt; ~/.bash_profilesource ~/.bash_profilegit clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-buildrbenv install 2.2.2rbenv global 2.2.2ruby -v","text":"manage服务器代码上传copy srpg_too 目录到 /var/webapps/alchemist_mnt (文件所有者必须为webapp) ruby运行环境构建 1 检查依赖 -ruby(v2.2.2p95~)-gem bundle-Node.js-npm-bower-msyql-redis2.1 设置gem源为淘宝源Gemfile （描述gem之间依赖文件）需要如下修改source ‘https://gems.ruby-china.org/&#39;2.2 安装gem filesu - webappbundle install2.2.1 安装bundle 命令不存在，。gem install bundle2.2.2 提示gem命令不存在，就执行rbenv global 2.2.2， 如果无法运行就重新安装ruby 2.2.2 版本，流程如下su - webappgit clone https://github.com/rbenv/rbenv.git ~/.rbenvcd ~/.rbenv &amp;&amp; src/configure &amp;&amp; make -C srcecho ‘export PATH=”$HOME/.rbenv/bin:$PATH”‘ &gt;&gt; ~/.bash_profile~/.rbenv/bin/rbenv initecho ‘eval “$(rbenv init -)”‘ &gt;&gt; ~/.bash_profilesource ~/.bash_profilegit clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-buildrbenv install 2.2.2rbenv global 2.2.2ruby -v Cap环境部署 1 配置SSH无密码登录配置config/deploy/produciton.rb ssh无密码登陆（id_rsa.pub和authorized_keys） 设置authorized_keys，记得chmod 600，否则无法生效） 1.1 生成sshkey:cd ~/.sshssh-keygen输入公钥名：id_rsa!AADD68F1E0BFC2CE65796C5F7EEBD67E 1.2 配置authorized_keyscat id_rsa.pub &gt;&gt; authorized_keyschmod -R 600 authorized_keyschmod 700 /.ssh备注：如果还是无法实现无密码登录，再清空下/.ssh/koown_hosts文件（echo “” &gt; ~/.sshown_hosts);!AADD68F1E0BFC2CE65796C5F7EEBD67E 1.3执行以下deploy命令：production环境为例cd currentbundle exec cap production mkdir:socketsbundle exec cap production bower:install 前端bower模块安装 1 Node.js 安装bowernpm install -g bower –registry=https://registry.npm.taobao.org (-g不一定要) 2install Bowerfilebundle exec rake bower:install 3 manage server DB构建bundle exec rake maint:create maint:migrate 4.4 添加管理账号 bundle exec rake maint:seed 4.5 配置crontab 缺少crontab 会影响预约奖励发放 cd 根目录（current/） gem install whenever ，检查config/schedule.rb是否存在 whenever -w（写入到crontab 中） 查看log/cron_log.log日志是否已生成。","categories":[{"name":"脚本工具","slug":"脚本工具","permalink":"http://zxtotti17.github.io/categories/%E8%84%9A%E6%9C%AC%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Ruby on Rails","slug":"Ruby-on-Rails","permalink":"http://zxtotti17.github.io/tags/Ruby-on-Rails/"},{"name":"Capistrano 自动部署工具","slug":"Capistrano-自动部署工具","permalink":"http://zxtotti17.github.io/tags/Capistrano-%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7/"}]},{"title":"Hexo 安装问题","slug":"hexo-安装遇到的问题","date":"2018-07-03T09:39:12.000Z","updated":"2022-09-09T08:25:59.456Z","comments":true,"path":"/post/hexo-安装遇到的问题.html","link":"","permalink":"http://zxtotti17.github.io/post/hexo-%E5%AE%89%E8%A3%85%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98.html","excerpt":"","text":"建站的过程网上一大把就不记录了，主要写下遇到的几个问题 github上的项目名称一定要和自己在github上的用户名一致，否则会生成静态文件后点开会白屏 多看看官方手册上面有详细记录https://hexo.io/zh-cn/docs hexo g -dhexo cleanhexo shexo目录下执行这样一句话npm install hexo-asset-image –save，这是下载安装一个可以上传本地图片的插件,再运行hexo n “xxxx”来生成md博文hexo new post xxxxx 生成带图片的博文 npm install hexo-generator-json-content –savenpm install hexo-deployer-git –savepost_asset_folder: true config.yml index_generator: per_page: 9 ##首页默认9篇文章标题 如果值为0不分页archive_generator: per_page: 100 ##归档页面默认100篇文章标题 yearly: true ##生成年视图 monthly: true ##生成月视图tag_generator: per_page: 100 ##标签分类页面默认100篇文章category_generator: per_page: 100 ###分类页面默认100篇文章","categories":[],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://zxtotti17.github.io/tags/node-js/"}]}],"categories":[{"name":"IT笔记","slug":"IT笔记","permalink":"http://zxtotti17.github.io/categories/IT%E7%AC%94%E8%AE%B0/"},{"name":"设计方法","slug":"设计方法","permalink":"http://zxtotti17.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%B3%95/"},{"name":"脚本工具","slug":"脚本工具","permalink":"http://zxtotti17.github.io/categories/%E8%84%9A%E6%9C%AC%E5%B7%A5%E5%85%B7/"},{"name":"开发环境安装","slug":"开发环境安装","permalink":"http://zxtotti17.github.io/categories/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://zxtotti17.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"面试","slug":"面试","permalink":"http://zxtotti17.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"游戏","slug":"游戏","permalink":"http://zxtotti17.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"go","slug":"go","permalink":"http://zxtotti17.github.io/tags/go/"},{"name":"node.js","slug":"node-js","permalink":"http://zxtotti17.github.io/tags/node-js/"},{"name":"安全","slug":"安全","permalink":"http://zxtotti17.github.io/tags/%E5%AE%89%E5%85%A8/"},{"name":"redis","slug":"redis","permalink":"http://zxtotti17.github.io/tags/redis/"},{"name":"mysql","slug":"mysql","permalink":"http://zxtotti17.github.io/tags/mysql/"},{"name":"MQ","slug":"MQ","permalink":"http://zxtotti17.github.io/tags/MQ/"},{"name":"mongodb","slug":"mongodb","permalink":"http://zxtotti17.github.io/tags/mongodb/"},{"name":"python","slug":"python","permalink":"http://zxtotti17.github.io/tags/python/"},{"name":"Erlang","slug":"Erlang","permalink":"http://zxtotti17.github.io/tags/Erlang/"},{"name":"c++","slug":"c","permalink":"http://zxtotti17.github.io/tags/c/"},{"name":"设计模式","slug":"设计模式","permalink":"http://zxtotti17.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"nginx","slug":"nginx","permalink":"http://zxtotti17.github.io/tags/nginx/"},{"name":"td-agent","slug":"td-agent","permalink":"http://zxtotti17.github.io/tags/td-agent/"},{"name":"Sentry","slug":"Sentry","permalink":"http://zxtotti17.github.io/tags/Sentry/"},{"name":"Ruby on Rails","slug":"Ruby-on-Rails","permalink":"http://zxtotti17.github.io/tags/Ruby-on-Rails/"},{"name":"Capistrano 自动部署工具","slug":"Capistrano-自动部署工具","permalink":"http://zxtotti17.github.io/tags/Capistrano-%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7/"}]}